--- 
published: false
title: "Lectures on Quantum Information Science"
author: "Artur Ekert and Tim Hosgood"
date: "Last updated: `r format(Sys.Date(), format='%B %d, %Y')`"
description: "The online book version of an introductory series of lectures on quantum computing."
output:
  bookdown::gitbook:
    css: ["gitbook-custom.css"]
    split_by: chapter
    config:
      toc:
        before: |
          <li><a href="https://thosgood.com/quantum-info/">Quantum Information Science</a></li>
        collapse: section
      view: https://github.com/thosgood/quantum-info/blob/master/%s
      download: ["pdf"]
      sharing:
        facebook: no
        github: no
        twitter: no
        linkedin: no
        weibo: no
        instapaper: no
        vk: no
        all: []
      info: no
  bookdown::pdf_book:
    template: latex-template.tex
    latex_engine: xelatex
    keep_tex: yes
---

\providecommand{\xmapsto}[1]{\overset{#1}{\longmapsto}}
\providecommand{\bra}[1]{\langle#1|}
\providecommand{\ket}[1]{|#1\rangle}
\providecommand{\braket}[1]{\langle#1\rangle}
\providecommand{\proj}[1]{|#1\rangle\langle#1|}
\providecommand{\av}[1]{\braket{#1}}
\providecommand{\tr}{\operatorname{tr}}
\providecommand{\id}{\operatorname{id}}
\providecommand{\diag}[2]{\begin{bmatrix}#1&0\\0&#2\end{bmatrix}}
\providecommand{\mqty}[1]{\begin{matrix}#1\end{matrix}}
\providecommand{\bmqty}[1]{\begin{bmatrix}#1\end{bmatrix}}
\renewcommand{\leq}{\leqslant}
\renewcommand{\geq}{\geqslant}

```{r echo=FALSE,warning=FALSE}
 library(knitr)
  opts_chunk$set(cache=TRUE,
                 echo=FALSE,
                 fig.pos='H',
                 fig.ext=if (knitr:::is_latex_output()) 'pdf' else 'png',
                 fig.align='center'
                )
```


# Introduction {-}

In this series of lectures you will learn how inherently quantum phenomena, such as quantum interference and quantum entanglement, can make information processing more efficient and more secure, even in the presence of noise.

The interdisciplinary nature of this topic, combined with the diverse backgrounds that different readers have, means that some may find some particular chapters easy, while others find them difficult.
The following will be assumed as prerequisites: elementary probability theory, complex numbers, vectors and matrices, tensor products, and Dirac bra-ket notation.
A basic knowledge of quantum mechanics (especially in the simple context of finite dimensional state spaces, e.g. state vectors, composite systems, unitary matrices, Born rule for quantum measurements) and some ideas from classical theoretical computer science (complexity theory) would be helpful, but is not at all essential.
Some of these things are covered at the end of this chapter.


## Topics {-}

- Fundamentals of quantum theory
  + addition of probability amplitudes
  + quantum interference
  + mathematical description of states and evolution of closed quantum systems (Hilbert space, unitary evolution)
  + measurements (projectors, Born rule)
  + Pauli matrices
- Distinguishability of quantum states
- The Bloch sphere
  + parametrisation
  + action of quantum gates on the Bloch vector
- The definition of quantum entanglement (tensor product structure)
- The no-cloning theorem and quantum teleportation
- Quantum gates
  + phase gate
  + Hadamard
  + controlled-not
  + SWAP
  + the Hadamard-phase-Hadamard network
  + phase “kick-back” induced by controlled-U
  + phase “kick-back” induced by quantum Boolean function evaluation
- Quantum algorithms
  + Deutsch
  + Bernstein-Vazirani
  + Simon
- Bell's theorem
  + Quantum correlations
  + CHSH inequality
  + density matrices
  + partial trace
  + statistical mixture of pure states,
- Born rule for density matrices
- Quantum entanglement in terms of density matrices
- Completely positive maps
  + Kraus operators
  + the Choi matrix
  + positive versus completely positive maps
  + partial-transpose
- The simple model of decoherence
- Quantum error correction of bit-flip and phase-flip errors





## Some mathematical preliminaries

### Euclidean vectors

We assume that you are familiar with Euclidean vectors --- those arrow-like geometric objects which are used to represent physical quantities, such as velocities, or forces.
You know that any two velocities can be added to yield a third, and the multiplication of a "velocity vector" by a real number is another "velocity vector".
So a **linear combination** of vectors is another vector.
Mathematicians have simply taken these properties and defined vectors as _anything_ that we can add and multiply by numbers, as long as everything behaves in a nice enough way.
This is basically what an Italian mathematician Giuseppe Peano (1858--1932) did in a chapter of his 1888 book with an impressive title: _Calcolo geometrico secondo l'Ausdehnungslehre di H. Grassmann preceduto dalle operazioni della logica deduttiva_.


### Vector spaces

Following Peano, we define a **vector space** as a mathematical structure in which the notion of linear combination "makes sense".

More formally, a **complex vector space** is a set $V$ such that, given any two **vectors** $a$ and $b$ (that is, any two elements of $V$) and any two complex numbers $\alpha$ and $\beta$, we can form the linear combination^[As we said, there are certain "nice properties" that these things must satisfy. Addition of vectors must be commutative and associative, with an identity (the zero vector, which will always be written as $\mathbf{0}$ ) and an inverse for each $v$ (written as $-v$). Multiplication by complex numbers must obey the two distributive laws: $(\alpha+\beta)v = \alpha v+\beta v$ and $\alpha (v+w) = \alpha v+\alpha w$.] $\alpha a+\beta b$, which is also a vector in $V$.

A **subspace** of $V$ is any subset of $V$ which is closed under vector addition and multiplication by complex numbers.
Here we start using the Dirac bra-ket notation and write vectors in a somewhat fancy way as $\ket{\mbox{label}}$, where the "label" is anything that serves to specify what the vector is.
For example, $\ket{\uparrow}$ and $\ket{\downarrow}$ may refer to an electron with spin up or down along some prescribed direction and $\ket{0}$ and $\ket{1}$ may describe a quantum bit (a "qubit") holding either logical $0$ or $1$.
These are often called **ket** vectors, or simply **kets**.
(We will deal with "bras" in a moment).
A **basis** in $V$ is a collection of vectors $\ket{e_1},\ket{e_2},\ldots,\ket{e_n}$ such that every vector $\ket{v}$ in $V$ can be written (in _exactly_ one way) as a linear combination of the basis vectors; $\ket{v}=\sum_i v_i\ket{e_i}$.
The number of elements in a basis is called the **dimension** of $V$.
(Showing that this definition is independent of the basis that we choose is a "fun" linear algebra exercise).
The most common $n$-dimensional complex vector space is the space of ordered $n$-tuples of complex numbers, usually written as column vectors:
$$
  \begin{gathered}
    \ket{a}
    = \begin{bmatrix}a_1\\a_2\\\vdots\\a_n\end{bmatrix}
    \qquad
    \ket{b}
    = \begin{bmatrix}b_1\\b_2\\\vdots\\b_n\end{bmatrix}
  \\\alpha\ket{a}+\beta\ket{b}
    = \begin{bmatrix}\alpha a_1+\beta b_1\\\alpha a_2+\beta b_2\\\vdots\\\alpha a_n+\beta b_n\end{bmatrix}
  \end{gathered}
$$

In fact, this is the space we will use most of the time.
Throughout the course we will deal only with vector spaces of _finite_ dimensions.
This is sufficient for all our purposes and we will avoid many mathematical subtleties associated with infinite dimensional spaces, for which we would need to tools of **functional analysis**.


### Bras and Kets


With any physical system we associate a complex vector space with an inner product, known as a Hilbert space $\mathcal{H}$.
The inner product^[The inner product is a function that assigns to each pair of vectors $\ket{u},\ket{v}\in{\mathcal{H}}$ a complex number $\braket{u|v}$ and satisfies the following conditions: $\braket{u|v}=\braket{v}{u}^\star$; $\braket{v|v}\geq 0$ for all $v$; $\braket{v|v}= 0$ if and only if $v=0$. The inner product must be linear in the second argument but antilinear in the first argument; $\braket{c_1u_1+c_2u_2}{v} = c_1^\star\braket{u_1}{v}+c_2^\star\braket{u_2}{v}$ for any complex constants $c_1$ and $c_2$.] between vectors $\ket{u}$ and $\ket{v}$ in ${\mathcal{H}}$ is written as
$$
  \braket{u|v}
$$
For example, for column vectors $\ket{u}$ and $\ket{v}$ in $\mathbb{C}^n$ written as
$$
  \ket{u}
  = \begin{bmatrix}u_1\\u_2\\\vdots\\u_n\end{bmatrix}
  \qquad
  \ket{v}
  = \begin{bmatrix}v_1\\v_2\\\vdots\\v_n\end{bmatrix}
$$
their inner product is defined as
$$
  \braket{u|v}
  = u_1^\star v_1 + u_2^\star v_2+\ldots + u_n^\star v_n.
$$
Following Dirac we may split the inner product into two ingredients ^[The term "Hilbert space" used to be reserved for an infinite-dimensional inner product space that is **complete**, i.e. such that every Cauchy sequence in the space converges to an element in the space. Nowadays, as in these notes, the term includes finite-dimensional spaces, which automatically satisfy the condition of completeness.]
$$
  \braket{u|v}
  \longrightarrow \bra{u}\,\ket{v}.
$$
Here $\ket{v}$ is a ket vector, and $\bra{u}$ is called a **bra** vector, or a **bra**, and can be represented by a row vector:
$$
  \bra{u}
  = \begin{bmatrix}u_1^\star,&u_2^\star,&\ldots,&u_n^\star\end{bmatrix}.
$$
The inner product can now be viewed as the result of the matrix multiplication:
$$
  \begin{aligned}
    \braket{u|v}
    &= \begin{bmatrix}u_1^\star,&u_2^\star,&\ldots,&u_n^\star\end{bmatrix}
    \cdot \begin{bmatrix}v_1\\v_2\\\vdots\\v_n\end{bmatrix}
  \\&= u_1^\star v_1 + u_2^\star v_2 + \ldots + u_n^\star v_n.
  \end{aligned}
$$

Bras are vectors: you can add them, and multiply them by scalars (which, here, are complex numbers), but they are vectors in the space ${\mathcal{H}}^\star$ which is **dual** to $\mathcal{H}$.
Elements of ${\mathcal{H}}^\star$ are **linear functionals**, that is, linear maps from $\mathcal{H}$ to $\mathbb{C}$.
A linear functional $\bra{u}$ acting on a vector $\ket{v}$ in $\mathcal{H}$ gives a complex number $\braket{u|v}$.

All Hilbert spaces of the same dimension are isomorphic, so the differences between quantum systems cannot be really understood without additional structure. This structure is provided by a specific algebra of operators acting on $\mathcal{H}$.


### Daggers

Although $\mathcal{H}$ and $\mathcal{H}^\star$ are not identical spaces -- the former is inhabited by kets, and the latter by bras -- they are closely related.
There is a bijective map from one to the other, $\ket{v}\leftrightarrow \bra{v}$, denoted by a **dagger**:^["Is this a $\dagger$ which I see before me..."]
$$
  \begin{aligned}
    \bra{v}
    &= (\ket{v})^\dagger
  \\\ket{v}
    &= (\bra{v})^\dagger.
  \end{aligned}
$$
We usually omit the parentheses when it is obvious what the dagger operation applies to.
The dagger operation, also known as **Hermitian conjugation**, is _antilinear_: 
$$
  \begin{aligned}
    (c_1\ket{v_1}+c_2\ket{v_2})^\dagger
    &= c_1^\star\bra{v_1} + c_2^\star\bra{v_2}
  \\(c_1\bra{v_1}+c_2\bra{v_2})^\dagger
    &= c_1^\star\ket{v_1} + c_2^\star\ket{v_2}.
  \end{aligned}
$$
Also, when applied twice, the dagger operation is the identity map.
In the matrix representation,^[Recall that the conjugate transpose, or the Hermitian conjugate, of an $(n\times m)$ matrix $A$ is an $(m\times n)$ matrix $A^\dagger$, obtained by interchanging the rows and columns of $A$ and taking complex conjugates of each entry in $A$, i.e. $A^\dagger_{ij}=A^\star_{ji}$. In mathematics texts it is often denoted by ${}^\star$ rather than ${}^\dagger$.]
$$
  \ket{v} = \begin{bmatrix}v_1\\v_2\\\vdots\\v_n\end{bmatrix}
  \overset{\dagger}{\longleftrightarrow}
  \bra{v} = \begin{bmatrix}v_1^\star,&v_2^\star,&\ldots,&v_n^\star\end{bmatrix}.
$$


### Geometry

The inner product brings geometry: the **length**, or **norm**, of $\ket{v}$ is given by $\|v\|=\sqrt{\braket{v|v}}$, and we say that $\ket{u}$ and $\ket{v}$ are **orthogonal** if $\braket{u|v}=0$.
Any maximal set of pairwise orthogonal vectors of unit length^[That is, consider all sets $\{\ket{e_i}\}$ of vectors such that $\braket{e_i}{e_j}=\delta_{ij}$ (where the **Kronecker delta** $\delta_{ij}$ is a symbol that is defined to be $0$ if $i\neq j$, and to be $1$ if $i=j$.), and then pick any of the largest such sets (which must exist, by the fact that we assume our vector spaces to be finite dimensional).] forms an orthonormal basis, and so any vector can be expressed as a linear combination of the basis vectors:
$$
  \begin{gathered}
    \ket{v}
    =\sum_i v_i\ket{e_i}
  \\\mbox{where $v_i=\braket{e_i|v}$}.
  \end{gathered}
$$
Then the bras $\bra{e_i}$ form the **dual basis**
$$
  \begin{gathered}
    \bra{v}
    =\sum_i v_i^\star\bra{e_i}
  \\\mbox{where $v_i^\star=\braket{v|e_i}$}.
  \end{gathered}
$$

To make the notation a bit less cumbersome, we will sometimes^[Do not confuse $\ket{0}$ with the zero vector. We _never_ write the zero vector as $\ket{0}$, it will be always written as $0$ without any bra or ket decorations, e.g. $\ket{v}+0=\ket{v}$.] label the basis kets as $\ket{i}$ rather than $\ket{e_i}$, and write
$$
  \begin{aligned}
    \ket{v}
    &= \sum_i \ket{i}\braket{i|v}
  \\\bra{v}
    &= \sum_j \braket{v|i}\bra{i}.
  \end{aligned}
$$


### Operators

**!!!TODO!!! note that unitary operators preserve the inner product (2.5)**


### Outer products


### The trace
