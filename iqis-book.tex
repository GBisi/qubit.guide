\documentclass[fleqn]{article}
\usepackage{NotesTeX}
\usepackage{charter}

\usepackage{amsmath,amssymb}
\usepackage{enumitem}
\usepackage{tcolorbox}
\usepackage{tikz-cd}
\usepackage{amscd}
\usepackage{mathtools}
\usepackage{dsfont}
\usepackage{colortbl}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{longtable}
\usepackage{float}
\usepackage{comment}

\usepackage{pgfplots}
\pgfplotsset{compat=1.17}
\usepackage{tikz-3dplot-circleofsphere}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}

\renewcommand{\leq}{\leqslant}
\renewcommand{\geq}{\geqslant}

\definecolor{primary}{RGB}{177,98,78}
\definecolor{secondary}{RGB}{91,132,177}

\usepackage{hyperref}
\hypersetup{linkcolor={secondary},urlcolor={primary}}
\usepackage[noabbrev,capitalise,nameinlink]{cleveref}
\crefformat{equation}{(#2#1#3)}


\newenvironment{idea}{\noindent}{\medskip}

\tcolorboxenvironment{idea}{
  boxrule=2pt,
  boxsep=3pt,
  colback={white},
  colframe={secondary},
  enhanced jigsaw,
  rounded corners,
  before skip=10pt,
  after skip=10pt,
}

\newtheorem*{scenario}{Scenario}

\tcolorboxenvironment{scenario}{
  boxrule=2pt,
  boxsep=3pt,
  colback={white},
  colframe={gray},
  enhanced jigsaw,
  rounded corners,
  before skip=10pt,
  after skip=10pt,
}

\newtheorem*{circuit}{Circuit}

\tcolorboxenvironment{circuit}{
  boxrule=2pt,
  boxsep=3pt,
  colback={white},
  colframe={primary},
  enhanced jigsaw,
  rounded corners,
  before skip=10pt,
  after skip=10pt,
}


\renewcommand{\footnote}[1]{\en{#1}}

\let\oldsection\section
\renewcommand\section{\clearpage\oldsection}
\let\oldpart\part
\renewcommand\part{\clearpage\oldpart}


\pagestyle{fancy}
\lhead{\thesubsection\,\,{\itshape\rightmark}}
\rhead{\thepage}
\fancyfoot{}


\usepackage{etoolbox}
\AtBeginEnvironment{quote}{\itshape}



\title{Introduction to Quantum Information Science}
\author{\href{https://www.arturekert.org/}{Artur Ekert} and \href{https://thosgood.com}{Tim Hosgood}}
\date{Last updated: 03 May 2022}


\begin{document}


\setcounter{tocdepth}{2}
\maketitle

\hypertarget{introduction}{%
\section*{Introduction}\label{introduction}}
\addcontentsline{toc}{section}{Introduction}

\providecommand{\xmapsto}[1]{\overset{#1}{\longmapsto}}
\providecommand{\bra}[1]{\langle#1|}
\providecommand{\ket}[1]{|#1\rangle}
\providecommand{\braket}[2]{\langle#1|#2\rangle}
\providecommand{\proj}[1]{|#1\rangle\langle#1|}
\providecommand{\av}[1]{\langle#1\rangle}
\providecommand{\tr}{\operatorname{tr}}
\providecommand{\id}{\mathbf{1}}
\providecommand{\diag}[2]{\begin{bmatrix}#1&0\\0&#2\end{bmatrix}}
\providecommand{\mqty}[1]{\begin{matrix}#1\end{matrix}}
\providecommand{\bmqty}[1]{\begin{bmatrix}#1\end{bmatrix}}
\renewcommand{\leq}{\leqslant}
\renewcommand{\geq}{\geqslant}

For the past however-many years, \href{https://www.arturekert.com/}{Artur Ekert} has been teaching the masters course ``Introduction to Quantum Information'' at the University of Oxford.
During this time, many versions of accompanying lecture notes have come and gone, with constant improvements and changes being made.
The version that you will find on this website has been carefully edited by \href{https://thosgood.com}{Tim Hosgood} into a cohesive ``book'', containing additional exercises and topics.
Thanks go to Zhenyu Cai for many helpful comments and corrections, and we also appreciate the work of Yihui Xie in developing the \href{https://bookdown.org/yihui/bookdown/}{Bookdown package} with which this document was built.

For more information, see the \href{https://arturekert.org/iqis}{accompanying website}.

\hypertarget{plan}{%
\subsection*{Plan}\label{plan}}
\addcontentsline{toc}{subsection}{Plan}

In this series of lectures you will learn how inherently quantum phenomena, such as quantum interference and quantum entanglement, can make information processing more efficient and more secure, even in the presence of noise.

The interdisciplinary nature of this topic, combined with the diverse backgrounds that different readers have, means that some may find some particular chapters easy, while others find them difficult.
The following will be assumed as prerequisites: elementary probability theory, complex numbers, vectors and matrices, tensor products, and Dirac bra-ket notation.
A basic knowledge of quantum mechanics (especially in the simple context of finite dimensional state spaces, e.g.~state vectors, composite systems, unitary matrices, Born rule for quantum measurements) and some ideas from classical theoretical computer science (complexity theory) would be helpful, but is not at all essential.
Some of these things are covered at the end of this chapter.

\hypertarget{topics}{%
\subsection*{Topics}\label{topics}}
\addcontentsline{toc}{subsection}{Topics}

\begin{itemize}
\tightlist
\item
  Fundamentals of quantum theory

  \begin{itemize}
  \tightlist
  \item
    addition of probability amplitudes
  \item
    quantum interference
  \item
    mathematical description of states and evolution of closed quantum systems (Hilbert space, unitary evolution)
  \item
    measurements (projectors, Born rule)
  \item
    Pauli matrices
  \end{itemize}
\item
  Distinguishability of quantum states
\item
  The Bloch sphere

  \begin{itemize}
  \tightlist
  \item
    parametrisation
  \item
    action of quantum gates on the Bloch vector
  \end{itemize}
\item
  The definition of quantum entanglement (the tensor product structure)
\item
  The no-cloning theorem, and quantum teleportation
\item
  Quantum gates

  \begin{itemize}
  \tightlist
  \item
    phase gate
  \item
    Hadamard
  \item
    controlled-\(\texttt{NOT}\)
  \item
    SWAP
  \item
    the Hadamard-phase-Hadamard network
  \item
    phase ``kick-back'' induced by controlled-\(U\)
  \item
    phase ``kick-back'' induced by quantum Boolean function evaluation
  \end{itemize}
\item
  Quantum algorithms

  \begin{itemize}
  \tightlist
  \item
    Deutsch
  \item
    Bernstein-Vazirani
  \item
    Simon
  \end{itemize}
\item
  Bell's theorem

  \begin{itemize}
  \tightlist
  \item
    Quantum correlations
  \item
    CHSH inequality
  \end{itemize}
\item
  Density matrices

  \begin{itemize}
  \tightlist
  \item
    partial trace
  \item
    statistical mixture of pure states
  \item
    Born rule for density matrices
  \item
    quantum entanglement in terms of density matrices
  \end{itemize}
\item
  Completely positive maps

  \begin{itemize}
  \tightlist
  \item
    Kraus operators
  \item
    the Choi matrix
  \item
    positive versus completely positive maps
  \item
    partial-transpose
  \end{itemize}
\item
  The simple model of decoherence
\item
  Quantum error correction of bit-flip and phase-flip errors
\end{itemize}

\hypertarget{some-mathematical-preliminaries}{%
\section*{Some mathematical preliminaries}\label{some-mathematical-preliminaries}}
\addcontentsline{toc}{section}{Some mathematical preliminaries}

Here we quickly recall most of the fundamental mathematical results that we will rely on in the rest of this book, namely \emph{linear algebra over the complex numbers}.
If an equation like \(\operatorname{tr}|a\rangle\langle b|=\langle a|b\rangle\) makes sense to you, then you can safely skip over this and get started directly with \protect\hyperlink{quantum-interference}{Chapter 1}.

\hypertarget{euclidean-vectors}{%
\subsection{Euclidean vectors}\label{euclidean-vectors}}

We assume that you are familiar with Euclidean vectors --- those arrow-like geometric objects which are used to represent physical quantities, such as velocities, or forces.
You know that any two velocities can be added to yield a third, and the multiplication of a ``velocity vector'' by a real number is another ``velocity vector''.
So a \textbf{linear combination} of vectors is another vector.
Mathematicians have simply taken these properties and defined vectors as \emph{anything} that we can add and multiply by numbers, as long as everything behaves in a nice enough way.
This is basically what an Italian mathematician Giuseppe Peano (1858--1932) did in a chapter of his 1888 book with an impressive title: \emph{Calcolo geometrico secondo l'Ausdehnungslehre di H. Grassmann preceduto dalle operazioni della logica deduttiva}.

\hypertarget{vector-spaces}{%
\subsection{Vector spaces}\label{vector-spaces}}

Following Peano, we define a \textbf{vector space} as a mathematical structure in which the notion of linear combination ``makes sense''.

More formally, a \textbf{complex vector space} is a set \(V\) such that, given any two \textbf{vectors} \(a\) and \(b\) (that is, any two elements of \(V\)) and any two complex numbers \(\alpha\) and \(\beta\), we can form the linear combination\footnote{As we said, there are certain ``nice properties'' that these things must satisfy. Addition of vectors must be commutative and associative, with an identity (the zero vector, which will always be written as \(\mathbf{0}\) ) and an inverse for each \(v\) (written as \(-v\)). Multiplication by complex numbers must obey the two distributive laws: \((\alpha+\beta)v = \alpha v+\beta v\) and \(\alpha (v+w) = \alpha v+\alpha w\).} \(\alpha a+\beta b\), which is also a vector in \(V\).

A \textbf{subspace} of \(V\) is any subset of \(V\) which is closed under vector addition and multiplication by complex numbers.
Here we start using the Dirac bra-ket notation and write vectors in a somewhat fancy way as \(|\text{label}\rangle\), where the ``label'' is anything that serves to specify what the vector is.
For example, \(|\uparrow\rangle\) and \(|\downarrow\rangle\) may refer to an electron with spin up or down along some prescribed direction and \(|0\rangle\) and \(|1\rangle\) may describe a quantum bit (a ``qubit'') holding either logical \(0\) or \(1\).
These are often called \textbf{ket} vectors, or simply \textbf{kets}.
(We will deal with ``bras'' in a moment).
A \textbf{basis} in \(V\) is a collection of vectors \(|e_1\rangle,|e_2\rangle,\ldots,|e_n\rangle\) such that every vector \(|v\rangle\) in \(V\) can be written (in \emph{exactly} one way) as a linear combination of the basis vectors; \(|v\rangle=\sum_i v_i|e_i\rangle\).
The number of elements in a basis is called the \textbf{dimension} of \(V\).
(Showing that this definition is independent of the basis that we choose is a ``fun'' linear algebra exercise).
The most common \(n\)-dimensional complex vector space is the space of ordered \(n\)-tuples of complex numbers, usually written as column vectors:
\[
  \begin{gathered}
    |a\rangle
    = \begin{bmatrix}a_1\\a_2\\\vdots\\a_n\end{bmatrix}
    \qquad
    |b\rangle
    = \begin{bmatrix}b_1\\b_2\\\vdots\\b_n\end{bmatrix}
  \\\alpha|a\rangle+\beta|b\rangle
    = \begin{bmatrix}\alpha a_1+\beta b_1\\\alpha a_2+\beta b_2\\\vdots\\\alpha a_n+\beta b_n\end{bmatrix}
  \end{gathered}
\]

In fact, this is the space we will use most of the time.
Throughout the course we will deal only with vector spaces of \emph{finite} dimensions.
This is sufficient for all our purposes and we will avoid many mathematical subtleties associated with infinite dimensional spaces, for which we would need to tools of \textbf{functional analysis}.

\hypertarget{bras-and-kets}{%
\subsection{Bras and kets}\label{bras-and-kets}}

An \textbf{inner product} on a vector space \(V\) (over the complex numbers) is a function that assigns to each pair of vectors \(|u\rangle,|v\rangle\in V\) a complex number \(\langle u|v\rangle\), and satisfies the following conditions:

\begin{itemize}
\tightlist
\item
  \(\langle u|v\rangle=\langle v|u\rangle^\star\);
\item
  \(\langle v|v\rangle\geqslant 0\) for all \(|v\rangle\);
\item
  \(\langle v|v\rangle= 0\) if and only if \(|v\rangle=0\).
\end{itemize}

The inner product must also be \emph{linear} in the second argument but \emph{antilinear} in the first argument:
\[
  \langle c_1u_1+c_2u_2|v\rangle = c_1^\star\langle u_1|v\rangle+c_2^\star\langle u_2|v\rangle
\]
for any complex constants \(c_1\) and \(c_2\).

With any physical system we associate a complex vector space with an inner product, known as a \textbf{Hilbert space}\footnote{The term ``Hilbert space'' used to be reserved for an infinite-dimensional inner product space that is \textbf{complete}, i.e.~such that every Cauchy sequence in the space converges to an element in the space. Nowadays, as in these notes, the term includes finite-dimensional spaces, which automatically satisfy the condition of completeness.} \(\mathcal{H}\).
The inner product between vectors \(|u\rangle\) and \(|v\rangle\) in \({\mathcal{H}}\) is written as \(\langle u|v\rangle\).

For example, for column vectors \(|u\rangle\) and \(|v\rangle\) in \(\mathbb{C}^n\) written as
\[
  |u\rangle
  = \begin{bmatrix}u_1\\u_2\\\vdots\\u_n\end{bmatrix}
  \qquad
  |v\rangle
  = \begin{bmatrix}v_1\\v_2\\\vdots\\v_n\end{bmatrix}
\]
their inner product is defined by
\[
  \langle u|v\rangle
  = u_1^\star v_1 + u_2^\star v_2+\ldots + u_n^\star v_n.
\]
Following Dirac, we may split the inner product into two ingredients:
\[
  \langle u|v\rangle
  \longrightarrow \langle u|\,|v\rangle.
\]
Here \(|v\rangle\) is a ket vector, and \(\langle u|\) is called a \textbf{bra} vector, or a \textbf{bra}, and can be represented by a row vector:
\[
  \langle u|
  = \begin{bmatrix}u_1^\star,&u_2^\star,&\ldots,&u_n^\star\end{bmatrix}.
\]
The inner product can now be viewed as the result of the matrix multiplication:
\[
  \begin{aligned}
    \langle u|v\rangle
    &= \begin{bmatrix}u_1^\star,&u_2^\star,&\ldots,&u_n^\star\end{bmatrix}
    \cdot \begin{bmatrix}v_1\\v_2\\\vdots\\v_n\end{bmatrix}
  \\&= u_1^\star v_1 + u_2^\star v_2 + \ldots + u_n^\star v_n.
  \end{aligned}
\]

Bras are vectors: you can add them, and multiply them by scalars (which, here, are complex numbers), but they are vectors in the space \({\mathcal{H}}^\star\) which is \textbf{dual} to \(\mathcal{H}\).
Elements of \({\mathcal{H}}^\star\) are \textbf{linear functionals}, that is, linear maps from \(\mathcal{H}\) to \(\mathbb{C}\).
A linear functional \(\langle u|\) acting on a vector \(|v\rangle\) in \(\mathcal{H}\) gives a complex number \(\langle u|v\rangle\).

\begin{idea}
All Hilbert spaces of the same dimension are isomorphic, so the differences between quantum systems cannot be really understood without additional structure. This structure is provided by a specific algebra of operators acting on \(\mathcal{H}\).

\end{idea}

\hypertarget{daggers}{%
\subsection{Daggers}\label{daggers}}

Although \(\mathcal{H}\) and \(\mathcal{H}^\star\) are not identical spaces --- the former is inhabited by kets, and the latter by bras --- they are closely related.
There is a bijective map from one to the other, \(|v\rangle\leftrightarrow \langle v|\), denoted by a \textbf{dagger}:\footnote{``Is this a \(\dagger\) which I see before me\ldots{}''}
\[
  \begin{aligned}
    \langle v|
    &= (|v\rangle)^\dagger
  \\|v\rangle
    &= (\langle v|)^\dagger.
  \end{aligned}
\]
We usually omit the parentheses when it is obvious what the dagger operation applies to.

The dagger operation, also known as \textbf{Hermitian conjugation}, is \emph{antilinear}:
\[
  \begin{aligned}
    (c_1|v_1\rangle+c_2|v_2\rangle)^\dagger
    &= c_1^\star\langle v_1| + c_2^\star\langle v_2|
  \\(c_1\langle v_1|+c_2\langle v_2|)^\dagger
    &= c_1^\star|v_1\rangle + c_2^\star|v_2\rangle.
  \end{aligned}
\]
Also, when applied twice, the dagger operation is the identity map.
In the matrix representation,\footnote{Recall that the conjugate transpose, or the Hermitian conjugate, of an \((n\times m)\) matrix \(A\) is an \((m\times n)\) matrix \(A^\dagger\), obtained by interchanging the rows and columns of \(A\) and taking complex conjugates of each entry in \(A\), i.e.~\(A^\dagger_{ij}=A^\star_{ji}\). In mathematics texts it is often denoted by \({}^\star\) rather than \({}^\dagger\).}
\[
  |v\rangle = \begin{bmatrix}v_1\\v_2\\\vdots\\v_n\end{bmatrix}
  \overset{\dagger}{\longleftrightarrow}
  \langle v| = \begin{bmatrix}v_1^\star,&v_2^\star,&\ldots,&v_n^\star\end{bmatrix}.
\]

\hypertarget{geometry}{%
\subsection{Geometry}\label{geometry}}

The inner product brings geometry: the \textbf{length}, or \textbf{norm}, of \(|v\rangle\) is given by \(\|v\|=\sqrt{\langle v|v\rangle}\), and we say that \(|u\rangle\) and \(|v\rangle\) are \textbf{orthogonal} if \(\langle u|v\rangle=0\).
Any maximal set of pairwise orthogonal vectors of unit length\footnote{That is, consider sets of vectors \(|e_i\rangle\) such that \(\langle e_i|e_j\rangle=\delta_{ij}\) (where the \textbf{Kronecker delta} \(\delta_{ij}\) is \(0\) if \(i\neq j\), and \(1\) if \(i=j\).), and then pick any of the largest such sets (which must exist, since we assume our vector spaces to be finite dimensional).} forms an orthonormal basis, and so any vector can be expressed as a linear combination of the basis vectors:
\[
  \begin{gathered}
    |v\rangle
    =\sum_i v_i|e_i\rangle
  \\\text{where $v_i=\langle e_i|v\rangle$}.
  \end{gathered}
\]
Then the bras \(\langle e_i|\) form the \textbf{dual basis}
\[
  \begin{gathered}
    \langle v|
    =\sum_i v_i^\star\langle e_i|
  \\\text{where $v_i^\star=\langle v|e_i\rangle$}.
  \end{gathered}
\]

To make the notation a bit less cumbersome, we will sometimes label the basis kets as \(|i\rangle\) rather than \(|e_i\rangle\), and write
\[
  \begin{aligned}
    |v\rangle
    &= \sum_i |i\rangle\langle i|v\rangle
  \\\langle v|
    &= \sum_j \langle v|i\rangle\langle i|.
  \end{aligned}
\]
But \emph{do not confuse \(|0\rangle\) with the zero vector}!
We \emph{never} write the zero vector as \(|0\rangle\), but only ever as \(0\), without any bra or ket decorations (so e.g.~\(|v\rangle+0=|v\rangle\)).

\begin{idea}

\begin{itemize}
\item
  With any \emph{isolated} quantum system, which can be prepared in \(n\) \emph{perfectly distinguishable} states, we can associate a Hilbert space \(\mathcal{H}\) of dimension \(n\) such that each vector \(|v\rangle\in\mathcal{H}\) of unit length (i.e.~\(\langle v|v\rangle =1\)) represents a quantum state of the system.
\item
  The overall phase of the vector has no physical significance: \(|v\rangle\) and \(e^{i\varphi}|v\rangle\) (for any real \(\varphi\)) both describe the same state.
\item
  The inner product \(\langle u|v\rangle\) is the \emph{probability amplitude} that a quantum system prepared in state \(|v\rangle\) will be found in state \(|u\rangle\) upon measurement.
\item
  States corresponding to orthogonal vectors (i.e.~\(\langle u|v\rangle=0\)) are \emph{perfectly distinguishable}, since, if we prepare the system in state \(|v\rangle\), then it will never be found in state \(|u\rangle\), and vice versa.
  In particular, states forming orthonormal bases are always perfectly distinguishable from each other.
  Choosing such states, as we shall see in a moment, is equivalent to choosing a particular quantum measurement.
\end{itemize}


\end{idea}

\hypertarget{operators}{%
\subsection{Operators}\label{operators}}

A \textbf{linear map} between two vector spaces \(\mathcal{H}\) and \(\mathcal{K}\) is a function \(A\colon\mathcal{H}\to\mathcal{K}\) that respects linear combinations:
\[
  A(c_1|v_1\rangle+c_2|v_2\rangle)=c_1 A|v_1\rangle+c_2 A|v_2\rangle
\]
for any vectors \(|v_1\rangle,|v_2\rangle\) and any complex numbers \(c_1,c_2\).
We will focus mostly on \textbf{endomorphisms}, that is, maps from \(\mathcal{H}\) to \(\mathcal{H}\), and we will call them \textbf{operators}.
The symbol \(\mathbf{1}\) is reserved for the identity operator that maps every element of \(\mathcal{H}\) to itself (i.e.~\(\mathbf{1}|v\rangle=|v\rangle\) for all \(|v\rangle\in\mathcal{H}\)).
The product \(AB\) of two operators \(A\) and \(B\) is the operator obtained by first applying \(B\) to some ket \(|v\rangle\) and then \(A\) to the ket which results from applying \(B\):
\[
  (AB)|v\rangle = A(B|v\rangle).
\]
The order \emph{does} matter: in general, \(AB\neq BA\).
In the exceptional case in which \(AB=BA\), one says that these two operators \textbf{commute}.
The inverse of \(A\), written as \(A^{-1}\), is the operator that satisfies \(AA^{-1}=\mathbf{1}=A^{-1}A\).
For finite-dimensional spaces, one only needs to check \emph{one} of these two conditions, since any one of the two implies the other, whereas, on an infinite-dimensional space, \emph{both} must be checked.
Finally, given a particular basis, an operator \(A\) is uniquely determined by the entries of its matrix, defined by \(A_{ij}=\langle i|A|j\rangle\).
The \textbf{adjoint}, or \textbf{Hermitian conjugate}, of \(A\), denoted by \(A^\dagger\), is defined by the relation
\[
  \begin{gathered}
    \langle i|A^\dagger|j\rangle
    = \langle j|A|i\rangle^\star
  \\\text{for all $|i\rangle,|j\rangle\in\mathcal{H}$}.
  \end{gathered}
\]

An operator \(A\) is said to be

\begin{itemize}
\tightlist
\item
  \textbf{normal} if \(AA^\dagger = A^\dagger A\),
\item
  \textbf{unitary} if \(AA^\dagger = A^\dagger A = \mathbf{1}\),
\item
  \textbf{Hermitian} (or \textbf{self-adjoint}) if \(A^\dagger = A\).
\end{itemize}

Any physically admissible evolution of an isolated quantum system is represented by a unitary operator.
Note that unitary operators preserve the inner product: given a unitary operator \(U\) and two kets \(|a\rangle\) and \(|b\rangle\), and defining \(|a'\rangle=U|a\rangle\) and \(|b'\rangle=U|b\rangle\), we have that
\[
  \begin{gathered}
    \langle a'|=\langle a|U^\dagger
  \\\langle b'|=\langle b|U^\dagger
  \\\langle a'|b'\rangle=\langle a|U^\dagger U|b\rangle=\langle a|\mathbf{1}|b\rangle=\langle a|b\rangle.
  \end{gathered}
\]
Preserving the inner product implies preserving the norm induced by this product, i.e.~unit state vectors are mapped to unit state vectors, i.e.~\emph{unitary operations are the isometries of the Euclidean norm}.

\hypertarget{outer-products}{%
\subsection{Outer products}\label{outer-products}}

Apart from the inner product \(\langle u|v\rangle\), which is a complex number, we can also form the \textbf{outer product} \(|u\rangle\langle v|\), which is a linear map (operator) on \(\mathcal{H}\) (or on \(\mathcal{H}^\star\), depending how you look at it).
This is what physicists like (and what mathematicians dislike!) about Dirac notation: a certain degree of healthy ambiguity.

\begin{itemize}
\tightlist
\item
  The result of \(|u\rangle\langle v|\) acting on a ket \(|x\rangle\) is \(|u\rangle\langle v|x\rangle\), i.e.~the vector \(|u\rangle\) multiplied by the complex number \(\langle v|x\rangle\).
\item
  Similarly, the result of \(|u\rangle\langle v|\) acting on a bra \(\langle y|\) is \(\langle y|u\rangle\langle v|\), i.e.~the functional \(\langle v|\) multiplied by the complex number \(\langle y|u\rangle\).
\end{itemize}

The product of two maps, \(A=|a\rangle\langle b|\) followed by \(B=|c\rangle\langle d|\), is a linear map \(BA\), which can be written in Dirac notation as
\[
  BA = |c\rangle\langle d|a\rangle\langle b| = \langle d|a\rangle|c\rangle\langle b|
\]
i.e.~the inner product (complex number) \(\langle d|a\rangle\) times the outer product (linear map) \(|c\rangle\langle b|\).

Any operator on \(\mathcal{H}\) can be expressed as a sum of outer products. Given an orthonormal basis \(\{|e_i\rangle\}\), any operator which maps the basis vectors \(|e_i\rangle\) to vectors \(|f_i\rangle\) can be written as \(\sum_i|f_i\rangle\langle e_i|\), where the sum is over all the vectors in the orthonormal basis.
If the vectors \(\{|f_i\rangle\}\) also form an orthonormal basis then the operator simply ``rotates'' one orthonormal basis into another.
These are unitary operators which preserve the inner product.
In particular, if each \(|e_i\rangle\) is mapped to \(|e_i\rangle\), then we obtain the identity operator:
\[
  \sum_i|e_i\rangle\langle e_i|=\mathbf{1}.
\]
This relation holds for \emph{any} orthonormal basis, and it is one of the most ubiquitous and useful formulas in quantum theory.
For example, for any vector \(|v\rangle\) and for any orthonormal basis \(\{|e_i\rangle\}\), we have
\[
  \begin{aligned}
    |v\rangle
    &= \mathbf{1}|v\rangle
  \\&= \sum_i |e_i\rangle\langle e_i|\;|v\rangle
  \\&= \sum_i |e_i\rangle\;\langle e_i|v\rangle
  \\&= \sum_i v_i|e_i\rangle,
  \end{aligned}
\]
where \(v_i=\langle e_i|v\rangle\) are the components of \(|v\rangle\).
Finally, note that the adjoint of \(|a\rangle\langle b|\) is \(|b\rangle\langle a|\).

\hypertarget{the-trace}{%
\subsection{The trace}\label{the-trace}}

The \textbf{trace} is an operation which turns outer products into inner products,
\[
  \operatorname{tr}\colon |b\rangle\langle a| \longmapsto \langle a|b\rangle.
\]
We have just seen that any linear operator can be written as a sum of outer products, and so we can extend the definition of trace (by linearity) to any operator.
Alternatively, for any square matrix \(A\), the trace of \(A\) is defined to be the sum of its diagonal elements:
\[
  \operatorname{tr}A = \sum_k \langle e_k|A|e_k\rangle = \sum_k A_{kk}.
\]
You can show, using this definition or otherwise, that the trace is cyclic (i.e.~\(\operatorname{tr}(AB) = \operatorname{tr}(BA)\)) and linear (i.e.~\(\operatorname{tr}(\alpha A+\beta B) = \alpha\operatorname{tr}(A)+\beta\operatorname{tr}(B)\), where \(A\) and \(B\) are square matrices and \(\alpha\) and \(\beta\) complex numbers).
Moreover,
\[
  \begin{aligned}
    \operatorname{tr}|b\rangle\langle a|
    &= \sum_k \langle e_k|b\rangle\langle a|e_k\rangle
  \\&= \sum_k \langle a|e_k\rangle\langle e_k|b\rangle
  \\&= \langle a|\mathbf{1}\rangle|b\rangle
  \\&= \langle a|b\rangle.
  \end{aligned}
\]
Here, the second term can be viewed both as the sum of the diagonal elements of \(|b\rangle\langle a|\) in the \(|e_k\rangle\) basis, and as the sum of the products of two complex numbers \(\langle e_k|b\rangle\) and \(\langle a|e_k\rangle\).
We have used the decomposition of the identity, \(\sum_k|e_k\rangle\langle e_k|=\mathbf{1}\).
Given that we can decompose the identity by choosing any orthonormal basis, it is clear that the trace does \emph{not} depend on the choice of the basis.

\textbf{!!to-do: mention what this whole package of data all bundled up looks like from the categorical pov!!}

\hypertarget{some-useful-identities}{%
\subsection{Some useful identities}\label{some-useful-identities}}

\begin{itemize}
\tightlist
\item
  \(|a\rangle^\dagger = \langle a|\)
\item
  \(\langle a|^\dagger = |a\rangle\)
\item
  \((\alpha|a\rangle+\beta|b\rangle)^\dagger = \alpha^\star\langle a|+\beta^\star\langle b|\)
\item
  \((|a\rangle\langle b|)^\dagger = |b\rangle\langle a|\)
\item
  \((AB)^\dagger=B^\dagger A^\dagger\)
\item
  \((\alpha A+\beta B)^\dagger=\alpha^\star A^\dagger+\beta^\star B^\dagger\)
\item
  \((A^\dagger)^\dagger=A\)
\item
  \(\operatorname{tr}(\alpha A+ \beta B) = \alpha \operatorname{tr}(A)+\beta\operatorname{tr}(B)\)
\item
  \(\operatorname{tr}|a\rangle\langle b| = \langle b|a\rangle\)
\item
  \(\operatorname{tr}(ABC) = \operatorname{tr}(CAB) = \operatorname{tr}(BCA)\)
\end{itemize}

\hypertarget{part-foundations}{%
\part{Foundations}\label{part-foundations}}

\hypertarget{quantum-interference}{%
\section{Quantum interference}\label{quantum-interference}}

\begin{quote}
About complex numbers, called \textbf{probability amplitudes}, that, unlike probabilities, can cancel each other out, leading to \textbf{quantum interference}, and consequently qualitatively new ways of processing information.
\end{quote}

The classical theory of computation does not usually refer to physics.
Pioneers such as Alan Turing, Alonzo Church, Emil Post, and Kurt Gödel managed to capture the correct classical theory by intuition alone and, as a result, it is often falsely assumed that its foundations are self-evident and purely abstract.
They are not!\footnote{Computation is a physical process. Computation is a physical process. Computation is \ldots{}}

The concepts of information and computation can be properly formulated only in the context of a physical theory --- information is stored, transmitted and processed always by \emph{physical} means.
Computers are physical objects and computation is a physical process.
Indeed, any computation, classical or quantum, can be viewed in terms of physical experiments, which produce \textbf{outputs} that depend on initial preparations called \textbf{inputs}.
Once we abandon the classical view of computation as a purely logical notion independent of the laws of physics it becomes clear that whenever we improve our knowledge about physical reality, we may also gain new means of computation.
Thus, from this perspective, it is not very surprising that the discovery of quantum mechanics in particular has changed our understanding of the nature of computation.
In order to explain what makes quantum computers so different from their classical counterparts, we begin with the rudiments of quantum theory.

Some of what we say in this chapter will be repeated in later chapters, but usually in much more detail.
Feel free to think of this chapter as a sort of ``aeroplane tour'' of the rudiments, knowing that we will soon land on the ground to go out exploring by foot.

\hypertarget{two-basic-rules}{%
\subsection{Two basic rules}\label{two-basic-rules}}

Quantum theory, at least at some instrumental level, can be viewed as a modification of probability theory.
We replace positive numbers (probabilities) with complex numbers \(z\) (called \textbf{probability amplitudes}) such that the squares of their absolute values, \(|z|^2\), are interpreted as probabilities.

\begin{idea}
The correspondence between probability amplitudes \(z\) and probabilities \(|z|^2\) is known as \textbf{Born's Rule}.

\end{idea}

The rules for combining amplitudes are very reminiscent of the rules for combining probabilities:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Whenever something can happen in a sequence of independent steps, we multiply the amplitudes of each step.
\end{enumerate}

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-3-1} \end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Whenever something can happen in several alternative ways, we add the amplitudes for each separate way.
\end{enumerate}

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-4-1} \end{center}

That's it!
These two rules are basically all you need to manipulate amplitudes in any physical process, no matter how complicated.\footnote{We will, however, amend the two rules later on when we touch upon particle statistics.}
They are universal and apply to any physical system, from elementary particles through atoms and molecules to white dwarfs stars.
They also apply to information, since, as we have already emphasised, information is physical.
The two rules look deceptively simple but, as you will see in a moment, their consequences are anything but trivial.

\hypertarget{quantum-interference-the-failure-of-probability-theory}{%
\subsection{Quantum interference: the failure of probability theory}\label{quantum-interference-the-failure-of-probability-theory}}

Modern mathematical probability theory is based on three axioms, proposed by Andrey Nikolaevich Kolmogorov (1903--1987) in his monograph with the impressive German title \emph{Grundbegriffe der Wahrscheinlichkeitsrechnung} (``Foundations of Probability Theory'').
The \textbf{Kolmogorov axioms} are simple and intuitive:\footnote{I always found it an interesting coincidence that the two basic ingredients of modern quantum theory, namely probability and complex numbers, were discovered by the same person, an extraordinary man of many talents: a gambling scholar by the name of Girolamo Cardano (1501--1576).}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Once you identify all elementary outcomes, or events, you may then assign probabilities to them.
\item
  Probability is a number between \(0\) and \(1\), and an event which is certain has probability \(1\).
\item
  Last but not least, the probability of any event can be calculated using a deceptively simple rule --- the \textbf{additivity axiom}:
  \emph{Whenever an event can occur in several mutually exclusive ways, the probability for the event is the sum of the probabilities for each way considered separately.}
\end{enumerate}

Obvious, isn't it?
So obvious, in fact, that probability theory was accepted as a mathematical framework theory, a language that can be used to describe actual physical phenomena.
Physics should be able to identify elementary events and assign numerical probabilities to them.
Once this is done we may revert to mathematical formalism of probability theory.
The Kolmogorov axioms will take care of the mathematical consistency and will guide us whenever there is a need to calculate probabilities of more complex events.
This is a very sensible approach, apart from the fact that it does not always work!
Today, we know that probability theory, as ubiquitous as it is, fails to describe many common quantum phenomena.
In order to see the need for quantum theory let us consider a simple experiment in which probability theory fails to give the right predictions.

\hypertarget{the-double-slit-experiment}{%
\subsubsection{The double slit experiment}\label{the-double-slit-experiment}}

In a double slit experiment, a particle emitted from a source \(S\) can reach the detector \(D\) by taking two different paths, e.g.~through an upper or a lower slit in a barrier between the source and the detector.
After sufficiently many repetitions of this experiment we can evaluate the frequency of clicks in the detector \(D\) and show that it is inconsistent with the predictions based on probability theory.
Let us use the quantum approach to show how the discrepancy arises.

The particle emitted from a source \(S\) can reach detector \(D\) by taking two different paths, with amplitudes \(z_1\) and \(z_2\) respectively.
We may say that the upper slit is taken with probability \(p_1=|z_1|^2\) and the lower slit with probability \(p_2=|z_2|^2\).
These are two mutually exclusive events.
With the two slits open, probability theory declares (by the additivity axiom) that the particle should reach the detector with probability \(p_1+p_2= |z_1|^2+|z_2|^2\).
But this is not what happens experimentally!

Following the ``quantum rules'', first we add the amplitudes and then we square the absolute value of the sum to get the probability.
Thus, the particle will reach the detector with probability
\[
  \begin{aligned}
    p &= |z|^2
  \\& = |z_1 + z_2|^2
  \\& = |z_1|^2 + |z_2|^2
        + z_1^\star z_2 + z_1 z_2^\star
  \\& = p_1 + p_2
        + |z_1||z_2|\left(
          e^{i(\varphi_2-\varphi_1)}
          + e^{-i(\varphi_2-\varphi_1)}
        \right)
  \\& = p_1 + p_2
        + 2 \sqrt{p_1 p_2} \cos(\varphi_2-\varphi_1)
  \\& = p_1 + p_2 + \text{interference terms}
  \end{aligned}
\tag{1.2.1.1}
\]
where we have expressed the amplitudes in their polar forms
\[
\begin{aligned}
  z_1 &= |z_1|e^{i\varphi_1}
\\z_2 &= |z_2|e^{i\varphi_2}.
\end{aligned}
\]
The appearance of the interference terms marks the departure from the classical theory of probability.
The probability of any two seemingly mutually exclusive events is the sum of the probabilities of the individual events, \(p_1 + p_2\), \emph{modified} by the \textbf{interference term} \(2 \sqrt{p_1p_2}\cos(\varphi_2-\varphi_1)\).
Depending on the \textbf{relative phase} \(\varphi_2-\varphi_1\), the interference term can be either negative (which we call \textbf{destructive} interference) or positive (\textbf{constructive} interference), leading to either suppression or enhancement of the total probability \(p\).

The algebra is simple; our focus is on the physical interpretation.
Firstly, note that the important quantity here is the \emph{relative} phase \(\varphi_2-\varphi_1\) rather than the individual values \(\varphi_1\) and \(\varphi_2\).
This observation is not trivial at all: if a particle reacts only to the difference of the two phases, each pertaining to a separate path, then it must have, somehow, experienced the two paths, right?
Thus we cannot say that the particle has travelled \emph{either} through the upper or the lower slit, because it has travelled through \emph{both}.
In the same way, quantum computers follow, in some tangible way, \emph{all} computational paths simultaneously, producing answers that depend on \emph{all} these alternative calculations.
Weird, but this is how it is!

Secondly, what has happened to the additivity axiom in probability theory?
What was wrong with it?
One problem is the assumption that the processes of taking the upper or the lower slit are mutually exclusive; in reality, as we have just mentioned, the two transitions \emph{both occur}, simultaneously.
However, we cannot learn this from probability theory, nor from any other \emph{a priori} mathematical construct.\footnote{According to the philosopher Karl Popper (1902--1994) a theory is genuinely scientific only if it is possible, in principle, to establish that it is false. Genuinely scientific theories are never finally confirmed because no matter how many confirming observations have been made observations that are inconsistent with the empirical predictions of the theory are always possible.}

\begin{idea}
There is no fundamental reason why Nature should conform to the additivity axiom.

\end{idea}

We find out how nature works by making intelligent guesses, running experiments, checking what happens and formulating physical theories.
If our guess disagrees with experiments then it is wrong, so we try another intelligent guess, and another, etc.
Right now, quantum theory is the best guess we have: it offers good explanations and predictions that have not been falsified by any of the existing experiments.
This said, rest assured that one day quantum theory \emph{will} be falsified, and then we will have to start guessing all over again.

\hypertarget{superpositions}{%
\subsection{Superpositions}\label{superpositions}}

Amplitudes are more than just tools for calculating probabilities: they tell us something about physical reality.
When we deal with probabilities, we may think about them as numbers that quantify our lack of knowledge.
Indeed, when we say that a particle goes through the upper or the lower slit with some respective probabilities, it does go through one of the two slits, we just do not know which one.
In contrast, according to quantum theory, a particle that goes through the upper and the lower slit with certain amplitudes does explore \emph{both} of the two paths, not just one of them.
This is a statement about a real physical situation --- about something that is out there and something we can experiment with.

\begin{idea}
The assumption that the particle goes through one of the two slits, but just that we do not know which one, is inconsistent with \emph{many} experimental observations.

\end{idea}

We have to accept that, apart from some easy to visualise states, known as the \textbf{basis states}, (such as the particle at the upper slit or the particle at the lower slit), there are infinitely many other states, all of them equally real, in which the particle is in a \textbf{superposition} of the two basis states.
This rather bizarre picture of reality is the best we have at the moment, and it works, at least for now.

Physicists write such superposition states as\footnote{Dirac notation will likely be familiar to physicists, but may look odd to mathematicians or computer scientists. Love it or hate it (and I suggest the former), the notation is so common that you simply have no choice but to learn it, especially if you want to study anything related to quantum theory.}
\[
  |\psi\rangle=\alpha |\text{at the upper slit}\rangle +\beta |\text{at the lower slit}\rangle,
\]
meaning the particle at the upper slit with amplitude \(\alpha\) and at the lower slit with amplitude \(\beta\).
Mathematically, you can think about this expression as a vector \(|\psi\rangle\) in a two-dimensional complex vector space written in terms of the two basis vectors \(|\text{at the upper slit}\rangle\) and \(|\text{at the lower slit}\rangle\).
You could also write this vector as a column vector with two complex entries \(\alpha\) and \(\beta\), but then you would have to explain the \emph{physical meaning} of the basis states.
Here, we use the \(|\cdot\rangle\) notation, introduced by Paul Dirac in the early days of the quantum theory as a useful way to write and manipulate vectors.
In Dirac notation you can put into the box \(|\phantom{0}\rangle\) anything that serves to specify what the vector is: it could be \(|\uparrow\rangle\) for spin up and \(|\downarrow\rangle\) for spin down, or \(|0\rangle\) for a quantum bit holding logical \(0\) and \(|1\rangle\) for a quantum bit holding logical \(1\), etc.
As we shall see soon, there is much more to this notation, and learning to manipulate it will help you greatly.

\hypertarget{interferometers}{%
\subsection{Interferometers}\label{interferometers}}

Many modern interference experiments are performed using internal degrees of freedom of atoms and ions.
For example, \textbf{Ramsey interferometry}, named after American physicist Norman Ramsey, is a generic name for an interference experiment in which atoms are sent through two separate resonant interaction zones, known as \textbf{Ramsey zones}, separated by an intermediate dispersive interaction zone.

Many beautiful experiments of this type were carried out in the 1990s in Serge Haroche's lab at the Ecole Normale Supérieure in Paris.
Rubidium atoms were sent through two separate interaction zones (resonant interaction in the first and the third cavity) separated by a phase inducing dispersive interaction zone (the central cavity).
The atoms were subsequently measured, via a selective ionisation, and found to be in one of the two preselected energy states, here labeled as \(|0\rangle\) and \(|1\rangle\).
The fraction of atoms found in states \(|0\rangle\) or \(|1\rangle\) showed a clear dependence on the phase shifts induced by the dispersive interaction in the central cavity.
In 2012, Serge Haroche and Dave Wineland shared the Nobel Prize in physics for ``ground-breaking experimental methods that enable measuring and manipulation of individual quantum systems.''



\begin{figure}[H]

{\centering \includegraphics{iqis-book_files/figure-latex/ramsey-figure-1} 

}

\caption{A schematic diagram of a Ramsey interference experiment.}\label{fig:ramsey-figure}
\end{figure}

The three rectangular boxes in Figure \ref{fig:ramsey-figure} represent three cavities, each cavity being an arrangement of mirrors which traps electromagnetic field (think about standing waves in between two mirrors).
The oval shapes represent rubidium atoms with two preselected energy states labelled as \(|0\rangle\) and \(|1\rangle\).
Each atom is initially prepared in a highly excited internal energy state \(|0\rangle\) and zips through the three cavities, from the left to the right.
In each cavity the atom interacts with the cavity field.
The first and the third cavities are, for all theoretical purposes, identical: their frequencies are tuned to the resonant frequency of the atom, and the atom exchanges energy with the cavity, going back and forth between its energy states \(|0\rangle\) and \(|1\rangle\).
In contrast, in the second (central) cavity, the atom undergoes the so-called dispersive interaction: it is too off-resonance to exchange energy with the field but its energy states ``feel'' the field and acquire phase shifts.
After experiencing this well timed sequence of resonant--dispersive--resonant interactions, the energy of the atom is measured and the atom is found to be either in state \(|0\rangle\) or state \(|1\rangle\).
The fraction of atoms found in state \(|0\rangle\) or \(|1\rangle\) shows a clear dependence on the phase shifts induced by the dispersive interaction in the central cavity.

We can understand this interference better if we follow the two internal states of the atom as it moves through the three cavities.



\begin{figure}[H]

{\centering \includegraphics{iqis-book_files/figure-latex/ramsey-figure-2-1} 

}

\caption{The Ramsey interferometer represented as an abstract diagram. It should be read from left to right. The line segments represent transitions between the two states, \(|0\rangle\) and \(|1\rangle\), and the numbers are the corresponding probability amplitudes.}\label{fig:ramsey-figure-2}
\end{figure}

Suppose we are interested in the probability that the atom, initially in state \(|0\rangle\), will be found, after completing its journey through the three cavities, in state \(|1\rangle\).
As you can see in Figure \ref{fig:ramsey-figure-2}, this can happen in two ways, as indicated by the two red paths connecting the input state \(|0\rangle\) on the left with the output state \(|1\rangle\) on the right.
Again, let \(U_{ij}\) denote the probability amplitude that input \(|j\rangle\) generates output \(|i\rangle\) (for \(i,j=0,1\)).
We can see from the diagram that
\[
  \begin{aligned}
    U_{10}
    &= \frac{1}{\sqrt2} e^{i\varphi_0}\frac{1}{\sqrt2} + \frac{1}{\sqrt2} e^{i\varphi_1}\frac{-1}{\sqrt2}
  \\&= \frac12 e^{i\varphi_0} - \frac12 e^{i\varphi_1}
  \\&= -ie^{i\frac{\varphi_0+\varphi_1}{2}}\sin\frac{\varphi}{2},
  \end{aligned}
\]
where \(\varphi = \varphi_1-\varphi_0\) is the relative phase.
The corresponding probability reads\footnote{From the classical probability theory perspective the resonant interaction induces a random switch between \(|0\rangle\) and \(|1\rangle\) (why?) and the dispersive interaction has no effect on these two states (why?). Hence, one random switch followed by another random switch gives exactly a single random switch, which gives \(\frac12\) for the probability that input \(|0\rangle\) becomes output \(|1\rangle\).}
\[
  \begin{aligned}
    P_{10}
    &= \vert U_{10}\vert^2
  \\&= \left\vert \frac12 e^{i\varphi_0} - \frac12 e^{i\varphi_1}\right\vert^2
  \\&= \frac12 - \frac12\cos\varphi.
  \end{aligned}
\]
You should recognise the first term, \(\frac12\), as the ``classical'' probability and the second one, \(-\frac12\cos\varphi\), as the interference term.
We can repeat such calculations for any other pair of input--output states.
This approach works fine here but, in general, tracking all possible paths in evolving quantum systems can become messy when the number of input and output states increases.
There is, however, a neat way of doing it via matrix multiplication.

The effect of each interaction on atomic states can be described by a matrix of transition amplitudes, as illustrated in Figure \ref{fig:interference-matrix}.
Then a sequence of independent interactions is described by the product of these matrices.
\[
  \begin{aligned}
    U &=
    \begin{bmatrix}
      \frac{1}{\sqrt2} & \frac{1}{\sqrt2}
    \\\frac{1}{\sqrt2} & \frac{-1}{\sqrt2}
    \end{bmatrix}
    \begin{bmatrix}
      e^{i\varphi_0} & 0
    \\0 & e^{i\varphi_1}
    \end{bmatrix}
    \begin{bmatrix}
      \frac{1}{\sqrt2} & \frac{1}{\sqrt2}
    \\\frac{1}{\sqrt2} & \frac{-1}{\sqrt2}
    \end{bmatrix}
  \\&= e^{i\frac{\varphi_0+\varphi_1}{2}}
    \begin{bmatrix}
      \cos\frac{\varphi}{2} & -i\sin\frac{\varphi}{2}
    \\\ -i\sin\frac{\varphi}{2}& \cos\frac{\varphi}{2}
    \end{bmatrix},
  \end{aligned}
\]
where \(\varphi = \varphi_1-\varphi_0\), as before.



\begin{figure}[H]

{\centering \includegraphics{iqis-book_files/figure-latex/interference-matrix-1} 

}

\caption{The Ramsey interferometer represented as an abstract diagram (matrix approach). Here we have omitted the \(|0\rangle\) and \(|1\rangle\) labels, just to simply the diagram. We also ignore the global phase factor of \(e^{i\frac{\varphi_0+\varphi_1}{2}}\).}\label{fig:interference-matrix}
\end{figure}

In general, quantum operation \(A\) followed by another quantum operation \(B\) is a quantum operation described by the matrix product \(BA\) (watch the order of matrices).
Indeed, the expression \((BA)_{ij}=\sum_k B_{ik}A_{kj}\) is the sum over amplitudes that input \(|j\rangle\) generates output \(|i\rangle\) via a specific intermediate state \(|k\rangle\).
As you can see, the matrix approach is a wonderful bookkeeping tool for in one swap it takes care of both multiplying and adding probability amplitudes corresponding to all the contributing paths.

\hypertarget{qubits-gates-and-circuits}{%
\subsection{Qubits, gates, and circuits}\label{qubits-gates-and-circuits}}

Atoms, trapped ions, molecules, nuclear spins and many other quantum objects with two pre-selected basis states labeled as \(|0\rangle\) and \(|1\rangle\) (from now on we will call such objects quantum bits or \textbf{qubits}) can be used to implement simple quantum interference.
There is no need to learn about physics behind these diverse technologies if all you want is to understand the basics of quantum theory.
We may now conveniently forget about any specific experimental realisation of a qubit and represent a generic \textbf{single qubit interference} graphically as a \textbf{circuit diagram}:\footnote{Do not confuse the interference diagrams of Figure \ref{fig:ramsey-figure} and Figure \ref{fig:interference-matrix} with the circuit diagram. In the circuit diagrams, which we will use a lot from now on, a single qubit is represented by a single line.}

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-5-1} \end{center}

This diagram should be read from left to right.
The horizontal line represents a qubit that is inertly carried from one quantum operation to another. We often call this line a \textbf{quantum wire}.
The wire may describe translation in space (e.g.~atoms travelling through cavities) or translation in time (e.g.~a sequence of operations performed on a trapped ion).
The boxes or circles on the wire represent elementary quantum operations, called \textbf{quantum logic gates}.
Here we have two types of gates: two Hadamard gates \(H\) (think about resonant interactions) and one phase gate \(P_\varphi\) (think about dispersive interaction), where\footnote{Global phase factors are irrelevant, it is the relative phase \(\varphi =\varphi_1-\varphi_0\) that matters. In a single qubit phase gate we usually factor out \(e^{i\varphi_0}\), which leaves us with the two diagonal entries: \(1\) and \(e^{i\varphi}\).}
\[
H=\begin{bmatrix}
    \frac{1}{\sqrt2} & \frac{1}{\sqrt2}
  \\\frac{1}{\sqrt2} & \frac{-1}{\sqrt2}
  \end{bmatrix}
  \quad\text{and}\quad
P_\varphi  = \begin{bmatrix}
    1 & 0
  \\0 & e^{i\varphi}
  \end{bmatrix}.
\]

The input qubits appear as state vectors on the left side of circuit diagrams, and the output qubits as state vectors on the right.
The product of the three matrices \(HP_\varphi H\) (see Figure \ref{fig:interference-matrix}) describes the action of the whole circuit: it maps input state vectors to output state vectors\footnote{\(HP_\varphi H =\begin{bmatrix}\cos\frac{\varphi}{2} & -i\sin\frac{\varphi}{2}\\\ -i\sin\frac{\varphi}{2}& \cos\frac{\varphi}{2}\end{bmatrix}\)}:
\[
  \begin{array}{lcr}
    |0\rangle & \longmapsto & \cos\frac{\varphi}{2}|0\rangle - i\sin\frac{\varphi}{2}|1\rangle,
  \\|1\rangle
    & \longmapsto
    &- i\sin\frac{\varphi}{2}|0\rangle + \cos\frac{\varphi}{2}|1\rangle.
  \end{array}
\]

\hypertarget{quantum-decoherence}{%
\subsection{Quantum decoherence}\label{quantum-decoherence}}

We do need quantum theory to describe many physical phenomena, but, at the same time, there are many other phenomena where the classical theory of probability works pretty well.
We hardly see quantum interference on a daily basis.
Why?
The answer is \textbf{decoherence}.
The addition of probability amplitudes, rather than probabilities, applies to physical systems which are completely isolated.
However, it is almost impossible to isolate a complex quantum system, such as a quantum computer, from the rest of the world.
There will always be spurious interactions with the environment, and when we add amplitudes, we have to take into account not only different configurations of the physical system at hand, but also different configurations of the environment.

For example, consider an isolated system composed of a quantum computer and its environment.
The computer is prepared in some input state \(I\) and generates output \(O\).
Let us look at the following two scenarios:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \emph{The computer is isolated and quantum computation does not affect the environment.}
  The computer and the environment evolve independently from each other and, as a result, the environment does not hold any physical record of how the computer reached output \(O\).
  In this case we add the amplitudes for each of the two alternative computational paths.
\end{enumerate}

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-6-1} \end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  \emph{Quantum computation affects the environment.}
  The environment now holds a physical record of how the computer reached output \(O\), which results in two final states of the composed system (computer + environment) which we denote \(O_1\) and \(O_2\).
  We add the probabilities for each of the two alternative computational paths.
\end{enumerate}

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-7-1} \end{center}

When quantum computation affects the environment, we have to include the environment in our analysis for it now takes part in the computation.
Depending on which computational path was taken, the environment may end up in two distinct states.
The computer itself may show output \(O\), but when we include the environment we have not one, but two outputs, \(O_1\) and \(O_2\), denoting, respectively, ``computer shows output \(O\) and the environment knows that path \(1\) was taken'' and ``computer shows output \(O\) and the environment knows that path \(2\) was taken''.
There are no alternative ways of reaching \(O_1\) or \(O_2\), hence there is no interference, and the corresponding probabilities read \(p_1=|z_1|^2\) for \(O_1\), and \(p_2=|z_2|^2\) for \(O_2\).
The probability that the computer shows output \(O\), regardless the state of the environment, is the sum of of the two probabilities: \(p=p_1+p_2\).
We have lost the interference term and any advantages of quantum computation along with it.
In the presence of decoherence, the interference formula in Equation (1.2.1.1) is modified and reads
\[
p
= p_1 + p_2 + 2 v \sqrt{p_1 p_2}\cos (\varphi_2-\varphi_1),
\]
where the parameter \(v\), called the \textbf{visibility} of the interference pattern, ranges from \(0\) (the environment can perfectly distinguish between the two paths, total decoherence, no interference) to \(1\) (the environment cannot distinguish between the two paths, no decoherence, full interference), with the values in between corresponding to partial decoherence.

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-8-1} \end{center}

We shall derive this formula later on, and you will see that \(v\) quantifies the degree of distinguishability between \(O_1\) and \(O_2\).
The more the environment knows about which path was taken the less interference we see.

\begin{idea}
Decoherence suppresses quantum interference.

\end{idea}

Decoherence is chiefly responsible for our classical description of the world --- without interference terms we may as well add probabilities instead of amplitudes.
While decoherence is a serious impediment to building quantum computers, depriving us of the power of quantum interference, it is not all doom and gloom: there are clever ways around decoherence, such as quantum error correction and fault-tolerant methods we will meet later.

\hypertarget{computation-deterministic-probabilistic-and-quantum}{%
\subsection{Computation: deterministic, probabilistic, and quantum}\label{computation-deterministic-probabilistic-and-quantum}}

Take one physical bit or a qubit.
It has two logical states: \(|0\rangle\) and \(|1\rangle\).
Bring another qubit and the combined systems has four logical states \(|00\rangle, |01\rangle,|10\rangle\) and \(|11\rangle\).
In general \(n\) qubits will give us \(2^n\) states representing all possible binary strings of length \(n\).
It is important to use subsystems --- here qubits --- rather than one chunk of matter, for operating on at most \(n\) qubits we can reach any of the \(2^n\) states of the composed system.
Now, let the qubits interact in a controllable fashion.
We are computing.
Think about computation as a physical process that evolves a prescribed initial configuration of a computing machine, called \textbf{\(\texttt{INPUT}\)}, into some final configuration, called \textbf{\(\texttt{OUTPUT}\)}.
We shall refer to the configurations as \textbf{states}.
Figure \ref{fig:deterministic-computation} shows five consecutive computational steps performed on four distinct states.

\begin{figure}[H]

{\centering \includegraphics{iqis-book_files/figure-latex/deterministic-computation-1} 

}

\caption{Deterministic computation.}\label{fig:deterministic-computation}
\end{figure}

That computation was \textbf{deterministic}: every time you run it with the same input, you get the same output.
But a computation does not have to be deterministic --- we can augment a computing machine by allowing it to ``toss an unbiased coin'' and to choose its steps randomly.
It can then be viewed as a directed\footnote{So we read left to right, and omit the arrowheads.} tree-like graph where each node corresponds to a state of the machine, and each edge represents one step of the computation, as shown in Figure \ref{fig:probabilistic-computation}

\begin{figure}[H]

{\centering \includegraphics{iqis-book_files/figure-latex/probabilistic-computation-1} 

}

\caption{Probabilistic computation.}\label{fig:probabilistic-computation}
\end{figure}

The computation starts from some initial state (\(\texttt{INPUT}\)) and it subsequently branches into other nodes representing states reachable with non-zero probability from the initial state.
The probability of a particular final state (\(\texttt{OUTPUT}\)) being reached is equal to the sum of the probabilities along all mutually exclusive paths which connect the initial state with that particular state.
Figure \ref{fig:probabilistic-computation} shows only two computational paths, but, in general, there could be many more paths (here, up to 256) contributing to the final probability.
Quantum computation can be represented by a similar graph, as in \ref{fig:quantum-computation}.

\begin{figure}[H]

{\centering \includegraphics{iqis-book_files/figure-latex/quantum-computation-1} 

}

\caption{Quantum computation.}\label{fig:quantum-computation}
\end{figure}

For quantum computations, we associate with each edge in the graph the probability \emph{amplitude} that the computation follows that edge.
The probability amplitude of a particular path to be followed is the product of amplitudes pertaining to transitions in each step.
The probability amplitude of a particular final state being reached is equal to the sum of the amplitudes along all mutually exclusive paths which connect the initial state with that particular state:
\[
  z = \sum_{\mathrm{all\,paths}\,k} z_k.
\]
The resulting probability, as we have just seen, is the sum of the probabilities pertaining to each computational path \(p_k\) modified by the interference terms:
\[
  \begin{aligned}
    p
    &= |z|^2
  \\&= \sum_{k,j} z_j^\star z_k
  \\&= \sum_k p_k + \sum_{k\ne j} \sqrt{p_k p_j}\cos(\varphi_k-\varphi_j).
  \end{aligned}
\]

\begin{idea}
Quantum computation can be viewed as a complex multi-particle quantum interference involving many computational paths through a computing device.
The art of quantum computation is to shape quantum interference, through a sequence of computational steps, enhancing probabilities of correct outputs and suppressing probabilities of the wrong ones.

\end{idea}

\hypertarget{computational-complexity}{%
\subsection{Computational complexity}\label{computational-complexity}}

Is there a compelling reason why we should care about quantum computation?
It may sound like an extravagant way to compute something that can be computed anyway.
Indeed, your standard laptop, given enough time and memory, can simulate pretty much any physical process.
In principle, it can also simulate any quantum interference and compute everything that quantum computers can compute.
The snag is, this simulation, in general, is very inefficient.
And efficiency does matter, especially if you have to wait more than the age of the Universe for your laptop to stop and deliver an answer!\footnote{The age of the Universe is currently estimated at 13.772 billion years.}

In order to solve a particular problem, computers (classical or quantum) follow a precise set of instructions called an \textbf{algorithm}.
Computer scientists quantify the efficiency of an algorithm according to how rapidly its running time, or the use of memory, increases when it is given ever larger inputs to work on.
An algorithm is said to be \textbf{efficient} if the number of elementary operations taken to execute it increases no faster than a polynomial function of the size of the input.\footnote{Note that the technological progress alone, such as increasing the speed of classical computers, will never turn an inefficient algorithm (exponential scaling) into an efficient one (polynomial scaling). Why?}
We take the input size to be the total number of binary digits (bits) needed to specify the input.
For example, using the algorithm taught in elementary school, one can multiply two \(n\) digit numbers in a time that grows like the number of digits squared, \(n^2\).
In contrast, the fastest-known method for the reverse operation --- factoring an \(n\)-digit integer into prime numbers --- takes a time that grows exponentially, roughly as \(2^n\).
That is considered inefficient.

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-9-1} \end{center}

The class of problems that can be solved by a deterministic computer in polynomial time is represented by the capital letter \(\texttt{P}\), for \emph{polynomial} time.
The class of problems that can be solved in polynomial time by a probabilistic computer is called \(\texttt{BPP}\), for \emph{bounded-error probabilistic polynomial} time.
It is clear that \(\texttt{BPP}\) contains \(\texttt{P}\), since a deterministic computation is a special case of a probabilistic computation in which we never consult the source of randomness.
When we run a probabilistic (a.k.a. randomised) computation many times on the same input, we will not get the same answer every time, but the computation is useful if the probability of getting the right answer is high enough.
Finally, the complexity class \(\texttt{BQP}\), for \emph{bounded-error quantum polynomial}, is the class of problems that can be solved in polynomial time by a quantum computer.

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-10-1} \end{center}

Since a quantum computer can easily generate random bits and simulate a probabilistic classical computer, \(\texttt{BQP}\) certainly contains the class \(\texttt{BPP}\).
Here we are interested in problems that are in \(\texttt{BQP}\) but not known to be in \(\texttt{BPP}\).
The most popular example of such a problem is factoring.

A quantum algorithm, discovered by Peter Shor in 1994, can factor \(n\)-digit numbers in a number of steps that grows only as \(n^2\), as opposed to the \(2^n\) that we have classically.\footnote{It must be stressed that not all quantum algorithms are so efficient, in fact many are no faster than their classical counterparts. Which particular problems will lend themselves to quantum speed-ups is an open question.}
Since the intractability of factorisation underpins the security of many methods of encryption, Shor's algorithm was soon hailed as the first `killer application' for quantum computation: something very useful that only a quantum computer could do.
Since then, the hunt has been on for interesting things for quantum computers to do, and at the same time, for the scientific and technological advances that could allow us to build quantum computers.

\hypertarget{outlook}{%
\subsection{Outlook}\label{outlook}}

When the physics of computation was first investigated, starting in the 1960s, one of the main motivations was a fear that quantum-mechanical effects might place fundamental bounds on the accuracy with which physical objects could render the properties of the abstract entities, such as logical variables and operations, that appear in the theory of computation.
It turned out, however, that quantum mechanics itself imposes no significant limits, but does break through some of those that classical physics imposed.
The quantum world has a richness and intricacy that allows new practical technologies, and new kinds of knowledge.
In this course we will merely scratch the surface of the rapidly developing field of quantum computation.
We will concentrate mostly on the fundamental issues and skip many experimental details.
However, it should be mentioned that quantum computing is a serious possibility for future generations of computing devices.
At present it is not clear how and when fully-fledged quantum computers will eventually be built;
but this notwithstanding, the quantum theory of computation already plays a much more fundamental role in the scheme of things than its classical predecessor did.
I believe that anyone who seeks a fundamental understanding of either physics, computation or logic must incorporate its new insights into their world view.

\hypertarget{remarks-and-exercises-1}{%
\subsection{\texorpdfstring{\emph{Remarks and exercises}}{Remarks and exercises}}\label{remarks-and-exercises-1}}

\hypertarget{a-historical-remark}{%
\subsubsection{A historical remark}\label{a-historical-remark}}

Back in 1926, Max Born simply postulated the connection between amplitudes and probabilities, but did not get it quite right on his first attempt.
In the original paper\footnote{Max Born, ``Zur Quantenmechanik der Stoßvorgänge'', \emph{Zeitschrift für Physik} \textbf{37} (1926), 893--867.} proposing the probability interpretation of the state vector (wavefunction) he wrote:

\begin{quote}
\ldots{} If one translates this result into terms of particles only one interpretation is possible.
\(\Theta_{\eta,\tau,m}(\alpha,\beta,\gamma)\) {[}the wavefunction for the particular problem he is considering{]} gives the probability\(^*\) for the electron arriving from the \(z\) direction to be thrown out into the direction designated by the angles \(\alpha,\beta,\gamma\)\ldots{}

\(^*\) Addition in proof: More careful considerations show that the probability is proportional to the square of the quantity \(\Theta_{\eta,\tau,m}(\alpha,\beta,\gamma)\).
\end{quote}

\hypertarget{modifying-the-born-rule}{%
\subsubsection{Modifying the Born rule}\label{modifying-the-born-rule}}

Suppose that we modified the Born rule, so that probabilities were given by the absolute values of amplitudes \emph{raised to power \(p\)} (for some \(p\) not necessarily equal to \(2\)).
Then admissible physical evolutions would still have to preserve the normalisation of probability: mathematically speaking, they would have to be isometries of \(p\)-norms.

Recall that the \(p\)-norm of vector \(v\), with components \(v_1, v_2,\ldots, v_n\), is defined as
\[
  \sqrt[{}^p]{|v_1|^p + |v_2|^p + \ldots + |v_n|^p}.
\]
It is clear that any permutation of vector components and multiplication by phase factors (i.e.~unit complex numbers) will leave any \(p\)-norm unchanged.
It turns out that these complex permutations are the \emph{only} isometries, except for \emph{one} special case!
For \(p=2\), the isometries are unitary operations, which form a continuous group; in all other cases we are restricted to discrete permutations.
We do not have to go into details of the proof since we can \emph{see} this result.



\begin{figure}[H]

{\centering \includegraphics{iqis-book_files/figure-latex/p-norm-unit-spheres-1} 

}

\caption{The unit spheres in the \(p\)-norm for \(p=1,2,42,\infty\).}\label{fig:p-norm-unit-spheres}
\end{figure}

In particular, the image of the unit sphere must be preserved under probability preserving operations.
As we can see in Figure \ref{fig:p-norm-unit-spheres}, the \(2\)-norm is special because of its rotational invariance --- the probability measure picks out no preferred basis in the space of state vectors.
Moreover, it respects unitary operations and does not restrict them in any way.
If the admissible physical evolutions were restricted to discrete symmetries, e.g.~permutations, then there would be no continuity, and no concept of ``time'' as we know it.

\hypertarget{complex-numbers}{%
\subsubsection{Complex numbers}\label{complex-numbers}}

Complex numbers have many applications in physics, however, not until the advent of quantum theory was their ubiquitous and fundamental role in the description of the actual physical world so evident.
Even today, their profound link with probabilities appears to be a rather mysterious connection.
Mathematically speaking, the set of complex numbers is a field. This is an important algebraic structure used in almost all branches of mathematics.
You do not have to know much about algebraic fields to follow these lectures, but still, you should know the basics.
Look them up.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  The set of rational numbers and the set of real numbers are both fields, but the set of integers is not. Why?
\item
  What does it mean to say that the field of complex numbers is \textbf{algebraically closed}?
\item
  Evaluate each of the following quantities:
  \[
   1+e^{-i\pi},
   \quad
   |1+i|,
   \quad
   (1+i)^{42},
   \quad
   \sqrt{i},
   \quad
   2^i,
   \quad
   i^i.
    \]
\item
  Here is a simple proof that \(+1=-1\): \[1=\sqrt{1}=\sqrt{(-1)(-1)}=\sqrt{-1}\sqrt{-1}=i^2=-1.\] What is wrong with it?
\end{enumerate}

\hypertarget{many-computational-paths}{%
\subsubsection{Many computational paths}\label{many-computational-paths}}

A quantum computer starts calculations in some initial state, then follows \(n\) different computational paths which lead to the final output.
The computational paths are followed with probability amplitudes \(\frac{1}{\sqrt n}e^{i k \varphi}\), where \(\varphi\) is a fixed angle \(0< \varphi <2\pi\) and \(k=0,1,...n-1\).
Show that the probability of generating the output is\footnote{\(1+z+z^2+\ldots + z^n= \frac{1-z^{n+1}}{1-z}\)}
\[
  \frac{1}{n}\left\vert
    \frac{1-e^{i n\varphi}}{1-e^{i\varphi}}
  \right\vert^2
  = \frac{1}{n} \frac{\sin^2 (n\frac{\varphi}{2})}{\sin^2 (\frac{\varphi}{2})}.
\]
for \(0<\varphi<2\pi\), and \(1\) for \(\varphi=0\).
Plot the probability as a function of \(\varphi\).

\hypertarget{distant-photon-emitters}{%
\subsubsection{Distant photon emitters}\label{distant-photon-emitters}}

Imagine two distant stars, A and B, that emit \emph{identical} photons.
If you point a single detector towards them you will register a click every now and then, but you never know which star the photon came from.
Now prepare two detectors and point them towards the stars.
Assume the photons arrive with the probability amplitudes specified in Figure \ref{fig:photons-from-stars}.
Every now and then you will register a coincidence: the two detectors will fire.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Calculate the probability of a coincidence.
\item
  Now, assume that \(z\approx \frac{1}{r}e^{i\frac{2r\pi}{\lambda}}\), where \(r\) is the distance between detectors and the stars. How can we use this to measure \(r\)?
\end{enumerate}

\begin{figure}[H]

{\centering \includegraphics{iqis-book_files/figure-latex/photons-from-stars-1} 

}

\caption{Two photon detectors pointing at two stars, with the probabilities of detection labelling the arrows.}\label{fig:photons-from-stars}
\end{figure}

\hypertarget{physics-against-logic}{%
\subsubsection{Physics against logic?}\label{physics-against-logic}}

Now that we have poked our heads into the quantum world, let us see how quantum interference challenges conventional logic and leads to qualitatively different computations.
Consider the following task (which we will return to a few more times in later chapters): design a logic gate that operates on a single bit such that, when it is followed by another, identical, logic gate, the output is \emph{always} the negation of the input.
Let us call this logic gate \textbf{the square root of \(\texttt{NOT}\)}, or \(\sqrt{\texttt{NOT}}\).
A simple check, such as an attempt to construct a truth table, should persuade you that there is no such operation in logic.
It may seem reasonable to argue that since there is no such operation in logic, \(\sqrt{\texttt{NOT}}\) is impossible.
Think again!

Figure \ref{fig:sqrt-not} shows a simple computation, two identical computational steps performed on two states labelled as \(0\) and \(1\), i.e.~on one bit.
An interplay of constructive and destructive interference makes some transitions impossible and the result is the logical \(\texttt{NOT}\).
Thus, quantum theory declares, the square root of \(\texttt{NOT}\) is possible.
And it does exist!
Experimental physicists routinely construct this and many other ``impossible'' gates in their laboratories.
They are the building blocks of a quantum computer.
Quantum theory explains the behaviour of \(\sqrt{\texttt{NOT}}\), hence, reassured by the physical experiments that corroborate this theory, logicians are now entitled to propose a new logical operation \(\sqrt{\texttt{NOT}}\).
Why?
Because a faithful physical model for it exists in nature.

Write a \(2\times 2\) matrix which describes the \(\sqrt{\texttt{NOT}}\) operation.
Is there just one such a matrix?
Suppose you are given a supply of Hadamard and phase gates with tuneable phase settings.
How would you construct the \(\sqrt{\texttt{NOT}}\) gate?



\begin{figure}[H]

{\centering \includegraphics{iqis-book_files/figure-latex/sqrt-not-1} 

}

\caption{A computation that, when repeated, gives exactly \(\texttt{NOT}\). An unlabelled line means that it has probability \(1\), and the lack of a line corresponds to having probability \(0\).}\label{fig:sqrt-not}
\end{figure}

\hypertarget{quantum-bomb-tester}{%
\subsubsection{Quantum bomb tester}\label{quantum-bomb-tester}}

You have been drafted by the government to help in the demining effort in a former war-zone.\footnote{This is a slightly modified version of a bomb testing problem described by Avshalom Elitzur and Lev Vaidman in \emph{Quantum-mechanical interaction-free measurement}, Found. Phys. \textbf{47} (1993), 987-997.}
In particular, retreating forces have left very sensitive bombs in some of the sealed rooms.
The bombs are configured such that if even one photon of light is absorbed by the fuse (i.e.~if someone looks into the room), the bomb will go off.
Each room has an input and output port which can be hooked up to external devices.
An empty room will let light go from the input to the output ports unaffected, whilst a room with a bomb will explode if light is shone into the input port and the bomb absorbs even just one photon --- see Figure \ref{fig:bomb-detecting-scenario}.



\begin{figure}[H]

{\centering \includegraphics{iqis-book_files/figure-latex/bomb-detecting-scenario-1} 

}

\caption{\emph{Left} --- the passage of a photon through an empty room. \emph{Right} --- the passage of a photon through a room containing a bomb.}\label{fig:bomb-detecting-scenario}
\end{figure}

Your task is to find a way of determining whether a room has a bomb in it without blowing it up, so that specialised (limited and expensive) equipment can be devoted to defusing that particular room.
You would like to know with certainty whether a particular room had a bomb in it.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  To start with, consider the setup in Figure \ref{fig:mach-zehnder-bomb-tester}, where the input and output ports are hooked up in the lower arm of a Mach--Zehnder interferometer.\footnote{Read about Mach--Zehnder interferometers in \protect\hyperlink{quantum-gates}{Chapter 3}.}

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    Assume an empty room.
    Send a photon to input port \(|0\rangle\).
    Which detector, at the output port, will register the photon?
  \item
    Now assume that the room does contain a bomb.
    Again, send a photon to input port \(|0\rangle\).
    Which detector will register the photon and with which probability?
  \item
    Design a scheme that allows you --- at least some of the time --- to decide whether a room has a bomb in it without blowing it up.
    If you iterate the procedure, what is its overall success rate for the detection of a bomb without blowing it up?
  \end{enumerate}
\end{enumerate}

\begin{figure}[H]

{\centering \includegraphics{iqis-book_files/figure-latex/mach-zehnder-bomb-tester-1} 

}

\caption{The Mach--Zehnder interferometer hooked up to the bomb-testing room.}\label{fig:mach-zehnder-bomb-tester}
\end{figure}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\item
  Assume that the two beam splitters in the interferometer are different.
  Say the first beam-splitter reflects incoming light with probability \(r\) and transmits with probability \(t=1-r\), and the second one transmits with probability \(r\) and reflects with probability \(t\).
  Would the new setup improve the overall success rate of the detection of a bomb without blowing it up?
\item
  There exists a scheme, involving many beam-splitters and something called the \textbf{quantum Zeno effect}, such that the success rate for detecting a bomb without blowing it up approaches 100\%.
  Try to work it out, or find a solution on the internet.
\end{enumerate}

\hypertarget{more-time-more-memory}{%
\subsubsection{More time, more memory}\label{more-time-more-memory}}

A quantum machine has \(N\) perfectly distinguishable configurations.
What is the maximum number of computational paths connecting a specific input with a specific output after \(k\) steps of the machine?

Suppose you are using your laptop to add together amplitudes pertaining to each of the paths.
As \(k\) and \(N\) increase you may need more time and more memory to complete the task.
How does the execution time and the memory requirements grow with \(k\) and \(N\)?
In particular, will you need more time, or more memory, or both?

\hypertarget{quantum-turing-machines}{%
\subsubsection{Quantum Turing machines}\label{quantum-turing-machines}}

The classical theory of computation is essentially the theory of the universal Turing machine --- the most popular mathematical model of classical computation.
Its significance relies on the fact that, given a large but finite amount of time, the universal Turing machine is capable of any computation that can be done by any modern classical digital computer, no matter how powerful.
The concept of Turing machines may be modified to incorporate quantum computation, but we will not follow this path.
It is much easier to explain the essence of quantum computation talking about quantum logic gates and quantum Boolean networks or circuits.
The two approaches are computationally equivalent, even though certain theoretical concepts, e.g.~in computational complexity, are easier to formulate precisely using the Turing machine model.
The main advantage of quantum circuits is that they relate far more directly to proposed experimental realisations of quantum computation.

\hypertarget{polynomial-good-exponential-bad}{%
\subsubsection{Polynomial = good; exponential = bad}\label{polynomial-good-exponential-bad}}

In computational complexity the basic distinction is between polynomial and exponential algorithms.
Polynomial growth is good and exponential growth is bad, especially if you have to pay for it.
There is an old story about the legendary inventor of chess who asked the Persian king to be paid only by a grain of cereal, doubled on each of the 64 squares of a chess board.
The king placed one grain of rice on the first square, two on the second, four on the third, and he was supposed to keep on doubling until the board was full.
The last square would then have \(2^{63}=9,223,372,036,854,775,808\) grains of rice, more than has been ever harvested on planet Earth, to which we must add the grains of all previous squares, making the total number about twice as large.
If we placed that many grains in an unbroken line we would reach the nearest star Alpha Centauri, our closest celestial neighbour beyond the solar system, about \(4.4\) light-years away.\footnote{One light year (the distance that light travels through a vacuum in one year) is \(9.4607\times10^{15}\) metres.}
The moral of the story: if whatever you do requires an exponential use of resources, you are in trouble.

\hypertarget{big-o}{%
\subsubsection{Big O}\label{big-o}}

In order to make qualitative distinctions between how different functions grow we will often use the asymptotic big-\(O\) notation.
For example, suppose an algorithm running on input of size \(n\) takes \(a n^2+bn+c\) elementary steps, for some positive constants \(a, b\) and \(c\).
These constants depend mainly on the details of the implementation and the choice of elementary steps.
What we really care about is that, for large \(n\), the whole expression is dominated by its quadratic term.
We then say that the running time of this algorithm grows as \(n^2\), and we write it as \(O(n^2)\), ignoring the less significant terms and the constant coefficients.
More precisely, let \(f(n)\) and \(g(n)\) be functions from positive integers to positive reals.
You may think of \(f(n)\) and \(g(n)\) as the running times of two algorithms on inputs of size \(n\).
We say \(f=O(g)\),\footnote{\(f=O(g)\) is pronounced as ``\(f\) is big-oh of \(g\)''.} which means that \(f\) grows no faster than \(g\), if there is a constant \(c>0\) such that \(f(n)\leqslant c g(n)\) for all sufficiently large values of \(n\).
Essentially, \(f=O(g)\) is a very loose analogue of \(f \leqslant g\).
In addition to the big-\(O\) notation, computer scientists often use \(\Omega\) for lower bounds: \(f=\Omega (g)\) means \(g=O(f)\).
Again, this is a very loose analogue of \(f \geqslant g\).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  When we say that \(f(n)=O(\log n)\), why don't we have to specify the base of the logarithm?
\item
  Let \(f(n)=5n^3+1000n+50\). Is \(f(n)=O(n^3)\), or \(O(n^4)\), or both?
\item
  Which of the following statements are true?

  \begin{enumerate}
  \def\labelenumii{\alph{enumii}.}
  \tightlist
  \item
    \(n^k=O(2^n)\) for any constant \(k\)
  \item
    \(n!=O(n^n)\)
  \item
    if \(f_1=O(g)\) and \(f_2=O(g)\), then \(f_1+f_2=O(g)\).
  \end{enumerate}
\end{enumerate}

\hypertarget{imperfect-prime-tester}{%
\subsubsection{Imperfect prime tester}\label{imperfect-prime-tester}}

There exists a randomised algorithm which tests whether a given number \(N\) is prime.\footnote{Primality used to be given as the classic example of a problem in \(\texttt{BPP}\) but not \(\texttt{P}\). However, in 2002 a deterministic polynomial time test for primality was proposed by Manindra Agrawal, Neeraj Kayal, and Nitin Saxena. Thus, since 2002, primality has been in \(\texttt{P}\).}
The algorithm always returns \(\texttt{yes}\) when \(N\) is prime, and the probability it returns \(\texttt{yes}\) when \(N\) is not prime is \(\epsilon\), where \(\epsilon\) is never greater than a half (independently, each time you run the algorithm).
You run this algorithm (for the same \(N\)) \(r\) times and each time the algorithm returns \(\texttt{yes}\).
What is the probability that \(N\) is not prime?

\hypertarget{imperfect-decision-maker}{%
\subsubsection{Imperfect decision maker}\label{imperfect-decision-maker}}

Suppose a randomised algorithm solves a decision problem, returning \(\texttt{yes}\) or \(\texttt{no}\) answers.
It gets the answer wrong with a probability not greater than \(\frac12-\delta\), where \(\delta>0\) is a constant.\footnote{This result is known as the \textbf{Chernoff bound}.}.
If we are willing to accept a probability of error no larger than \(\epsilon\), then it suffices to run the computation \(r\) times, where \(r=O(\log 1/\epsilon)\).

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-11-1} \end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  If we perform this computation \(r\) times, how many possible sequences of outcomes are there?
\item
  Give a bound on the probability of any particular sequence with \(w\) wrong answers.
\item
  If we look at the set of \(r\) outcomes, we will determine the final outcome by performing a majority vote.
  This can only go wrong if \(w>r/2\).
  Give an upper bound on the probability of any single sequence that would lead us to the wrong conclusion.
\item
  Using the bound \(1-x\leqslant e^{-x}\), conclude that the probability of our coming to the wrong conclusion is upper bounded by \(e^{-2r\delta^2}\).
\end{enumerate}

\hypertarget{qubits}{%
\section{Qubits}\label{qubits}}

\begin{quote}
About \textbf{quantum bits} and \textbf{quantum circuits}, including the ``impossible'' \textbf{square root of \(\texttt{NOT}\)}, as well as an introduction to \textbf{single-qubit unitaries} and rotations of the \textbf{Bloch sphere}, and the implications concerning \textbf{universal gates}.
\end{quote}

When studying classical information theory, one single bit isn't usually the most interesting object to think about --- it's either \(0\) or \(1\).
Yet in the quantum case, just working with one ``quantum bit'' (which we call a \textbf{qubit}) opens up a whole world of interesting mathematics.
In fact, \textbf{single qubit interference} is arguably one of the fundamental building blocks for quantum computing, and deserves to be thoroughly investigated and understood.

\hypertarget{composing-quantum-operations}{%
\subsection{Composing quantum operations}\label{composing-quantum-operations}}

In order to understand something in its full complexity it is always good to start with the simplest case.
Let us take a closer look at quantum interference in the simplest possible computing machine: the one that has only two distinguishable configurations --- two quantum states --- which we label as \(|0\rangle\) and \(|1\rangle\).
We prepare the machine in some input state, usually \(|0\rangle\), and let it \textbf{evolve}: the machine undergoes a prescribed sequence of computational steps, each of which induces transitions between the two ``computational states'', \(|0\rangle\) and \(|1\rangle\).
The machine then ends in the output state \(|\psi\rangle=\alpha_0|0\rangle+\alpha_1|1\rangle\), meaning the two outputs, \(|0\rangle\) and \(|1\rangle\), are reached with probability amplitudes \(\alpha_0\) and \(\alpha_1\), respectively.
In the process of computation each computational step \(U\) (also referred to as an \textbf{operation}) sends state \(|k\rangle\) to state \(|l\rangle\), where \(k,l=0,1\), but only with some \textbf{amplitude} \(U_{lk}\).
We write this as
\[
  |k\rangle \longmapsto \sum_l U_{lk} |l\rangle.
\]
(watch out for the order of the indices).

Thus any computational step \(U\) of this machine can be described by a matrix which tabulates all the transition amplitudes:
\[
  U =
  \begin{bmatrix}
    U_{00} & U_{01}
  \\U_{10} & U_{11}
  \end{bmatrix}.
\]
The matrix element \(U_{lk}\) represents the amplitude of transition from state \(|k\rangle\) to state \(|l\rangle\) (again, watch the order of indices).
To be clear, the entries in this matrix are not any random complex numbers: their moduli squared represent transition probabilities, which in turn implies that such matrices must be \textbf{unitary}.\footnote{Recall that matrix \(U\) is called \textbf{unitary} if \[U^\dagger U = UU^\dagger = \mathbf{1}\] where the \textbf{adjoint} or \textbf{Hermitian conjugate} \(U^\dagger\) of any matrix \(U\) with complex entries \(U_{ij}\) is obtained by taking the complex conjugate of every element in the matrix and then interchanging rows and columns (\(U^\dagger_{kl}= U^\star_{lk}\)).}

We can also describe \(U\) by drawing a diagram, which contains exactly the same information as the matrix representation, but just in a different form:

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-12-1} \end{center}

Now how can we find some quantum interference to study?
Consider two computational steps, \(U\) and \(V\).
What is the amplitude that input \(|k\rangle\) will generate output \(|m\rangle\)?
We have to check all computational paths leading from input \(|k\rangle\) to output \(|m\rangle\) and add the corresponding amplitudes.
For example, as you can see in Figure \ref{fig:composition-of-two-computation-steps}, input \(|0\rangle\) and output \(|1\rangle\) are connected by the two computational paths: \(|0\rangle\mapsto|0\rangle\mapsto|1\rangle\) (amplitude \(V_{10}U_{00}\)) and \(|0\rangle\mapsto|1\rangle\mapsto|1\rangle\) (amplitude \(V_{11}U_{10}\)).
Thus the total amplitude that input \(|0\rangle\) gives output \(|1\rangle\) is the sum \(V_{10}U_{00}+V_{11}U_{10}\), and when we take the modulus squared of this expression we will see the interference term.



\begin{figure}[H]

{\centering \includegraphics{iqis-book_files/figure-latex/composition-of-two-computation-steps-1} 

}

\caption{The composition of two computational steps, \(U\) and \(V\), with the possible paths from \(|0\rangle\) to \(|1\rangle\) highlighted.}\label{fig:composition-of-two-computation-steps}
\end{figure}

In general, given \(U\) and \(V\)
\[
  \begin{aligned}
    |k\rangle
    &\longmapsto
    \sum_l U_{lk}|l\rangle
  \\|l\rangle
    &\longmapsto
    \sum_m V_{ml}|m\rangle
  \end{aligned}
\]
we can compose the two operations: we first apply \(U\), and then \(V\), to obtain
\[
  \begin{aligned}
    |k\rangle
    &\longmapsto
    \sum_l U_{lk} \left(
      \sum_m V_{ml}|m\rangle
    \right)
  \\&=
    \sum_m \left(
      \sum_l V_{ml}U_{lk}
    \right) |m\rangle
  \\&=
    \sum_m (VU)_{mk} |m\rangle.
  \end{aligned}
\]

If you want to hone your quantum intuition think about it the following way.
The amplitude that input \(|k\rangle\) evolves to \(|m\rangle\) via a specific intermediate state \(|l\rangle\) is given by \(V_{ml}U_{lk}\) (evolutions are independent so the amplitudes are multiplied).
This done, we have to sum over all possible values of \(l\) (the transition can occur in several mutually exclusive ways so the amplitudes are added) to obtain \(\sum_l V_{ml}U_{lk}\).
Thus the matrix multiplication \(VU\) (watch the order of matrices) in one swoop takes care of multiplication and addition of amplitudes corresponding to different computational paths.

\hypertarget{quantum-bits-called-qubits}{%
\subsection{Quantum bits, called ``qubits''}\label{quantum-bits-called-qubits}}

A two-state machine that we have just described in abstract terms is usually realised as a controlled evolution of a two state system, called a quantum bit or a qubit.
For example, state \(|0\rangle\) may be chosen to be the lowest energy state of an atom (the \textbf{ground state}), and state \(|1\rangle\) a higher energy state (the \textbf{excited state}).
Pulses of light of appropriate frequency, duration, and intensity can take the atom back and forth between the basis states \(|0\rangle\) and \(|1\rangle\) (implementing logical \(\texttt{NOT}\)).

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-13-1} \end{center}

Some other pulses (say, half the duration or intensity) will take the atom into states that have no classical analogue.
Such states are called \textbf{coherent superpositions} of \(|0\rangle\) and \(|1\rangle\), and represent a qubit in state \(|0\rangle\) with some amplitude \(\alpha_0\) and in state \(|1\rangle\) with some other amplitude \(\alpha_1\).
This is conveniently represented by a state vector
\[
    |\psi\rangle =
    \alpha_0|0\rangle + \alpha_1|1\rangle
    \leftrightarrow
    \begin{bmatrix}
      \alpha_0
    \\\alpha_1
    \end{bmatrix}
\]
which we can also draw graphically:

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-14-1} \end{center}

\begin{idea}
A \textbf{qubit} is a quantum system in which the Boolean states \(0\) and \(1\) are represented by a prescribed pair of normalised and mutually orthogonal quantum states labelled by \(|0\rangle\) and \(|1\rangle\).
The two states form a so-called \textbf{computational} (or \textbf{standard}) basis, and so any other state of an isolated qubit can be written as a coherent superposition
\[
  |\psi\rangle = \alpha_0|0\rangle + \alpha_1|1\rangle
\]
for some \(\alpha_0\) and \(\alpha_1\) such that \(|\alpha_0|^2 + |\alpha_1|^2 = 1\).

In practice, a qubit is typically a microscopic system, such as an atom, a nuclear spin, or a polarised photon.

\end{idea}

As we have already mentioned, any\footnote{Here we are talking about \emph{isolated} systems. As you will soon learn, a larger class of physically admissible operations is described by completely positive maps. It may sound awfully complicated but, as you will soon see, it is actually very simple.} computational step, that is, any physically admissible operation \(U\) on a qubit, is described by a \((2\times 2)\) unitary matrix \(U\).
It modifies the state of the qubit as
\[
  |\psi\rangle
  \longmapsto
  |\psi'\rangle
  =
  U|\psi\rangle
\]
which we can write explicitly as
\[
  \begin{bmatrix}
    \alpha'_0
  \\\alpha'_1
  \end{bmatrix}
  =
  \begin{bmatrix}
    U_{00} & U_{01}
  \\U_{10} & U_{11}
  \end{bmatrix}
  \begin{bmatrix}
    \alpha_0
  \\\alpha_1
  \end{bmatrix}
\]
That is, the operation \(U\) turns the state \(|\psi\rangle\), with components \(\alpha_k\), into the state \(|\psi'\rangle=U|\psi\rangle\), with components \(\alpha'_l= \sum_k U_{lk}\alpha_k\).

\hypertarget{quantum-gates-and-circuits}{%
\subsection{Quantum gates and circuits}\label{quantum-gates-and-circuits}}

Atoms, trapped ions, molecules, nuclear spins and many other quantum objects, which we call qubits, can be used to implement simple quantum interference, and hence simple quantum computation.
There is no need to learn about physics behind these diverse technologies if all you want is to understand the basics of quantum computation.
We may now conveniently forget about any specific experimental realisation of a qubit and just remember that any manipulations on qubits have to be performed by physically admissible operations, and that such operations are represented by unitary transformations.

\begin{idea}
A \textbf{quantum (logic) gate} is a device which performs a fixed unitary operation on selected qubits in a fixed period of time, and a \textbf{quantum circuit} is a device consisting of quantum logic gates whose computational steps are synchronised in time.
The \textbf{sizes} of the circuit is the number of gates it contains.

\end{idea}

Some unitary \(U\) acting on a single qubit is represented diagrammatically as

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-15-1} \end{center}

This diagram should be read from left to right.
The horizontal line represents a qubit that is inertly carried from one quantum operation to another.
We often call this line a \textbf{quantum wire}.
The wire may describe translation in space (e.g.~atoms travelling through cavities) or translation in time (e.g.~a sequence of operations performed on a trapped ion).
A sequence of two gates acting on the same qubit, say \(U\) followed by \(V\), is represented by

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-16-1} \end{center}

and is described by the matrix product \(VU\) (note the order in which we multiply the matrices).

\hypertarget{single-qubit-interference}{%
\subsection{Single qubit interference}\label{single-qubit-interference}}

Let me now describe what is probably the most important sequence of operations performed on a single qubit, namely a generic \textbf{single qubit interference}.
It is typically constructed as a sequence of three elementary operations:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  the Hadamard gate
\item
  a phase-shift gate
\item
  the Hadamard gate again.
\end{enumerate}

We represent it graphically as

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-17-1} \end{center}

\begin{idea}

\begin{longtable}[]{@{}lll@{}}
\toprule
\endhead
\textbf{Hadamard} & \(H = \frac{1}{\sqrt2}\begin{bmatrix}1&1\\1&-1\end{bmatrix}\) & \(\begin{array}{lcr}|0\rangle&\longmapsto&\frac1{\sqrt{2}}(|0\rangle+|1\rangle)\\|1\rangle&\longmapsto&\frac1{\sqrt{2}}(|0\rangle-|1\rangle)\end{array}\)\tabularnewline
\textbf{Phase-shift} & \(P_\varphi = \begin{bmatrix}1&0\\0&e^{i\varphi}\end{bmatrix}\) & \(\begin{array}{lcr}|0\rangle&\longmapsto&|0\rangle\\|1\rangle&\longmapsto&e^{i\varphi}|1\rangle\end{array}\)\tabularnewline
\bottomrule
\end{longtable}


\end{idea}

You will see it over and over again, for it is quantum interference that gives quantum computation additional capabilities.\footnote{Indeed, you have already seen this sequence: recall our study of Ramsey interferometry, and note how this is essentially the same!}

\begin{idea}
Something that many explanations of quantum computing say is the following: ``quantum computers are quicker because they evaluate all possible solutions at once, in parallel''.
\textbf{This is not accurate.}

Firstly, quantum computers are not necessarily ``quicker'' than classical computers, but can simply implement quantum algorithms, some of which \emph{are} quicker than their classical counterparts.
Secondly, the idea that they ``just do all the possible computations at once'' is false --- instead, they rely on thoughtfully using interference (which can be constructive or destructive) to modify the probabilities of specific outcomes.

\emph{The power of quantum computing comes from quantum interference.}

\end{idea}

The product of the three matrices \(HP_\varphi H\) describes the action of the whole circuit: it gives the transition amplitudes between states \(|0\rangle\) and \(|1\rangle\) at the input and the output as
\[
  e^{i\frac{\varphi}{2}}
  \begin{bmatrix}
    \cos\varphi/2 & -i\sin\varphi/2
  \\-i\sin\varphi/2 & \cos\varphi/2
  \end{bmatrix}
  =
  \frac{1}{\sqrt 2}
  \begin{bmatrix}
    1 & 1
  \\1 & -1
  \end{bmatrix}
  \begin{bmatrix}
    1 & 0
  \\0 & e^{i\varphi}
  \end{bmatrix}
  \frac{1}{\sqrt 2}
  \begin{bmatrix}
    1 & 1
  \\1 & -1
  \end{bmatrix}
\]

Given that our input state is almost always \(|0\rangle\), it is sometimes much easier and more instructive to step through the execution of this circuit and follow the evolving state.
The interference circuit effects the following sequence of transformations:\footnote{We ignore the global phase factor \(e^{i\frac{\varphi}{2}}\).}
\[
  \begin{aligned}
    |0\rangle
    &\overset{H}{\longmapsto}
    \frac{1}{\sqrt2} \left(
      |0\rangle+|1\rangle
    \right)
  \\&\overset{P_\phi}{\longmapsto}
    \frac{1}{\sqrt2} \left(
      |0\rangle+e^{i\phi}|1\rangle
    \right)
  \\&\overset{H}{\longmapsto}
    \cos\frac{\phi}{2}|0\rangle - i\sin\frac{\phi}{2}|1\rangle.
  \end{aligned}
\]
The first Hadamard gate prepares an equally weighted superposition of \(|0\rangle\) and \(|1\rangle\) and the second one closes the interference by bringing the interfering paths together.
The phase shift \(\varphi\) effectively controls the evolution and determines the output.
The probabilities of finding the qubit in state \(|0\rangle\) or \(|1\rangle\) at the output are, respectively,
\[
  \begin{aligned}
    \Pr(0) &= \cos^2\frac{\phi}{2}
  \\\Pr(1) &= \sin^2\frac{\phi}{2}.
  \end{aligned}
\]
This simple quantum process contains, in a nutshell, the essential ingredients of quantum computation.
This sequence (Hadamard--phase shift--Hadamard) will appear over and over again.
It reflects a natural progression of quantum computation: first we prepare different computational paths, then we evaluate a function which effectively introduces phase shifts into different computational paths, then we bring the computational paths together at the output.

\hypertarget{the-square-root-of-not}{%
\subsection{The square root of NOT}\label{the-square-root-of-not}}

Now that we have poked our heads into the quantum world, let us see how quantum interference challenges conventional logic.
Consider a following task: design a logic gate that operates on a single bit and such that when it is followed by another, identical, logic gate the output is always the negation of the input.
Let us call this logic gate \textbf{the square root of \(\texttt{NOT}\)}, or \(\sqrt{\texttt{NOT}}\).

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-18-1} \end{center}

A simple check, such as an attempt to construct a truth table, should persuade you that there is no such operation in logic.
It may seem reasonable to argue that since there is no such operation in logic, \(\sqrt{\texttt{NOT}}\) is impossible.
But it does exist!
Experimental physicists routinely construct such ``impossible'' gates in their laboratories.
It is a physically admissible operation described by the unitary matrix\footnote{There are infinitely many unitary operations that act as the square root of \(\texttt{NOT}\).}
\[
  \sqrt{\texttt{NOT}}
  =
  \frac12
  \begin{bmatrix}
    1+i & 1-i
  \\1-i&1+i
  \end{bmatrix}
  =
  \frac1{\sqrt2}
  \begin{bmatrix}
    e^{i\frac{\pi}{4}} & e^{-i\frac{\pi}{4}}
  \\e^{-i\frac{\pi}{4}} & e^{i\frac{\pi}{4}}
  \end{bmatrix}.
\]
Indeed,
\[
  \frac12
  \begin{bmatrix}
    1+i & 1-i
  \\1-i & 1+i
  \end{bmatrix}
  \frac12
  \begin{bmatrix}
    1+i & 1-i
  \\1-i & 1+i
  \end{bmatrix}
  =
  \begin{bmatrix}
    0&1
  \\1&0
  \end{bmatrix}.
\]

We could also step through the circuit diagram and follow the evolution of the state vector:

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-19-1} \end{center}

Or, if you prefer to work with column vectors and matrices, you can write the two consecutive application of \(\sqrt{\texttt{NOT}}\) to state \(|0\rangle\) as
\[
  \begin{bmatrix}0\\1\end{bmatrix}
  \,\longleftarrow\!\!\!\vert\,\,
  \frac{1}{\sqrt 2}
  \begin{bmatrix}
    e^{i\frac{\pi}{4}}
  \\e^{-i\frac{\pi}{4}}
  \end{bmatrix}
  \,\longleftarrow\!\!\!\vert\,\,
  \begin{bmatrix}1\\0\end{bmatrix}
\]
(following a well established convention, the above should be read from \emph{right to left})\footnote{Just remember that circuits diagrams are read from \emph{left to right}, and vector and matrix operations go from \emph{right to left}.}, where each \(\longleftarrow\!\!\!\vert\) denotes multiplication by \(\frac1{\sqrt2}\begin{bmatrix}e^{i\frac{\pi}{4}} & e^{-i\frac{\pi}{4}}\\e^{-i\frac{\pi}{4}} & e^{i\frac{\pi}{4}}\end{bmatrix}\).

One way or another, quantum theory explains the behaviour of \(\sqrt{\texttt{NOT}}\), and so, reassured by the physical experiments\footnote{We discuss this in more detail in {[}Appendix:\textbf{!!to-do!!} Physics against logic, via beamsplitters{]}.} that corroborate this theory, logicians are now entitled to propose a new logical operation \(\sqrt{\texttt{NOT}}\).
Why?
Because a faithful physical model for it exists in nature!

\hypertarget{phase-gates-galore}{%
\subsection{Phase gates galore}\label{phase-gates-galore}}

As well as the generic phase gate \(P_\varphi\), let us mention three specific phase gates that will frequently pop up (two of which have rather confusing names, at first glance!).

\begin{idea}

\begin{longtable}[]{@{}lll@{}}
\toprule
\endhead
\textbf{Generic phase-shift} & \(P_\varphi = \begin{bmatrix}1&0\\0&e^{i\varphi}\end{bmatrix}\) & \(\begin{array}{lcr}|0\rangle&\longmapsto&|0\rangle\\|1\rangle&\longmapsto&e^{i\varphi}|1\rangle\end{array}\)\tabularnewline
\textbf{Phase-flip} & \(Z = \begin{bmatrix}1&0\\0&-1\end{bmatrix}\) & \(\begin{array}{lcr}|0\rangle&\longmapsto&|0\rangle\\|1\rangle&\longmapsto&-|1\rangle\end{array}\)\tabularnewline
\textbf{\(\pi/4\)-phase} & \(S = \begin{bmatrix}1&0\\0&i\end{bmatrix}\) & \(\begin{array}{lcr}|0\rangle&\longmapsto&|0\rangle\\|1\rangle&\longmapsto&i|1\rangle\end{array}\)\tabularnewline
\textbf{\(\pi/8\)-phase} & \(T = \begin{bmatrix}1&0\\0&e^{i\frac{\pi}{4}}\end{bmatrix}\) & \(\begin{array}{lcr}|0\rangle&\longmapsto&|0\rangle\\|1\rangle&\longmapsto&e^{i\frac{\pi}{4}}|1\rangle\end{array}\)\tabularnewline
\bottomrule
\end{longtable}


\end{idea}

Note that the phase gate \(P_\varphi\) is only defined up to a global phase factor\footnote{In general, states differing only by a global phase are physically indistinguishable, and so it is physical experimentation that leads us to this mathematical choice of only defining things up to a global phase.}, and so we can write its matrix either as
\[
  P_\varphi =
  \begin{bmatrix}
    1 & 0
  \\0 & e^{i\varphi}
  \end{bmatrix}
\]
or as
\[
  P_\varphi =
  \begin{bmatrix}
    e^{-i\frac{\varphi}{2}} & 0
  \\0 & e^{i\frac{\varphi}{2}}
  \end{bmatrix}
\]
The first version is more common in the quantum information science community, but the second one is sometimes more convenient to use, as it has determinant \(1\), and hence belongs to the group \(\mathrm{SU}(2)\).
We will occasionally switch to the \(\mathrm{SU}(2)\) version of a phase gates, and this is where the \(\pi/4\)-phase and \(\pi/8\)-phase gates get their names, since their \(\mathrm{SU}(2)\) versions have \(e^{\mp i\pi/4}\) and \(e^{\mp i\pi/8}\) (respectively) on the diagonal.

The remaining gate (\(Z\)) is arguably the most important specific phase gate, since it is one of the \textbf{Pauli operators}, which we will now discuss.

\hypertarget{pauli-operators}{%
\subsection{Pauli operators}\label{pauli-operators}}

Adding to our collection of common single-qubit gates, we now look at the three \textbf{Pauli operators}\footnote{We use the standard basis \(\{|0\rangle,|1\rangle\}\) most of the time, and so often refer to operators as matrices.} \(\sigma_x\), \(\sigma_y\), and \(\sigma_z\), also denoted by \(X\), \(Y\), and \(Z\) (respectively).
These three operators, combined with the identity, satisfy a lot of nice formal properties, which we shall examine briefly here, and then return to in more detail in \protect\hyperlink{quantum-gates}{Chapter 3}.

\begin{idea}

\begin{longtable}[]{@{}lll@{}}
\toprule
\endhead
\textbf{Identity} & \(\mathbf{1}= \begin{bmatrix}1&0\\0&1\end{bmatrix}\) & \(\begin{array}{lcr}|0\rangle&\longmapsto&|0\rangle\\|1\rangle&\longmapsto&|1\rangle\end{array}\)\tabularnewline
\textbf{Bit-flip} & \(X = \begin{bmatrix}0&1\\1&0\end{bmatrix}\) & \(\begin{array}{lcr}|0\rangle&\longmapsto&|1\rangle\\|1\rangle&\longmapsto&|0\rangle\end{array}\)\tabularnewline
\textbf{Bit-phase-flip} & \(Y = \begin{bmatrix}0&-i\\i&0\end{bmatrix}\) & \(\begin{array}{lcr}|0\rangle&\longmapsto&i|1\rangle\\|1\rangle&\longmapsto&-i|0\rangle\end{array}\)\tabularnewline
\textbf{Phase-flip} & \(Z = \begin{bmatrix}1&0\\0&-1\end{bmatrix}\) & \(\begin{array}{lcr}|0\rangle&\longmapsto&|0\rangle\\|1\rangle&\longmapsto&-|1\rangle\end{array}\)\tabularnewline
\bottomrule
\end{longtable}


\end{idea}

The identity is just a quantum wire, and we have already seen the \(X\) and \(Z\) gates in \protect\hyperlink{phase-gates-galore}{Phase gates galore}, as the bit-flip and phase-flip (respectively).
Note that, of these latter two, only the \(X\) gate has a classical analogue (as the logical \(\texttt{NOT}\) operator).
The remaining gate, the \(Y\) operator, describes the combined effect of both the bit- and the phase-flip: \(ZX=iY\).

In fact, this is just one of the equations that the Pauli matrices satisfy.
The Pauli matrices are unitary and Hermitian, they square to the identity, and they anti-commute.
By this last point, we mean that
\[
  \begin{aligned}
    XY+YX&=0,
  \\XZ+ZX&=0,
  \\YZ+ZY&=0.
  \end{aligned}
\]
As already mentioned, they satisfy \(ZX=iY\), but also any cyclic permutation of this equation.

These operators are also called \textbf{sigma matrices}, or \textbf{Pauli spin matrices}.
They are so ubiquitous in quantum physics that they should certainly be memorised.

\hypertarget{from-bit-flips-to-phase-flips-and-back-again}{%
\subsection{From bit-flips to phase-flips, and back again}\label{from-bit-flips-to-phase-flips-and-back-again}}

The Pauli \(Z\) gate is a special case of a phase gate \(P_\varphi\) with \(\varphi=\pi\).
When we insert it into the interference circuit we obtain

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-20-1} \end{center}

If you wish to verify this, write the Hadamard gate as \(H = (X+Z)/\sqrt{2}\) and use the properties of the Pauli operators.\footnote{\(\begin{aligned}HXH &= Z\\HZH &= X\\HYH &= -Y\end{aligned}\)}
So the Hadamard gate turns phase-flips into bit-flips, but it also turns bit-flips into phase-flips:

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-21-1} \end{center}

Let us also add, for completeness, that \(HYH=-Y\).
You will see these identities again and again, especially when we discuss quantum error corrections.\footnote{Unitaries, such as \(H\), that take the three Pauli operators to the Pauli operators via conjugation form the so-called \textbf{Clifford group}, which we will meet later on. Which phase gate is in the Clifford group of a single qubit?}

\hypertarget{any-unitary-operation-on-a-single-qubit}{%
\subsection{Any unitary operation on a single qubit}\label{any-unitary-operation-on-a-single-qubit}}

There are infinitely many unitary operations that can be performed on a single qubit.
In general, any complex \((n\times n)\) matrix has \(n^2\) complex entries, and can thus be specified by \(2n^2\) real independent parameters.
The unitarity constraint removes \(n^2\) of these, and so any unitary \((n\times n)\) matrix has \(n^2\) real independent parameters.
In particular, we need \emph{four} real parameters to specify a \((2\times 2)\) unitary matrix.
If we are prepared to ignore global phase factors (which we are) then there are only three real parameters left.
So, with this in mind, can we construct and implement any unitary on a single qubit in some simple way?

\emph{Yes, we can.}

Any unitary operation on a qubit (up to an overall multiplicative phase factor) can be implemented by a circuit containing just two Hadamards and three phase gates, with adjustable phase settings, as in Figure \ref{fig:universal-circuit-for-2-by-2}.



\begin{figure}[H]

{\centering \includegraphics{iqis-book_files/figure-latex/universal-circuit-for-2-by-2-1} 

}

\caption{The universal circuit for unitary \((2\times2)\) matrices.}\label{fig:universal-circuit-for-2-by-2}
\end{figure}

If we multiply the matrices corresponding to each gate in the network (remember that the order of matrix multiplication is reversed) we obtain
\[
  U(\alpha,\beta,\varphi)
  =\begin{bmatrix}
    e^{-i\left(\frac{\alpha+\beta}{2}\right)}\cos\varphi/2
    & -ie^{i\left(\frac{\alpha-\beta}{2}\right)}\sin\varphi/2
  \\-ie^{-i\left(\frac{\alpha-\beta}{2}\right)}\sin\varphi/2
    & e^{i\left(\frac{\alpha+\beta}{2}\right)}\cos\varphi/2
  \end{bmatrix}.
\]
Any \((2\times 2)\) unitary matrix (up to global phase) can be expressed in this form using the three independent real parameters, \(\alpha\), \(\beta,\) and \(\varphi\), which take values in \([0,2\pi]\).
In order to see that this construction does what it claims, let us explore an intriguing mathematical connection between single qubit unitaries and rotations in three dimensions.

\hypertarget{the-bloch-sphere}{%
\subsection{The Bloch sphere}\label{the-bloch-sphere}}

Unitary operations on a single qubit form a group.
More precisely, the set of all \((2\times 2)\) unitary matrices forms a non-abelian group under the matrix multiplication, denoted by \(\mathrm{U}(2)\).
It turns out that compositions of single qubit unitaries behave pretty much the same as compositions of rotations in three dimensions.
Technically speaking, we claim that \(\mathrm{U}(2)/\mathrm{U}(1)\cong \mathrm{SO}(3)\).\footnote{Note that \(\mathrm{U}(1)\cong\mathbb{C}^\times\), where \(\mathbb{C}^\times\) is the multiplicative group of unit elements of the complex numbers, i.e.~the set \(\mathbb{C}\setminus\{0\}\) with the group operation given by multiplication.}
That is, \((2\times 2)\) unitaries, up to global phase, form a group which is isomorphic to the group of rotations in three dimensions, denoted by \(\mathrm{SO}(3)\).
This isomorphism helps to visualise the actions of single-qubit gates.

There are many ways to introduce this isomorphism.
Here we will just show how to represent single-qubit state vectors in terms of Euclidean vectors in three dimensions; in \protect\hyperlink{quantum-gates}{Chapter 3} we will actually relate unitary operations on state vectors to rotations in this Euclidean space, demonstrating this isomorphism.\footnote{That is, we have the group \(\mathrm{U}(2)\) acting on the space of single-qubit state vectors, and we have the group \(\mathrm{SO}(3)\) acting on the unit sphere \(S^2\subset\mathbb{R}^3\). In this chapter we will discuss how to go from one \emph{space} (i.e.~the thing being acted upon by the group) to the other; in \protect\hyperlink{quantum-gates}{Chapter 3} we will discuss how to go from one \emph{group} (i.e.~the thing acting on the space) to the other.}

Any single qubit state can be written as \(|\psi\rangle=\alpha|0\rangle+\beta|1\rangle\), constrained by the relation \(|\alpha|^2+|\beta|^2=1\).
This suggests a more natural parametrisation as
\[
  |\psi\rangle =
  \cos\frac{\theta}{2}e^{i\varphi_0}|0\rangle
  + \sin\frac{\theta}{2}e^{i\varphi_1}|1\rangle
\]
(note that there is a good reason to use \(\theta/2\) instead of \(\theta\), and we we will explain why later on).
We can then factor out a global phase:
\[
  |\psi\rangle =
  e^{i\varphi_0}\left(
    \cos\frac{\theta}{2}|0\rangle + \sin\frac{\theta}{2}e^{i\varphi}|1\rangle
  \right),
\]
and even remove it completely, since states that are identical up to a global phase are physically indistinguishable.

The parametrisation in terms of \(\theta\) and \(\varphi\) should remind you of spherical polar coordinates for the surface of a sphere.



\begin{figure}[H]

{\centering \includegraphics{iqis-book_files/figure-latex/bloch-sphere-1} 

}

\caption{The Bloch sphere, with the point \(\vec{s}\) corresponding to \(|\psi\rangle\) marked.}\label{fig:bloch-sphere}
\end{figure}

We call this sphere the \textbf{Bloch sphere}, and the unit vector \(\vec{s}\) defined by \(\theta\) and \(\varphi\) the \textbf{Bloch vector}.\footnote{We will revisit this construction again in more detail, and from a slightly different point of view, in \protect\hyperlink{quantum-gates}{Chapter 3}.}
This is a very useful way to visualise quantum states of a single qubit and unitary operations that we perform on it.
Any unitary action on the state vector will induce a rotation of the corresponding Bloch vector.
But what kind of rotation?

We give a complete answer to this question in \protect\hyperlink{quantum-gates}{Chapter 3}, but we might as well give some specific results here first, since some are easy enough to calculate ``by hand''.
Note that \emph{any two orthogonal state vectors appear on the Bloch sphere as two Bloch vectors pointing in opposite directions}.
Now, the two eigenvectors of a single-qubit unitary \(U\) must be orthogonal, and thus define an axis running through the centre of the Bloch sphere.
This is the axis about which the Bloch vector is rotated when \(U\) acts on the corresponding state vector.
The rotation angle \(\alpha\) is given by the eigenvalues of \(U\), which, up to a global phase factor, are of the form \(e^{\mp i\alpha/2}\).

It is instructive to work out few simple cases and get a feel for the rotations corresponding to the most common unitaries.
For example, it is easy to check that a phase gate \(P_\alpha\) acts by
\[
  \cos\frac{\theta}{2}|0\rangle + e^{i\varphi}\sin\frac{\theta}{2}|1\rangle
  \longmapsto
  \cos\frac{\theta}{2}|0\rangle + e^{i(\varphi+\alpha)}\sin\frac{\theta}{2}|1\rangle.
\]
The azimuthal angle changes from \(\varphi\) to \(\varphi+\alpha\), and so the Bloch sphere is rotated anticlockwise by \(\alpha\) about the \(z\)-axis.
The Bloch vectors corresponding to the two eigenvectors of \(P_\alpha\), namely \(|0\rangle\) and \(|1\rangle\), define the axis of the rotation.



\begin{figure}[H]

{\centering \includegraphics{iqis-book_files/figure-latex/bloch-sphere-rotation-1} 

}

\caption{Phase gates \(P_\alpha\) represent rotations of the Bloch sphere around the \(z\)-axis.}\label{fig:bloch-sphere-rotation}
\end{figure}

As previously mentioned, the Pauli operator \(Z=\sigma_z\) is a special case of a phase gate, and represents rotation by \({180}^{\circ}\) (that is, \(\pi\) radians), about the \(z\)-axis.
You can also verify that \(X=\sigma_x\), with eigenvectors \({(|0\rangle\pm|1\rangle)/\sqrt{2}}\), represents rotation by \({180}^{\circ}\) about the \(x\)-axis, and \(Y=\sigma_y\), with eigenvectors \({(|0\rangle\pm i|1\rangle)/\sqrt{2}}\), represents rotation by \({180}^{\circ}\) about the \(y\)-axis.

\textbf{!!!TO-DO!!! points on the intersection of the axes with the Bloch sphere are exactly the eigenstates of the corresponding Pauli operator}

How about the Hadamard gate?
Like the Pauli operators, it squares to the identity (\(H^2=\mathbf{1}\)), which implies that its eigenvalues are \(\pm 1\).
Thus it will correspond to a rotation by \({180}^{\circ}\).
But about which axis?
This time, rather than finding eigenvectors of \(H\), we notice that \(HXH=Z\) and \(HZH=X\), thus \(H\) must swap \(x\)- and \(z\)-axes, turning rotations about the \(z\)-axis into rotations about the \(x\)-axis, and vice versa.
The Hadamard gate must then represent rotation by \({180}^{\circ}\) about the diagonal \((x+z)\)-axis.
You may also notice that, after this rotation, the \(y\)-axis points in the opposite direction, which seems to be related to another identity: \(HYH=-Y\).
This is not a coincidence.

One can show\footnote{Again, see \protect\hyperlink{quantum-gates}{Chapter 3}.} that the effect of the rotation represented by unitary \(U\) on the Bloch vector with components \(s_x\), \(s_y\), \(s_z\) is summarised in the formula
\[
  U (s_x X + s_y Y + s_z Z) U^\dagger
  = s'_x X+ s'_y Y + s'_z Z,
\]
where \(s'_x\), \(s'_y\), and \(s'_z\) are the components of the rotated Bloch vector.

\hypertarget{drawing-points-on-the-bloch-sphere}{%
\subsubsection{Drawing points on the Bloch sphere}\label{drawing-points-on-the-bloch-sphere}}

We know that the state \(|0\rangle\) corresponds to the north pole of the Bloch sphere, and the state \(|1\rangle\) to the south, but what about an arbitrary state \(|\psi\rangle=\alpha|0\rangle+\beta|1\rangle\)?
By definition, we can find the parametrisation in terms of \(\theta\) and \(\varphi\), but there is also a neat ``trick'' for finding the point on the Bloch sphere that corresponds to \(|\psi\rangle\), which goes as follows.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Calculate \(\lambda=\beta/\alpha\) (assuming that \(\alpha\neq0\), since otherwise \(|\psi\rangle=|1\rangle\)).
\item
  Write \(\lambda=\lambda_x+i\lambda_y\) and mark the point \(p=(\lambda_x,\lambda_y)\) in the \(xy\)-plane (i.e.~the plane \(\{z=0\}\)).
\item
  Draw the line going through the south-pole and the point \(p\). This will intersect the Bloch sphere in exactly one other point, and this is exactly the point corresponding to \(|\psi\rangle\).
\end{enumerate}

Note that this lets you \emph{draw} the point on the sphere, but doesn't (immediately) give you the \emph{coordinates} for it.
That is, this method is nice for geometric visualisation, but the parametrisation method is much better when it comes to actually doing calculations.

\hypertarget{composition-of-rotations}{%
\subsection{Composition of rotations}\label{composition-of-rotations}}

We are now in a position understand the circuit in Figure \ref{fig:universal-circuit-for-2-by-2} in geometric terms.
Recall that \emph{any} rotation in the Euclidean space can be performed as a sequence of three rotations: one about the \(z\)-axis, one about the \(x\)-axis, and one more about \(z\)-axis.
The circuit does exactly this:

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-22-1} \end{center}

The first phase gate effects rotation by \(\alpha\) about the \(z\)-axis, the second phase gate is sandwiched between the two Hadamard gates, and these three gates together effect rotation by \(\varphi\) about the \(x\)-axis, and, finally, the third phase gates effects rotation by \(\beta\) about the \(z\)-axis.
So we can implement any unitary \(U\) by choosing the three phase shifts, \(\alpha\), \(\varphi\), and \(\beta\), which are known as the three \textbf{Euler's angles}.

\hypertarget{a-finite-set-of-universal-gates}{%
\subsection{A finite set of universal gates}\label{a-finite-set-of-universal-gates}}

The Hadamard gate and the phase gates, with adjustable phases, allow us to implement an arbitrary single-qubit unitary \emph{exactly}.
The tacit assumption here is that we have here \emph{infinitely many} phase gates: one gate for each phase.
In fact, we can pick just one phase gate, namely any phase gate \(P_\alpha\) with the phase \(\alpha\) that is incommensurate\footnote{That is, there do \emph{not} exist any \(m,n\in\mathbb{Z}\) such that \(m\alpha=n\pi\). For example, it suffices to take \(\alpha\) to be rational.} with \(\pi\).
It is clear that repeated iteration of \(P_\alpha\) can be used to approximate any other phase gate to arbitrary accuracy: indeed, rotate the Bloch sphere by \(\alpha\) about the \(z\)-axis sufficiently many times and you end up as close as you please to any other rotation about the \(z\)-axis.

If you want to be \(\epsilon\)-close to the desired angle of rotation, then you may need to repeat the rotation by \(\alpha\) roughly \(1/\epsilon\) times.
Indeed, within \(n\) applications (for \(n\alpha\gg 2\pi\)) of \(P_\alpha\), we expect the accessible angles to be approximately evenly distributed within the range \([0,2\pi]\), i.e.~any angle of rotation can be achieved to an accuracy of \(\epsilon=2\pi/n\) by using up to \(n\approx 1/\epsilon\) applications of \(P_\alpha\).
So we can use \emph{just one} phase gate to \emph{approximate} the \emph{three} phase gates in the circuit in Figure \ref{fig:universal-circuit-for-2-by-2}.

There are other ways of implementing irrational rotations of the Bloch sphere.
For example, take the Hadamard gate and the \(T\) gate.
You can check that the compositions \(THTH\) and \(HTHT\) represent rotations by angles which are irrational multiples of \(\pi\), about two different axes.
We can then compose a sequence of these two rotations to approximate any other rotation of the sphere.
This may look very nice in theory, but there are issues with the actual physical implementation of this approach.
All the gates in the circuit will operate with finite precision, and the phase gates will deviate from implementing the required irrational rotations.
It turns out, however, that we can tolerate minor imperfections; the final result will not be that far off.

For more details on all the above, see \protect\hyperlink{quantum-gates}{Chapter 3}.

\hypertarget{remarks-and-exercises-2}{%
\subsection{\texorpdfstring{\emph{Remarks and exercises}}{Remarks and exercises}}\label{remarks-and-exercises-2}}

\hypertarget{unknown-phase}{%
\subsubsection{Unknown phase}\label{unknown-phase}}

Consider the usual quantum interference circuit:

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-23-1} \end{center}

Suppose you can control the input of the circuit and measure the output, but you do not know the phase shift \(\varphi\) introduced by the phase gate.
You prepare input \(|0\rangle\) and register output \(|1\rangle\).
What can you say about \(\varphi\)?

Now you are promised that \(\varphi\) is either \(0\) or \(\pi\).
You can run the circuit only once to find out which of the two phases was chosen.
Can you do that?

\hypertarget{cross-product-identity}{%
\subsubsection{One of the many cross-product identities}\label{cross-product-identity}}

Derive the identity
\[
  (\vec{a}\cdot\vec{\sigma})(\vec{b}\cdot\vec{\sigma})
  = (\vec{a}\cdot\vec{b})\mathbf{1}+ i(\vec{a}\times \vec{b})\cdot \vec{\sigma}.
\]

\emph{(Hint: all you need here are the Pauli matrices' commutation and anti-commutation relations, but it is instructive to derive the identity using the component notation, and below we give a sketch of how such a derivation would go.)}

First, notice that the products of Pauli matrices can be written succinctly as
\[
 \sigma_{i}\sigma_{j}
 = \delta _{ij}\mathbf{1}+ i\varepsilon_{ijk}\,\sigma _{k},
\]
where \(\delta_{ij}\) is the Kronecker delta and \(\varepsilon_{ijk}\) is the \textbf{Levi-Civita symbol}:
\[
 \varepsilon_{ijk}
 = \begin{cases}
  +1 & {\text{if }}(i,j,k){\text{ is }}(1,2,3)\text{, }(2,3,1){\text{, or }}(3,1,2)
\\-1 & {\text{if }}(i,j,k){\text{ is }}(3,2,1)\text{, }(1,3,2){\text{, or }}(2,1,3)
\\\;\;\;0 & {\text{if }}i=j,{\text{ or }}j=k,{\text{ or }}k=i
\end{cases}
\]
That is, \(\varepsilon _{ijk}\) is \(1\) if \((i, j, k)\) is an even permutation of \((1, 2, 3)\), it is \(-1\) if it is an odd permutation, and it is \(0\) if any index is repeated.
The Levi-Civita symbol is anti-symmetric, meaning when any two indices are changed, its sign alternates.
Then recall that the scalar (dot) product and vector (cross) product of two Euclidean vectors \(\vec{a}\) and \(\vec{b}\) can be written, in terms of the components, as
\[
  \begin{aligned}
    \vec{a}\cdot\vec{b}
    &= \sum_{i=1}^3 a_i b_i
  \\(\vec{a}\times\vec{b})_i
    &= \sum_{j,k=1}^3 \varepsilon_{ijk}a_jb_k.
  \end{aligned}
\]
The rest is rather straightforward:
\[
  (\vec{a}\cdot\vec{\sigma})(\vec{b}\cdot\vec{\sigma})
  = \sum_{ij}a_i b_j\sigma_i\sigma_j
  = \ldots.
\]

\hypertarget{quantum-gates}{%
\section{Quantum gates}\label{quantum-gates}}

\begin{quote}
About understanding the square root of \(\texttt{NOT}\) via a physical implementation using \textbf{symmetric beam-splitters}.
More about the Bloch sphere, via the omnipresent \textbf{Pauli matrices}, which can be described in a more algebraic way.
\end{quote}

Before moving on, we first study two of the subjects from \protect\hyperlink{qubits}{Chapter 2} in more depth: the square root of \(\texttt{NOT}\), and the Bloch sphere.

The goal for the latter is to be able to visualise sequences of unitary operations on a qubit as sequences of rotations, and to see the action of some quantum circuits without getting engaged in lengthy calculations.
The goal for the former is to study a way of implementing this gate using physical experiments, and then studying a related construction (the so-called \textbf{Mach--Zehnder interferometer}).

\hypertarget{physics-against-logic-via-beamsplitters}{%
\subsection{Physics against logic, via beamsplitters}\label{physics-against-logic-via-beamsplitters}}

A symmetric beam-splitter is a cube of glass which reflects half the light that impinges upon it, while allowing the remaining half to pass through unaffected.
For our purposes it can be viewed as a device which has two input and two output ports which we label as \(|0\rangle\) and \(|1\rangle\), as in Figure \ref{fig:beam-splitter}.

\begin{figure}[H]

{\centering \includegraphics{iqis-book_files/figure-latex/beam-splitter-1} 

}

\caption{A beam-splitter.}\label{fig:beam-splitter}
\end{figure}

When we aim a single photon at such a beam-splitter using one of the input ports, we notice that the photon doesn't split in two: we can place photo-detectors wherever we like in the apparatus, fire in a photon, and verify that if any of the photo-detectors registers a hit, none of the others do.
In particular, if we place a photo-detector behind the beam-splitter in each of the two possible exit beams, the photon is detected with equal probability at either detector, no matter whether the photon was initially fired from input port \(|0\rangle\) or \(|1\rangle\).

It may seem obvious that, at the very least, the photon is \emph{either} in the transmitted beam \(|0\rangle\) \emph{or} in the reflected beam \(|1\rangle\) during any one run of this experiment.
Thus we may be tempted to think of the beam-splitter as a random binary switch which, with equal probability, transforms any binary input into one of the two possible outputs.
However, that is not necessarily the case.
Let us introduce a second beam-splitter and place two normal mirrors so that both paths intersect at the second beam-splitter, resulting in something resembling the Mach-Zehnder interferometer (see \ref{fig:two-beam-splitters}).

\begin{figure}[H]

{\centering \includegraphics{iqis-book_files/figure-latex/two-beam-splitters-1} 

}

\caption{Two beam-splitters with mirrors, so that a photon travels through both.}\label{fig:two-beam-splitters}
\end{figure}

Now, the axiom of additivity in probability theory says that whenever something can happen in several alternative ways we add probabilities for each way considered separately.
We might argue that a photon fired into the input port \(|0\rangle\) can reach the detector \(0\) in two \emph{mutually exclusive} ways: either by two consecutive reflections or by two consecutive transmissions.
Each reflection happens with probability \(1/2\) and each transmission happens with probability \(1/2\) thus the total probability of reaching detector 0 is a sum of the probability of the two consecutive reflections (\(1/2\times 1/2 = 1/4\)) and the probability of the two consecutive transmissions (\(1/2\times 1/2 = 1/4\)) which gives probability \(1/2\).
This is summarised in Figure \ref{fig:classical-guess-double-beam-splitter}, and makes perfect sense --- a random switch followed by a random switch should give nothing else but a random switch.
However, if we set up such an experiment, that is not what happens!

\begin{idea}
There is no reason why probability theory (or any other \emph{a priori} mathematical construct for that matter) should make any meaningful statements about outcomes of physical experiments.

\end{idea}



\begin{figure}[H]

{\centering \includegraphics{iqis-book_files/figure-latex/classical-guess-double-beam-splitter-1} 

}

\caption{The two possible classical scenarios. Note that this is \textbf{not} what actually happens in the real physical world!}\label{fig:classical-guess-double-beam-splitter}
\end{figure}

In experimental reality, when the optical paths between the two beam-splitters are the same, the photon fired from input port \(|0\rangle\) \emph{always} strikes detector 1 and \emph{never} detector 0 (and the photon fired from input port \(|1\rangle\) \emph{always} strikes detector 0 and \emph{never} detector 1).
Thus a beam-splitter acts as the square root of \(\texttt{NOT}\) gate.

The action of the beam-splitter --- in fact, the action of any quantum device --- can be described by tabulating the amplitudes of transitions between its input and output ports.\footnote{Note that gate \(B\) is not the same square root of \(\texttt{NOT}\) as the one described previously. In fact, there are infinitely many ways of implementing this ``impossible'' logical operation.}
\[
  B = 
  \begin{bmatrix}
  B_{00} & B_{01}\\
  B_{10} & B_{11}
  \end{bmatrix}
  =
  \begin{bmatrix}
  \frac{1}{\sqrt 2} & \frac{i}{\sqrt 2}\\
  \frac{i}{\sqrt 2} & \frac{1}{\sqrt 2}
  \end{bmatrix}.
\]
The matrix element \(B_{lk}\), where \(k,l=0,1\), represents the amplitude of transition from input \(|k\rangle\) to output \(|l\rangle\) (watch the order of indices).
Each reflection (entries \(B_{01}\) and \(B_{10}\)) happens with amplitude \(i/\sqrt{2}\) and each transmission (entries \(B_{00}\) and \(B_{11}\)) happens with amplitude \(1/\sqrt{2}\).
Thus the total amplitude that a photon fired from input port \(|0\rangle\) will reach detector \(0\) is the sum of the amplitude of the two consecutive reflections (\(i/\sqrt{2}\times i/{\sqrt 2} = -1/2\)) and the amplitude of the two consecutive transmissions (\(1/{\sqrt 2}\times 1/{\sqrt 2} = 1/2\)) which gives the total amplitude \(0\).
The resulting probability is then zero.
Unlike probabilities, amplitudes can cancel out each other out.
We can now go on and calculate the amplitude that the photon will reach detector \(1\).
In this case we will get \(i\), which gives probability \(1\).
We can then switch to input \(|1\rangle\) and repeat our calculations.
All possible paths and associated amplitudes are shown in \ref{fig:paths-and-amplitudes-two-beam-splitters}.

\begin{figure}[H]

{\centering \includegraphics{iqis-book_files/figure-latex/paths-and-amplitudes-two-beam-splitters-1} 

}

\caption{All possible transitions and their amplitudes when we compose two beam-splitters $B$.}\label{fig:paths-and-amplitudes-two-beam-splitters}
\end{figure}

However, instead of going through all the paths in this diagram and linking specific inputs to specific outputs, we can simply multiply the transition matrices:
\[
  BB =
  \begin{bmatrix}
    \frac{1}{\sqrt 2} & \frac{i}{\sqrt 2}\\
    \frac{i}{\sqrt 2} & \frac{1}{\sqrt 2}
  \end{bmatrix}
  \begin{bmatrix}
    \frac{1}{\sqrt 2} & \frac{i}{\sqrt 2}\\
    \frac{i}{\sqrt 2} & \frac{1}{\sqrt 2}
  \end{bmatrix}
  =
  \begin{bmatrix}
  0 & i\\
  i & 0
  \end{bmatrix}
  = iX
\]
where
\[
  X = \texttt{NOT} = \begin{bmatrix}0&1\\1&0\end{bmatrix}.
\]

Recalling \protect\hyperlink{qubits}{Chapter 2}, we see that beam-splitters give a physical way of constructing the square root of \(\texttt{NOT}\).

\begin{idea}

\begin{longtable}[]{@{}lcc@{}}
\toprule
\endhead
\textbf{bit-flip} & \(\texttt{NOT}\equiv X\) & \(\begin{bmatrix}0&1\\1&0\end{bmatrix}\)\tabularnewline
\textbf{beam-splitter} & \(\sqrt{\texttt{NOT}}\equiv B\) & \(\frac{1}{\sqrt2}\begin{bmatrix}1&i\\i&1\end{bmatrix}\)\tabularnewline
\bottomrule
\end{longtable}


\end{idea}

\hypertarget{quantum-interference-revisited-still-about-beam-splitters}{%
\subsection{Quantum interference, revisited (still about beam-splitters)}\label{quantum-interference-revisited-still-about-beam-splitters}}

One of the simplest quantum devices in which quantum interference can be controlled is a \textbf{Mach--Zehnder interferometer} --- see Figure \ref{fig:mach-zehnder}.\footnote{You can play around with a virtual Mach--Zehnder interferometer at \href{https://lab.quantumflytrap.com/lab/mach-zehnder}{Virtual Lab by Quantum Flytrap}. (There are also lots of other things you can do in this virtual lab: \href{https://quantumflytrap.com/lab-how-to/}{go have a look!}).}



\begin{figure}[H]

{\centering \includegraphics{iqis-book_files/figure-latex/mach-zehnder-1} 

}

\caption{The \href{https://en.wikipedia.org/wiki/Mach-Zehnder_interferometer}{Mach-Zehnder interferometer}, with the input photon represented by the coloured dot. This experimental set-up is named after the physicists Ludwig Mach and Ludwig Zehnder, who proposed it back in 1890s.}\label{fig:mach-zehnder}
\end{figure}

It consists of two beam-splitters (the square boxes, bottom left and top right) and two slivers of glass of different thickness which are inserted into each of the optical paths connecting the two beam-splitters.
The slivers are usually referred to as ``phase shifters'' and their thicknesses, \(\varphi_0\) and \(\varphi_1\), are measured in units of the photon's wavelength multiplied by \(2\pi\).
The two inputs ports of the interferometer are labelled as \(|0\rangle\) and \(|1\rangle\), and each of the two output ports, also labelled as \(0\) and \(1\), terminates in a photodetector.\footnote{The two diagonal objects in the top-left and bottom-right corners of \ref{fig:mach-zehnder} are simply mirrors to make the two possible paths meet at the second beam-splitter.}

A photon (the coloured dot in the figure) impinges on the first beam-splitter from one of the two input ports (here input 1) and begins its journey towards one of the two photodetectors.
Let\footnote{We will often use \(i\) as an index even though it is also used for the imaginary unit. Hopefully, no confusion will arise for it should be clear from the context which one is which.} \(U_{ij}\) denote the probability amplitude that the photon initially in input port \(j=0,1\) ends up in detector \(i=0,1\).
At each of the two beam-splitters the photon is transmitted with the probability amplitude \(\sqrt{T}\) and reflected with the probability amplitude \(i\sqrt{R}\), with \(R+T=1\), and the two phase shifters modify the amplitudes by phase factors \(e^{i\varphi_0}\) and \(e^{i\varphi_1}\), respectively.
In quantum theory we almost always start with the amplitudes, and once we have a full expression for the amplitude of a given outcome we square its absolute value to get the corresponding probability.

For example, let us calculate \(U_{00}\).
We notice that there are two alternative ways for the photon in the input port \(0\) to end up in the output port \(0\).
It can take the lower path, through the phase shifter \(\varphi_0\), or the upper path, through the phase shifter \(\varphi_1\).
The lower path implies two consecutive transmissions at the beam-splitters and the phase factor \(e^{i\varphi_0}\), whereas the upper path implies two consecutive reflections and the phase factor \(e^{i\varphi_1}\).
Once the photon ends in the output port \(0\) there is no way of knowing which path was taken, thus we add the amplitudes pertaining to each path.
The resulting amplitude is
\[
  U_{00}
  = \sqrt{T} e^{i\varphi_0} \sqrt{T}
  + i\sqrt{R} e^{i\varphi_1} i \sqrt{R},
\]
and the corresponding probability \(P_{00}=|U_{00}|^2\) reads
\[
  \begin{aligned}
    P_{00}
    & = \left\vert
          \sqrt{T}e^{i\varphi_0}\sqrt{T} + i\sqrt{R}e^{i\varphi_1}i\sqrt{R}
        \right\vert^2
      = \left\vert
          Te^{i\varphi_0} - Re^{i\varphi_1}
        \right\vert^2
  \\& = T^2 + R^2
        - 2TR\cos(\varphi_1-\varphi_0).
  \end{aligned}
\]

The ``classical'' part of this expression, \(T^2+R^2\), basically says that the photon undergoes either two consecutive transmissions with probability \(T^2\), or two consecutive reflections with probability \(R^2\).
The probability of being transmitted through any phase shifter is always \(1\), hence the phase shifters play no role in the classical description of this process.
But the classical description is not correct, as the experiments show, whence the interference term \(2TR\cos(\varphi_1-\varphi_0)\) in which the phase shifters play the essential role.
Depending on the \emph{relative} phase \(\varphi=\varphi_1-\varphi_0\) the probability that the detector \(0\) ``clicks'' can vary from \((T-R)^2\), for \(\varphi=0\), to \(1\), for \(\varphi=\pi\).

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-24-1} \end{center}

If we do not care about the experimental details, we can represent the action of the Mach--Zehnder interferometer in terms of a diagram: see \ref{fig:mach-zehnder-diagram}.

\begin{figure}[H]

{\centering \includegraphics{iqis-book_files/figure-latex/mach-zehnder-diagram-1} 

}

\caption{The Mach-Zehnder interferometer represented as an abstract diagram.}\label{fig:mach-zehnder-diagram}
\end{figure}

Here we can follow, from left to right, the multiple different paths that a photon can take in between specific input and output ports.
The amplitude along any given path is just the product of the amplitudes pertaining to the path segments (Rule 1), while the overall amplitude is the sum of the amplitudes for the many different paths (Rule 2). You can, for example, see that the probability amplitude \(U_{10}\) is given by
\[
  U_{10}
  = \sqrt{T}e^{i\varphi_0}i\sqrt{R} + i\sqrt{R}e^{i\varphi_1}\sqrt{T}
\]
and the corresponding probability is
\[
  \begin{aligned}
    P_{10}
    & = \left\vert
        \sqrt{T}e^{i\varphi_0}i\sqrt{R} + i\sqrt{R}e^{i\varphi_1}\sqrt{T}
      \right\vert^2
  \\& = 2RT + 2RT\cos(\varphi_1-\varphi_0).
  \end{aligned}
\]
Again, the first term is of ``classical'' origin and represents probabilities corresponding to each path: one reflection followed by one transmission plus one transmission followed by one reflection, that is, \(RT+TR=2RT\).
The second term is the interference term.
Clearly, the photon entering port \(1\) will end up in one of the two detectors, hence,
\[
  P_{00} + P_{10}
  = R^2 + 2RT + T^2
  = (T+R)^2
  = 1.
\]
The action of the interferometer is thus fully described\footnote{In general, any isolated quantum device, including a quantum computer, can be described by a matrix of probability amplitudes \(U_{ij}\) that input \(j\) generates output \(i\). Watch the order of indices.} by the four probability amplitudes \(U_{ij}\) (\(i,j=0,1\)).

The most popular instance of a Mach--Zehnder interferometer involves only symmetric beam-splitters \((R=T=\frac12)\) and is fully described by the matrix
\[
  U =
  \begin{bmatrix}
    -\sin\varphi/2 & \cos\varphi/2
  \\\cos\varphi/2 & \sin\varphi/2
  \end{bmatrix}
\]
where \(\varphi=\varphi_1-\varphi_0\).
In fact, when you do all the calculations\footnote{That is, when you write down the matrices describing the action of the symmetric beam-splitters and the phase gates, and then multiply them all together (which is an exercise worth doing).} you obtain \(ie^{i\frac{\varphi_0+\varphi_1}{2}}U\) rather than \(U\), but the global phase factor \(ie^{i\frac{\varphi_0+\varphi_1}{2}}\) is common to all the amplitudes in the matrix and as such it does not contribute to the resulting probabilities.

To better understand why we don't worry about global phase factors, think about the eigenvalues of a matrix \(A\) and of the matrix \(\mu A\), where \(\mu\) is a complex number with \(|\mu|=1\).

\hypertarget{the-pauli-matrices-algebraically}{%
\subsection{The Pauli matrices, algebraically}\label{the-pauli-matrices-algebraically}}

Matrices form a vector space: you can add them, and you can multiply them by a scalar.
One possible choice of a basis in the vector space of \((2\times 2)\) matrices is the set of matrices \(\{M_{00},M_{01},M_{10},M_{11}\}\), where the entries of \(M_{ij}\) are all \(0\) except for the \(ij\)-th entry, which is \(1\) (e.g.~\(M_{01}=\begin{bmatrix}0&1\\0&0\end{bmatrix}\)).
However, it turns out that there is a different basis which offers lots of insights into the structure of the general single-qubit unitary transformations, namely \(\{\mathbf{1},X,Y,Z\}\), i.e.~the identity matrix and the three Pauli matrices.\footnote{In this chapter we are concerned only with the \emph{single-qubit} Pauli operators. There are analogous \emph{multi-qubit} Pauli operators, but be careful: these do not satisfy all the same properties! For example, anti-commutativity (explained below) is special to the \emph{single-qubit} case.}
We have already defined the Pauli operators in \protect\hyperlink{qubits}{Chapter 2}, but we recall their definition here along with a different notation that we sometimes use.

\begin{idea}

\begin{longtable}[]{@{}lc@{}}
\toprule
\endhead
\textbf{Identity} & \(\mathbf{1}= \begin{bmatrix}1&0\\0&1\end{bmatrix}\)\tabularnewline
\textbf{Bit-flip} & \(X\equiv\sigma_x = \begin{bmatrix}0&1\\1&0\end{bmatrix}\)\tabularnewline
\textbf{Bit-phase-flip} & \(Y\equiv\sigma_y = \begin{bmatrix}0&-i\\i&0\end{bmatrix}\)\tabularnewline
\textbf{Phase-flip} & \(Z\equiv\sigma_z = \begin{bmatrix}1&0\\0&-1\end{bmatrix}\)\tabularnewline
\bottomrule
\end{longtable}


\end{idea}

Recalling \protect\hyperlink{qubits}{Chapter 2}, we know that the Pauli operators (as well as the identity operator) are unitary and Hermitian, square to the identity, and anti-commute.\footnote{\[\begin{aligned}XY+YX&=0,\\XZ+ZX&=0,\\YZ+ZY&=0.\end{aligned}\]}

Any \((2\times 2)\) complex matrix \(A\) has a unique expansion in the form
\[
  \begin{aligned}
    A &=
    \begin{bmatrix}
      a_0 + a_z & a_x - i a_y
    \\a_x +i a_y &  a_0 - a_z
    \end{bmatrix}
  \\&= a_0\mathbf{1}+ a_x \sigma_x + a_y \sigma_y + a_z \sigma_z
  \\&= a_0\mathbf{1}+ \vec{a}\cdot\vec{\sigma}.
  \end{aligned}
\]
for some complex numbers \(a_0\), \(a_x\), \(a_y\), and \(a_z\).
Here, \(\vec{a}\) is a vector with three complex components \((a_x, a_y, a_z)\), and \(\vec{\sigma}\) represents the ``vector'' of Pauli matrices \((\sigma_x,\sigma_y,\sigma_z)\).
The algebraic properties of the Pauli matrices can be neatly compacted (see the exercises) into a single expression:

\begin{idea}
The \textbf{multiplication rule}:
\[
  (\vec{a}\cdot\vec{\sigma})\,(\vec{b}\cdot\vec{\sigma})
  = (\vec{a}\cdot\vec{b})\,\mathbf{1}+ i(\vec{a}\times \vec{b})\cdot\vec{\sigma}.
\]

\end{idea}

We also introduce the inner product of two matrices:

\begin{idea}
The \textbf{Hilbert--Schmidt product}:\footnote{The \(\frac12\) coefficient here is simply the normalisation factor, which changes if we consider \emph{multi-qubit} Pauli operators.}
\[
  (A|B) = \frac12 \operatorname{tr}A^\dagger B.
\]

\end{idea}

Recall that the trace of a square matrix \(A\), denoted by \(\operatorname{tr}A\), is defined to be the sum of the elements on the main diagonal of \(A\), and defines a linear mapping: for any scalars \(\alpha\) and \(\beta\),
\[
  \operatorname{tr}(\alpha A+\beta B) = \alpha\operatorname{tr}A +\beta\operatorname{tr}B.
\]
Moreover, the trace is invariant under \emph{cyclic} permutations: e.g.
\[
  \operatorname{tr}(ABC) = \operatorname{tr}(BCA) = \operatorname{tr}(CAB).
\]
Note, however, that this does \emph{not} imply that e.g.~\(\operatorname{tr}(ABC)=\operatorname{tr}(ACB)\).

\hypertarget{unitaries-as-rotations}{%
\subsection{Unitaries as rotations}\label{unitaries-as-rotations}}

Now we can finish off what we started in \protect\hyperlink{qubits}{Chapter 2}: we know how single-qubit state vectors correspond to points on the Bloch sphere, but now we can study how \((2\times 2)\) unitary matrices correspond to \emph{rotations} of this sphere.

Geometrically speaking, the group of unitaries \(\mathrm{U}(2)\) is a three-dimensional sphere \(S^3\) in \(\mathbb{R}^4\).
We often fix the determinant to be \(+1\) and express \((2\times 2)\) unitaries as
\[
  U = u_0\mathbf{1}+ i(u_x\sigma_x + u_y\sigma_y + u_z\sigma_z).
\]
Such matrices form a popular subgroup of \(\mathrm{U}(2)\); it is called the \textbf{special} (meaning the determinant is equal to \(1\)) unitary group, and denoted by \(\mathrm{SU}(2)\).
In quantum theory, any two unitary matrices that differ by some global multiplicative phase factor represent the same physical operation, so we are ``allowed to'' fix the determinant to be \(+1\), and thus restrict ourselves to considering matrices in \(\mathrm{SU}(2)\).
This is a sensible approach, practised by many theoretical physicists, but again, for some historical reasons, the convention in quantum information science does not follow this approach.
For example, phase gates are usually written as
\[
  P_\alpha = \begin{bmatrix}1&0\\0&e^{i\alpha}\end{bmatrix}
\]
rather than
\[
  P_\alpha = \begin{bmatrix}e^{-i\frac{\alpha}{2}}&0\\0&e^{\,i\frac{\alpha}{2}}\end{bmatrix}
\]
Still, sometimes the \(T\) gate
\[
  T
  = \begin{bmatrix}1&0\\0&e^{i\pi/4}\end{bmatrix}
  = \begin{bmatrix}e^{-i\pi/8}&0\\0&e^{i\pi/8}\end{bmatrix}
\]
is called the \(\pi/8\) gate, because of its \(\mathrm{SU}(2)\) form.

So let us write any \((2\times 2)\) unitary, up to an overall phase factor, as
\[
  U
  = u_0\mathbf{1}+ i(u_x \sigma_x + u_y \sigma_y + u_z \sigma_z)
  = u_0\mathbf{1}+ i{\vec{u}}\cdot{\vec{\sigma}}
\]
where \(u_0^2+|\vec{u}|^2=1\).
This additional unitarity restriction allows us to parametrise \(u_0\) and \(\vec{u}\) in terms of a real unit vector \(\vec{n}\), parallel to \(\vec{u}\), and a real angle \(\theta\) so that\footnote{As you can see, we often make progress and gain insights simply by choosing a convenient parametrisation.}
\[
  U
  = (\cos\theta)\mathbf{1}+ (i\sin\theta){\vec{n}}\cdot{\vec{\sigma}}.
\]

An alternative way of writing this expression is\footnote{Although this looks neat and tidy, the normal convention is to parametrise so that \(U=e^{i\frac{-\theta}{2}\vec{n}\cdot\vec{\sigma}}\), and then the direction follows from the right-hand rule, and the rotation corresponds to that in the Bloch sphere. It is a useful exercise to show that you can write \(U\) in this way as well.}
\[
  U
  = e^{i\theta {\vec{n}}\cdot{\vec{\sigma}}},
\]
as follows from the power-series expansion of the exponential.
Indeed, any unitary matrix can always be written in the exponential form as
\[
  \begin{aligned}
    e^{iA}
    &\equiv \mathbf{1}+ iA + \frac{(i A)^2}{1\cdot 2} + \frac{(i A)^3}{1\cdot 2\cdot 3} \ldots
  \\&= \sum_{n=0}^\infty \frac{(i A)^n}{n!}
  \end{aligned}
\]
where \(A\) is a Hermitian matrix.

\begin{idea}
Writing unitary matrices in the form \(e^{iA}\) is analogous to writing complex numbers of unit modulus as \(e^{i\alpha}\) (the so-called \textbf{polar form}).

\end{idea}

Now comes a remarkable connection between two-dimensional unitary matrices and ordinary three-dimensional rotations:

\begin{idea}
The unitary \(U = e^{i\theta \vec{n}\cdot\vec{\sigma}}\) represents a clockwise rotation through the angle \(2\theta\) about the axis defined by \(\vec{n}\).
(\textbf{N.B.} \(2\theta\), \emph{not} \(\theta\)).

\end{idea}

For example,
\[
  \begin{aligned}
    e^{i\theta\sigma_x}
    &=
    \begin{bmatrix}
      \cos\theta & i\sin\theta
    \\i\sin\theta & \cos\theta
    \end{bmatrix}
  \\e^{i\theta\sigma_y}
    &=
    \begin{bmatrix}
      \cos\theta & \sin\theta
    \\-\sin\theta & \cos\theta
    \end{bmatrix}
  \\e^{i\theta\sigma_z}
    &= \begin{bmatrix}e^{i\theta}&0\\0&e^{-i\theta}\end{bmatrix}
  \end{aligned}
\]
represent rotations by \(2\theta\) about the \(x\)-, \(y\)- and \(z\)-axis, respectively.



\begin{figure}[H]

{\centering \includegraphics{iqis-book_files/figure-latex/unnamed-chunk-25-1} 

}

\caption{\(e^{i\theta\vec{n}\cdot\vec{\sigma}}\) rotates the vector \(\vec{s}\) about \(\vec{n}\) by angle \(2\theta\), sending it to a point on the blue circle, whose centre is passed through by \(\vec{n}\).}\label{fig:unnamed-chunk-25}
\end{figure}

Now we can show that the Hadamard gate
\[
  \begin{aligned}
    H
    &= \frac{1}{\sqrt 2}
    \begin{bmatrix}
      1& 1
    \\1 & -1
    \end{bmatrix}
  \\&= \frac{1}{\sqrt 2}(\sigma_x + \sigma_z)
  \\&= (-i)e^{i \frac{\pi}{2} \frac{1}{\sqrt 2}(\sigma_x+\sigma_z)}
  \end{aligned}
\]
(which, up to the overall multiplicative phase factor of \(-i\), is equal to \(e^{i \frac{\pi}{2} \frac{1}{\sqrt 2}(\sigma_x+\sigma_z)}\)) represents rotation about the diagonal \((x+z)\)-axis through the angle \(\pi\).

In somewhat abstract terms, we make the connection between unitaries and rotations by looking how the unitary group \(\mathrm{U}(2)\) acts on the three-dimensional Euclidian space of \((2\times 2)\) Hermitian matrices \emph{with zero trace}.
All such matrices \(S\) can be written as \(S=\vec{s}\cdot\vec{\sigma}\) for some real \(\vec{s}\), i.e.~each matrix is represented by a Euclidean vector \(\vec{s}\) in \(\mathbb{R}^3\).
Now, \(U\in \mathrm{U}(2)\) acts on the Euclidean space of such matrices by \(S\mapsto S' = USU^\dagger\), i.e.
\[
  \vec{s}\cdot\vec{\sigma}
  \longmapsto
  \vec{s'}\cdot\vec{\sigma}
  = U(\vec{s}\cdot\vec{\sigma})U^\dagger
\tag{$\ddagger$}
\]
This is a linear map \(\mathbb{R}^3\to\mathbb{R}^3\), and is thus given by some \((3\times 3)\) real-valued matrix:
\[
  R_U\colon \mathbb{R}^3\to\mathbb{R}^3.
\]
We note that this map is an isometry (a distance preserving operation), since it preserves the scalar product in the Euclidean space: for any two vectors \(\vec{s}\) and \(\vec{v}\),
\[
  \begin{aligned}
    \vec{s'}\cdot\vec{v'}
    &= \frac12\operatorname{tr}[S'V']
  \\&= \frac12\operatorname{tr}[(USU^\dagger)(UVU^\dagger)]
  \\&= \frac12\operatorname{tr}[SV]
  \\&= \vec{s}\cdot\vec{v}
  \end{aligned}
\]
(where \(S=\vec{s}\cdot\vec{\sigma}\) and \(V=\vec{v}\cdot\vec{\sigma}\)) using the cyclic property of the trace.
This means that the matrix \(R_U\) is \emph{orthogonal}.\footnote{Orthogonal transformations preserve the length of vectors as well as the angles between them.}

Furthermore, we can show\footnote{We can also see that \(\det R_U=1\) from the fact that any matrix in \(\mathrm{U}(2)\) can be smoothly connected to the identity.} that \(\det R_U=1\).
But the only isometries in three dimensional Euclidian space (which are described by orthogonal matrices with determinant \(1\)) are rotations.

Thus, in the mathematical lingo, we have established a homomorphism\footnote{Recall that a homomorphism is a structure-preserving map between two algebraic structures of the same type, in our case two groups. An isomorphism between algebraic structures of the same type is one-to-one homomorphism.}
\[
  \begin{aligned}
    \mathrm{U}(2) &\longrightarrow \mathrm{SO}(3)
  \\U &\longmapsto R_U
  \end{aligned}
\]
where \(\mathrm{SO}(3)\) stands for the special orthogonal group in three dimensions (the group of all rotations about the origin of three-dimensional Euclidean space \(\mathbb{R}^3\) under the operation of composition).
It is quite clear from Equation (\(\ddagger\)) that unitary matrices differing only by a global multiplicative phase factor (e.g.~\(U\) and \(e^{i\gamma}U\)) represent the same rotation.

Physicists, however, usually prefer a more direct demonstration, which goes roughly like this.
Consider the map \(\vec{s} \mapsto \vec{s'}\) induced by \(U=e^{i \alpha \vec{n}\cdot\vec{\sigma}}\).
For small values of \(\alpha\), we can write
\[
  \begin{aligned}
    \vec{s'}\cdot\vec{\sigma}
    &= U(\vec{s}\cdot\vec{\sigma}) U^\dagger
  \\&= \Big(
      \mathbf{1}+i\alpha (\vec{n}\cdot\vec{\sigma})+\ldots
    \Big)
    (\vec{s}\cdot\vec{\sigma}) 
    \Big(
      \mathbf{1}- i\alpha(\vec{n}\cdot\vec{\sigma})+\ldots
    \Big).
  \end{aligned}
\]
To the first order in \(\alpha\), this gives
\[
  \vec{s'} \cdot\vec{\sigma}
  = \Big(
    \vec{s} + 2\alpha (\vec{n}\times\vec{s})
  \Big)
  \cdot \vec{\sigma}
\]
that is,
\[
  \vec{s'} =
  \vec{s} + 2\alpha(\vec{n}\times\vec{s})
\]
which we recognise as a good old textbook formula for an infinitesimal clockwise rotation of \(\vec{s}\) about the axis \(\vec{n}\) through the angle \(2\alpha\).

\hypertarget{universality-again}{%
\subsection{Universality, again}\label{universality-again}}

Although this may all seem tediously abstract, it is surprisingly useful.
Take another look at the single qubit interference circuit

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-26-1} \end{center}

and the corresponding sequence of unitary operations
\[
  \begin{aligned}
    H \left(
      e^{-i\frac{\varphi}{2}Z}
    \right) H
    &= e^{-i\frac{\varphi}{2}X}
  \\&= \begin{bmatrix}
      \cos\varphi/2 & -i\sin\varphi/2
    \\-i\sin\varphi/2 & \cos\varphi/2
    \end{bmatrix}
  \end{aligned}
\]

\begin{idea}
The single qubit interference circuit has a simple geometrical meaning: it shows how a rotation about the \(z\)-axis, induced by the phase gate \(P_\varphi\), is turned, by the two Hadamard gates, into a rotation about the \(x\)-axis.

\end{idea}

Now, take a look at this circuit:

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-27-1} \end{center}

What does it represent?
The central part is a rotation by \(\varphi\) about the \(x\)-axis, but is it is sandwiched between two rotations about the \(z\)-axis.
Now we have to appeal to your knowledge of classical mechanics: you may recall that any rotation in the Euclidean space can be performed as a sequence of three rotations: one about \(z\)-axis, one about \(x\)-axis, and one more about the \(z\)-axis.
In this context, this implies that any unitary \(U\), up to a global phase factor, can be written as
\[
  \begin{aligned}
    U(\alpha, \beta, \varphi)
    &= e^{-i\frac{\beta}{2}Z} e^{-i\frac{\varphi}{2}X} e^{-i\frac{\alpha}{2}Z}
  \\&= \begin{bmatrix}
      e^{-i\left(\frac{\alpha+\beta}{2}\right)}\cos\frac{\varphi}{2}
      & ie^{i\left(\frac{\alpha-\beta}{2}\right)}\sin\frac\varphi{2}
    \\ie^{-i\left(\frac{\alpha-\beta}{2}\right)}\sin\frac\varphi{2}
      & e^{i\left(\frac{\alpha+\beta}{2}\right)}\cos\frac\varphi{2}
    \end{bmatrix}.
  \end{aligned}
\]

Thus once you are given a couple of Hadamard gates and an infinite supply of phase gates, so that you can choose the three phases you need, you can construct an arbitrary unitary operation on a single qubit. Needless to say, the two axes in question, \(z\) and \(x\), do not have any special status, geometrically speaking --- if we have rotations about any two orthogonal\footnote{In fact, even this condition isn't necessary! See Figure \ref{fig:two-families-of-circles}} axes then we can create any one-qubit unitary that we want.



\begin{figure}[H]

{\centering \includegraphics{iqis-book_files/figure-latex/two-families-of-circles-1} 

}

\caption{If we can move along the two families of circles, then from any point on the sphere we can reach any other point. The two axes do not even have to be orthogonal: any two different axes will do. Can you see why?}\label{fig:two-families-of-circles}
\end{figure}

Consider the following circuit:

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-28-1} \end{center}

where both \(A\) and \(B\) are unitary operations.
We claim that \emph{any} unitary \(U\) can be represented in this form.

Again, we can prove this geometrically.
The circuit represents two rotations by \(180^\circ\) about two axes obtained by rotating the \(z\)-axis with unitaries \(A\) and \(B\), respectively.
Any rotation in the three-dimensional space is the composition of two rotations by \(180^\circ\), as shown in Figure \ref{fig:two-rotations-by-180}.
The resulting axis of rotation is perpendicular to the two axes about which rotations by \(180^\circ\) are performed, and the angle of the composed rotation is twice the angle between the two axes.



\begin{figure}[H]

{\centering \includegraphics{iqis-book_files/figure-latex/two-rotations-by-180-1} 

}

\caption{Rotating by \(\alpha\) around the \(z\)-axis is the same as the composition of two rotations by \(180^\circ\) around axes which both lie in the \(xy\)-plane, with angle \(\alpha/2\) between them.}\label{fig:two-rotations-by-180}
\end{figure}

\hypertarget{some-quantum-dynamics}{%
\subsection{Some quantum dynamics}\label{some-quantum-dynamics}}

The time evolution of a quantum state is a unitary process which is generated by a Hermitian operator called the \textbf{Hamiltonian}, which we also\footnote{Hopefully it will always be clear from the context which \(H\) refers to Hamiltonian and which \(H\) to Hadamard. Don't confuse the two!} denote by \(H\).
The Hamiltonian contains a complete specification of all interactions within the system under consideration.
In an isolated system, the state vector \(|\psi(t)\rangle\) changes smoothly in time according to the \textbf{Schrödinger equation}:
\[
  \frac{\mathrm{d}}{\mathrm{d}t} |\psi(t)\rangle
  =-\frac{i}{\hbar} H |\psi(t)\rangle.
\]

For \textbf{time-independent} Hamiltonians (i.e.~where \(|\psi(t)\rangle=|\psi\rangle\) has no \(t\)-dependence), the formal solution of this reads\footnote{Here \(\hbar\) denotes \textbf{Planck's constant}, which has the value \(\hbar = 1.05\times 10^{-34}\,\text{ Js}\). However, theorists always choose to work with a system of units where \(\hbar = 1\).}
\[
  \begin{gathered}
    |\psi(t)\rangle
    = U(t)|\psi(0)\rangle
  \\\quad\text{where}\quad
    U(t)
    = e^{-\frac{i}{\hbar}Ht}.
  \end{gathered}
\]

Now, to relate this to the earlier parts of this chapter, we note that the Hamiltonian of a qubit can always be written in the form \(H = E_0\mathbf{1}+\omega(\vec{n}\cdot\vec{\sigma})\), hence
\[
  \begin{aligned}
    U(t)
    &= e^{-i\omega t \vec n\cdot\vec\sigma}
  \\&= (\cos\omega t)\mathbf{1}- (i\sin\omega t)\vec{n}\cdot\vec{\sigma}
  \end{aligned}
\]
which is a rotation with angular frequency \(\omega\) about the axis defined by the unit vector \(\vec n\).

\textbf{!!!TO-DO!!! the \(4\pi\) world of qubits}

\hypertarget{remarks-and-exercises-3}{%
\subsection{\texorpdfstring{\emph{Remarks and exercises}}{Remarks and exercises}}\label{remarks-and-exercises-3}}

\hypertarget{orthonormal-pauli-basis}{%
\subsubsection{Orthonormal Pauli basis}\label{orthonormal-pauli-basis}}

Show that \(\{\mathbf{1},\sigma_x,\sigma_y,\sigma_z\}\) is an orthonormal basis with respect to the Hilbert-Schmidt product in the space of complex \((2\times 2)\) matrices.

\hypertarget{pauli-matrix-expansion-coefficients}{%
\subsubsection{Pauli matrix expansion coefficients}\label{pauli-matrix-expansion-coefficients}}

Recall that any \((2\times 2)\) complex matrix \(A\) has a unique expansion in the form
\[
  \begin{aligned}
    A &=
    \begin{bmatrix}
      a_0 + a_z & a_x - i a_y
    \\a_x +i a_y &  a_0 - a_z
    \end{bmatrix}
  \\&= a_0\mathbf{1}+ a_x \sigma_x + a_y \sigma_y + a_z \sigma_z
  \\&= a_0\mathbf{1}+ \vec{a}\cdot\vec{\sigma}.
  \end{aligned}
\tag{$\star$}
\]
for some complex numbers \(a_0\), \(a_x\), \(a_y\), and \(a_z\).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Show that the coefficients \(a_k\) (for \(k=x,y,z\)) are given by the inner product \(a_k = (\sigma_k|A) = \frac12\operatorname{tr}\sigma_k A\).
\end{enumerate}

In these notes, we usually deal with matrices that are Hermitian (\(A=A^\dagger\)) or unitary (\(AA^\dagger=\mathbf{1}\)).
It is easy to see that, if \(A\) is Hermitian, then \(a_0\) and the three components of \(\vec{a}\) are all real.
The \((2\times 2)\) unitaries are usually parametrised as
\[
  U = e^{i\gamma}\Big(u_0\mathbf{1}+ i(u_x\sigma_x + u_y\sigma_y + u_z\sigma_z)\Big)
\]
where \(e^{i\gamma}\) is an overall multiplicative phase factor, with \(\gamma\) real, and \(u_0\) and the three components \(u_x\), \(u_y\), \(u_z\) are all real numbers.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Show that the unitarity condition implies that
  \[
     u_0^2 + u_x^2 + u_y^2 + u_z^2 = 1
   \]
  and show, using this parametrisation, that the determinant of \(U\) is \(e^{i2\gamma}\).
\end{enumerate}

\hypertarget{linear-algebra-of-the-pauli-vector}{%
\subsubsection{Linear algebra of the Pauli vector}\label{linear-algebra-of-the-pauli-vector}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Show that \(\frac12\operatorname{tr}(\vec{a}\cdot\vec{\sigma})(\vec{b}\cdot\vec{\sigma}) = \vec{a}\cdot\vec{b}\). \emph{(You may find \protect\hyperlink{cross-product-identity}{a certain identity involving the cross product} helpful.)}
\item
  Show that any \(\vec{n}\cdot\vec{\sigma}\) has eigenvalues \(\pm|\vec{n}|\).
\item
  Show that, if \(\vec{n}\cdot\vec{m}=0\), then the operators \(\vec{n}\cdot\vec{\sigma}\) and \(\vec{m}\cdot\vec{\sigma}\) anticommute.
\end{enumerate}

\hypertarget{matrix-euler-formula}{%
\subsubsection{Matrix Euler formula}\label{matrix-euler-formula}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Show that, if \(A^2=\mathbf{1}\), then we can manipulate the power series expansion of \(e^{iA}\) into a simple expression: for any real \(\alpha\),
  \[
     e^{i\alpha A}
     = (\cos\alpha)\mathbf{1}+ (i\sin\alpha)A.
   \]
\item
  Show that any \((2\times 2)\) unitary matrix \(U\) can be written, up to an overall multiplicative phase factor, as
  \[
     U
     = e^{i \theta \vec{n}\cdot\vec{\sigma}}
     = (\cos\theta)\mathbf{1}+ (i\sin\theta)\vec{n}\cdot\vec{\sigma}.
   \]
  (The argument here is the same as the argument that \(e^{i\theta}=\cos\theta +i\sin\theta\)).
\end{enumerate}

\hypertarget{special-orthogonal-matrix-calculations}{%
\subsubsection{Special orthogonal matrix calculations}\label{special-orthogonal-matrix-calculations}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Show that \(\operatorname{tr}\sigma_x\sigma_y\sigma_z = 2i\).
\item
  Consider
  \[
     U(\vec e_k\cdot\sigma_k)U^\dagger=U\sigma_kU^\dagger={\vec f_k}\cdot\vec\sigma.
   \]
  So \(U\) maps the unit vectors \(\vec e_x\), \(\vec e_y\), and \(\vec z_z\), (along the \(x\)-, \(y\)-, and \(z\)-axis, respectively), to new unit vectors \(\vec f_x\), \(\vec f_y\), and \(\vec f_z\).
  We already know that, in Euclidean space, this transformation is described by a \((3\times 3)\) orthogonal matrix \(R_U\).
  How are the three vectors \(\vec f_x\), \(\vec f_y\), and \(\vec f_z\) related to the entries in matrix \(R_U\)?
\item
  Show that
  \[
     \begin{aligned}
       \operatorname{tr}\sigma_x\sigma_y\sigma_z
       &= \operatorname{tr}({\vec f_x}\cdot\vec\sigma)( {\vec f_y}\cdot\vec\sigma)({\vec f_z}\cdot\vec\sigma)
     \\&= 2i\det R_U
     \end{aligned}
   \]
  (which implies that \(\det R_U=1\)).
\item
  Use the orthonormality of the Pauli basis along with Equation (\(\ddagger\)) to show that the elements of the matrix \(R=R_U\) can be expressed in terms of those of the matrix \(U\), in the form
  \[
     R_{ij}=\frac12\operatorname{tr}\left(\sigma_i U\sigma_j U^\dagger\right).
   \]
  Here, \(i\) and \(j\) take values in \(\{1,2,3\}\), and \(\sigma_1\equiv\sigma_x\), \(\sigma_2\equiv\sigma_y\), \(\sigma_3\equiv\sigma_z\).
\end{enumerate}

\hypertarget{phase-as-rotation}{%
\subsubsection{Phase as rotation}\label{phase-as-rotation}}

Show that the phase gate
\[
  P_\varphi = \begin{bmatrix}1&0\\0&e^{i\varphi}\end{bmatrix}
\]
represents an anticlockwise rotation about the \(z\)-axis through the angle \(\varphi\).

\textbf{Hint.} It might be helpful to start with the \(\mathrm{SU}(2)\) version of the phase gate:
\[
  \begin{aligned}
    P_\varphi
    &= e^{-i\frac{\varphi}{2}\sigma_z}
  \\&= \begin{bmatrix}
      e^{-i \frac{\varphi}{2}}& 0
    \\0 & e^{i \frac{\varphi}{2}}
    \end{bmatrix}
    \quad\longrightarrow\quad
    R
  \\&= \begin{bmatrix}
      \cos \varphi & -\sin \varphi & 0
    \\\sin \varphi & \cos \varphi & 0
    \\0 & 0 & 1
    \end{bmatrix}
  \end{aligned}
\]

\hypertarget{geometry-of-the-hadamard}{%
\subsubsection{Geometry of the Hadamard}\label{geometry-of-the-hadamard}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Express the Hadamard gate \(H\) in terms of \(\vec{n}\cdot\vec{\sigma}\), and show that
  \[
    \begin{aligned}
   HZH&=X
    \\HXH&=Z
    \\HYH&=-Y.
    \end{aligned}
  \]
\item
  Show that the Hadamard gate \(H\) turns rotations about the \(x\)-axis into rotations about the \(z\)-axis, and vice versa.
  That is,
  \[
     \begin{aligned}
       H \left(
         e^{-i\frac{\varphi}{2}Z}
       \right) H
       &= e^{-i\frac{\varphi}{2}X}
     \\H \left(
         e^{-i\frac{\varphi}{2}X}
       \right) H
       &= e^{-i\frac{\varphi}{2}Z}.
     \end{aligned}
   \]
\end{enumerate}

\hypertarget{swiss-granite-fountain}{%
\subsubsection{Swiss Granite Fountain}\label{swiss-granite-fountain}}

In the Singapore Botanic Gardens, there is a sculpture by Ueli Fausch called ``Swiss Granite Fountain''.
It is a spherical granite ball which measures 80cm in diameter and weighs 700kg, and is kept afloat by strong water pressure directed through the basal block.
It is easy to set the ball in motion, and it keeps rotating in whatever way you start for a long time.
Suppose you are given access to this ball only near the top, so that you can push it to make it rotate around any horizontal axis, but you don't have enough of a grip to make it turn around the vertical axis.
Can you make it rotate around the vertical axis anyway?

\hypertarget{dynamics-in-a-magnetic-field}{%
\subsubsection{Dynamics in a magnetic field}\label{dynamics-in-a-magnetic-field}}

A qubit (spin one-half particle) initially in state \(|0\rangle\) (spin up) is placed in a uniform magnetic field.
The interaction between the field and the qubit is described by the Hamiltonian
\[
  H
  = \omega
  \begin{bmatrix}
    0 & - i
  \\i & 0
  \end{bmatrix}
\]
where \(\omega\) is proportional to the strength of the field.\footnote{In Earth's magnetic field, which is about \(0.5\) gauss, the value of \(\omega\) is of the order of \(10^6\) cycles per second.}
What is the state of the qubit after time \(t=\pi/4\omega\)?

\hypertarget{measurements}{%
\section{Measurements}\label{measurements}}

\begin{quote}
About the \textbf{Hilbert-space formalism} of quantum theory, and the role of \textbf{measurements} in quantum information theory, as well as introducing the quantum dramas of Alice and Bob.
\end{quote}

Eventually, we have to talk about quantum measurements, since, at some point, someone has to look at a measuring device and register the outcome of whatever quantum circuits we've been designing.
It turns out that this is a bit more tricky than one might think.
Quantum measurement is not a passive acquisition of information: if you measure, you disturb.
Even though it is a physical process, like any other quantum evolution, it is traditionally described by a different set of mathematical tools.

\hypertarget{hilbert-spaces-briefly}{%
\subsection{Hilbert spaces, briefly}\label{hilbert-spaces-briefly}}

A formal mathematical setting for a quantum system is that of a \textbf{Hilbert space} \(\mathcal{H}\), i.e.~a vector space with an inner product.
The result of any preparation of a system is represented by some unit vector \(|\psi\rangle\in \mathcal{H}\), and any test is represented by some other unit vector \(|e\rangle\in \mathcal{H}\).\footnote{The term ``Hilbert space'' used to be reserved for an infinite-dimensional inner product space that is \textbf{complete}, i.e.~such that every Cauchy sequence in the space converges to an element in the space. Nowadays, as in these notes, the term includes finite-dimensional spaces, which automatically satisfy the condition of completeness.}
The inner product of these two vectors, \(\langle e|\psi\rangle\), gives the probability amplitude that an object prepared in state \(|\psi\rangle\) will pass a test for being in state \(|e\rangle\).
Probabilities are obtained by squaring absolute values of probability amplitudes:
\[
  |\langle e|\psi\rangle|^2
  = \langle\psi|e\rangle\langle e|\psi\rangle.
\]
After the test, in which the object was found to be in state \(|e\rangle\), say, the object forgets about its previous state \(|\psi\rangle\) and is, indeed, actually now in state \(|e\rangle\).
This is the mysterious \textbf{quantum collapse} which we will briefly discuss later on.

A more complete test involves multiple states \(e_k\) that form an orthonormal basis \(\{|e_1\rangle,\ldots,|e_n\rangle\}\).
These states are perfectly distinguishable from each other: the condition \(\langle e_k|e_l\rangle = \delta_{kl}\) implies that a quantum system prepared in state \(|e_l\rangle\) will never be found in state \(|e_k\rangle\) (unless \(k=l\)).
The probability amplitude that the system in state \(|\psi\rangle\) will be found in state \(|e_k\rangle\) is \(\langle e_k|\psi\rangle\) and, given that the vectors \(|e_k\rangle\) span the whole vector space, the system will be always found in one of the basis states, whence
\[
  \sum_k |\langle e_k|\psi\rangle|^2 = 1.
\]
As a result:

\begin{idea}
A \textbf{complete} measurement in quantum theory is determined by the choice of an orthonormal basis \(\{|e_i\rangle\}\) in \(\mathcal{H}\), and every such basis (in principle) represents a possible complete measurement.

\end{idea}

\hypertarget{back-to-qubits-complete-measurements}{%
\subsection{Back to qubits; complete measurements}\label{back-to-qubits-complete-measurements}}

\begin{idea}
A \textbf{projector} is any Hermitian operator \(P=P^\dagger\) which is idempotent (\(P^2=P\)).
The rank of \(P\) is evaluated using \(\operatorname{tr}(P)\).
In the Dirac notation, \(|e\rangle\langle e|\) is a rank one projector on the subspace spanned by the unit vector \(|e\rangle\), and it acts on any vector \(|v\rangle\) as \((|e\rangle\langle e|)|v\rangle = |e\rangle\langle e|v\rangle\).

\end{idea}

The most common measurement in quantum information science is the standard measurement on a qubit, also referred to as the measurement in the \textbf{standard} (or \textbf{computational}) basis \(\{|0\rangle,|1\rangle\}\).
When we draw circuit diagrams it is tacitly assumed that such a measurement is performed on each qubit at the end of quantum evolution.

\begin{figure}[H]

{\centering \includegraphics{iqis-book_files/figure-latex/standard-basis-measurement-1} 

}

\caption{The standard (computational) basis defines the standard measurements.}\label{fig:standard-basis-measurement}
\end{figure}

However, if we want to emphasise the role of the measurement, then we can include it explicitly in the diagram as a special quantum gate, e.g.~as

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-29-1} \end{center}

or, in an alternative notation, as

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-30-1} \end{center}

As we can see, if the qubit is prepared in state \(|\psi\rangle = \alpha_0|0\rangle + \alpha_1|1\rangle\) and subsequently measured in the standard basis state, then the outcome is \(|k\rangle\) (for \(k=0,1\)) with probability\footnote{This slick argument is a good example of how nice the bra-ket notation can be.}
\[
  \begin{aligned}
    |\alpha_k|^2
    &= |\langle k|\psi\rangle|^2
  \\&= \underbrace{\langle\psi|k\rangle}_{\alpha_k^\star}
    \underbrace{\langle k|\psi\rangle}_{\alpha_k}
  \\&= \langle\psi| \underbrace{|k\rangle\langle k|}_{\text{projector}} |\psi\rangle
  \\&= \langle\psi|P_k|\psi\rangle
  \end{aligned}
\]
where \(P_k=|k\rangle\langle k|\) is the projector on \(|k\rangle\).
If the outcome of the measurement is \(k\), then the output state of the measurement gate is \(|k\rangle\).
The original state \(|\psi\rangle\) is \emph{irretrievably lost}.
This sudden change of the state, from the pre-measurement state \(|\psi\rangle\) to the post-measurement state, either \(|0\rangle\) or \(|1\rangle\), is often called a \textbf{collapse} or a \textbf{reduction} of the state.

So it looks like there are two distinct ways for a quantum state to change: on the one hand we have unitary evolutions, and on the other hand we have an abrupt change during the measurement process.
Surely, the measurement process is not governed by any different laws of physics?

No, it is not!

A measurement is a physical process and can be explained without any ``collapse'', but it is usually a complicated process in which one complex system (a measuring apparatus or an observer) interacts and gets correlated with a physical system being measured.
We will discuss this more later on, but for now let us accept a ``collapse'' as a \emph{convenient mathematical shortcut}, and describe it in terms of projectors rather than unitary operators.

\hypertarget{the-projection-rule-incomplete-measurements}{%
\subsection{The projection rule; incomplete measurements}\label{the-projection-rule-incomplete-measurements}}

So far we have identified measurements with orthonormal bases, or, if you wish, with a set of orthonormal projectors on the basis vectors.

\begin{idea}

\begin{itemize}
\tightlist
\item
  The \textbf{orthonormality} condition:
  \[
      \langle e_k|e_l\rangle = \delta_{kl}
    \]
  i.e.~the basis consists of unit vectors that are pairwise orthogonal.
\item
  The \textbf{completeness} condition:
  \[
      \sum_k|e_k\rangle\langle e_k| = \mathbf{1}
    \]
  i.e.~\emph{any} vector in \(\mathcal{H}\) can be expressed as the sum of the orthogonal projections on the \(|e_k\rangle\).
\end{itemize}


\end{idea}

Given a quantum system in state \(|\psi\rangle\) such that \(|\psi\rangle = \sum_k \alpha_k|e_k\rangle\), we can write
\[
  \begin{aligned}
    |\psi\rangle
    &= \mathbf{1}|\psi\rangle
  \\&= \sum_k (|e_k\rangle\langle e_k|) |\psi\rangle
  \\&= \sum_k |e_k\rangle\langle e_k|\psi\rangle
  \\&= \sum_k |e_k\rangle\alpha_k
  \\&= \sum_k \alpha_k|e_k\rangle.
  \end{aligned}
\]
This says that the measurement in the basis \(\{|e_i\rangle\}\) gives the outcome labelled by \(e_k\) with probability
\[
  |\langle e_k|\psi\rangle|^2 = \langle\psi|e_k\rangle\langle e_k|\psi\rangle
\]
and leaves the system in state \(|e_k\rangle\).
This is a \emph{complete} measurement, which represents the best we can do in terms of resolving state vectors in the basis states.
But sometimes we do not want our measurement to distinguish all the elements of an orthonormal basis.

For example, a complete measurement in a four-dimensional Hilbert space will have four distinct outcomes: \(|e_1\rangle\), \(|e_2\rangle\), \(|e_3\rangle\), and \(|e_4\rangle\), but we may want to lump together some of the outcomes and distinguish, say, only between \(\{|e_1\rangle\), \(|e_2\rangle\}\), and \(\{|e_3\rangle,|e_4\rangle\}\).
In other words, we might be trying to distinguish one \emph{subspace} from another, without separating vectors that lie in the same subspace.
Such measurements (said to be \textbf{incomplete}) are indeed possible, and they can be less disruptive than the complete measurements.

\begin{idea}
Intuitively, an incomplete measurement has fewer outcomes and is hence less informative, but the state after such a measurement is usually less disturbed.

\end{idea}

In general, instead of projecting on one dimensional subspaces spanned by vectors from an orthonormal basis, we can decompose our Hilbert space into mutually orthogonal subspaces of various dimensions and project on them.

\begin{idea}

\begin{itemize}
\tightlist
\item
  The orthogonality conditions for projectors:
  \[
      P_k P_l = P_k\delta_{kl}
    \]
\item
  The projector decomposition of the identity:
  \[
      \sum_k P_k = \mathbf{1}
    \]
\end{itemize}


\end{idea}

For any decomposition of the identity into orthogonal projectors \(P_k\), there exists a measurement that takes a quantum system in state \(|\psi\rangle\), outputs label \(k\) with probability \(\langle\psi|P_k|\psi\rangle\), and leaves the system in the state \(P_k|\psi\rangle\) (multiplied by the normalisation factor, i.e.~divided by the length of \(P_k|\psi\rangle\)):
\[
  |\psi\rangle
  \mapsto
  \frac{P_k|\psi\rangle}{\sqrt{\langle\psi|P_k|\psi\rangle}}.
\]

\hypertarget{example-of-an-incomplete-measurement}{%
\subsection{Example of an incomplete measurement}\label{example-of-an-incomplete-measurement}}

Consider a three-dimensional Hilbert space \(\mathcal{H}\), and the two orthogonal projectors
\[
  \begin{aligned}
    P &= |e_1\rangle\langle e_1| + |e_2\rangle\langle e_2|
  \\Q &= |e_3\rangle\langle e_3|
  \end{aligned}
\]
that form the decomposition of the identity: \(P+Q=\mathbf{1}\).
Suppose that a physical system is prepared in state \(|\psi\rangle = \alpha_1|e_1\rangle + \alpha_2|e_2\rangle + \alpha_3|e_3\rangle\).
Ideally, we would like to perform a complete measurement that would resolve the state \(|v\rangle\) into the three basis states, but suppose our experimental apparatus is not good enough, and lumps together \(|e_1\rangle\) and \(|e_2\rangle\).
In other words, it can only differentiate between the two subspaces associated with projectors \(P\) and \(Q\).

The apparatus, in this incomplete measurement, may find the system in the subspace associated with \(P\).
This happens with probability
\[
  \begin{aligned}
    \langle\psi|P|\psi\rangle
    &= \langle\psi|e_1\rangle \langle e_1|\psi\rangle + \langle\psi|e_2\rangle \langle e_2|\psi\rangle
  \\&= |\alpha_1|^2 + |\alpha_2|^2,
  \end{aligned}
\]
and the state right after the measurement is the normalised vector \(P|\psi\rangle\), i.e.
\[
  \frac{\alpha_1|e_1\rangle+\alpha_2|e_2\rangle}{\sqrt{|\alpha_1|^2 + |\alpha_2|^2}}.
\]

The measurement may also find the system in the subspace associated with \(Q\) with the probability \(\langle\psi|Q|\psi\rangle = |\alpha_3|^2\), resulting in the post-measurement state \(|e_3\rangle\).

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-31-1} \end{center}

\hypertarget{observables}{%
\subsection{Observables}\label{observables}}

An \textbf{observable} \(A\) is a measurable physical property which has a numerical value, for example, spin or momentum or energy.
The term ``observable'' also extends to any basic measurement in which each outcome is associated with a numerical value.
If \(\lambda_k\) is the numerical value associated with outcome \(|e_k\rangle\) then we say that the observable \(A\) is \textbf{represented} by the operator
\[
  \begin{aligned}
    A
    &= \sum_k \lambda_k |e_k\rangle\langle e_k|
  \\&= \sum_k \lambda_k P_k,
  \end{aligned}
\]
where \(\lambda_k\) is now the eigenvalue corresponding to the eigenvector \(|e_k\rangle\), or the projector \(P_k\).

\begin{idea}
Recall the following types of operator:

\begin{longtable}[]{@{}ll@{}}
\toprule
\endhead
\textbf{normal} & \(AA^\dagger = A^\dagger A\)\tabularnewline
\textbf{unitary} & \(AA^\dagger = A^\dagger A = \mathbf{1}\)\tabularnewline
\textbf{Hermitian}, or \textbf{self-adjoint} & \(A^\dagger = A\)\tabularnewline
\textbf{positive semi-definite} & \(\langle v|A|v\rangle\geqslant 0\) for all \(|v\rangle\)\tabularnewline
\bottomrule
\end{longtable}

Note that an operator \(A\) is normal if and only if it is unitarily diagonalisable, and that both unitary and Hermitian operators are normal.

\end{idea}

Conversely, to any normal operator \(A\) we can associate a measurement defined by the eigenvectors of \(A\), which form an orthonormal basis, and use the eigenvalues of \(A\) to label the outcomes of this measurement.
If we choose the eigenvalues to be real numbers then \(A\) becomes a Hermitian operator.
For example, the standard measurement on a single qubit is often called the \textbf{\(Z\)-measurement}, because the Pauli \(Z\) operator can be diagonalised in the standard basis and written as \(Z = (+1)|0\rangle\langle 0| + (-1)|1\rangle\langle 1|\).
The two outcomes, \(|0\rangle\) and \(|1\rangle\), are now labelled as \(+1\) and \(-1\), respectively.
Using the same association we also have the \(X\)- and the \(Y\)-measurements, defined by the Pauli \(X\) and \(Y\) operators, respectively.

\begin{idea}
The outcomes can be labelled by any symbols of your choice; it is the \emph{decomposition} of the Hilbert space into \emph{mutually orthogonal subspaces} that defines a measurement, not the labels.

\end{idea}

This said, labelling outcomes with real numbers is very useful.\footnote{Some textbooks describe observables in terms of Hermitian operators, claiming that the corresponding operators \emph{have to} be Hermitian ``because the outcomes are real numbers''. This is actually a bit backwards. As we say above, the labels can be arbitrary, but, since real number labels are often useful (as we're about to justify), we tend to only work with Hermitian operators.}
For example, the expected value \(\langle A\rangle\), which is the average of the numerical values \(\lambda_k\) weighted by their probabilities, is a very useful quantity and can be easily expressed in terms of the operator \(A\) as \(\langle\psi|A|\psi\rangle\), as follows:
\[
  \begin{aligned}
    \sum_k \lambda_k \Pr (\text{outcome k})
    &= \sum_k \lambda_k |\langle e_k|\psi\rangle|^2
  \\&= \sum_k\lambda_k \langle\psi|e_k\rangle\langle e_k|\psi\rangle
  \\&= \langle\psi| \left( \sum_k\lambda_k|e_k\rangle\langle e_k| \right)|\psi\rangle
  \\&= \langle\psi|A|\psi\rangle.
  \end{aligned}
\]
To be clear, this is not a value we expect to see in any particular experiment.
Instead, imagine a huge number of quantum objects, all prepared in the state \(|\psi\rangle\) and think about the observable \(A\) being measured on each of the objects.
Statistically we then expect the average of our measurement results to be roughly \(\langle A\rangle\).
Note that when \(A\) is a projector then \(\langle\psi|A|\psi\rangle\) is the probability of the outcome associated with \(A\).

\hypertarget{compatible-observables-and-the-uncertainty-relation}{%
\subsection{Compatible observables and the uncertainty relation}\label{compatible-observables-and-the-uncertainty-relation}}

\textbf{!!!TO-DO!!!}

\hypertarget{quantum-communication}{%
\subsection{Quantum communication}\label{quantum-communication}}

Now is a good moment to introduce Alice and Bob (not their real names): our two protagonists who always need to communicate with each other.
These two play the major role in many communication dramas, though they remain rather lacking in character development.

This time Alice is sending quantum states to Bob, and Bob does his best to identify them correctly by choosing appropriate measurements.
Let us start with a simple observation: if a quantum state of the carrier of information is described by a state vector in a \(2^n\)-dimensional Hilbert space, then the carrier can carry at most \(n\) bits of information.
For example, Alice can choose one of the \(2^n\) states from a pre-agreed orthonormal basis \(\{|e_k\rangle\}\), and Bob will be able to distinguish them reliably by choosing the \(\{|e_k\rangle\}\) basis for his measurement.

But can Alice and Bob do better than that?
Can Alice send more than \(n\) bits of information per carrier by encoding them in states \(|s_1\rangle,\ldots,|s_N\rangle\) where \(N \geqslant 2^n\)?
Can Bob choose a clever measurement and reliably distinguish between all such states?

The answer is \emph{no}.

\hypertarget{basic-quantum-coding-and-decoding}{%
\subsection{Basic quantum coding and decoding}\label{basic-quantum-coding-and-decoding}}

Suppose Alice randomly chooses one of the pre-agreed \(N\) signal states \(|s_k\rangle\) and sends it to Bob, who tries to identify the signal states by performing a measurement defined by the projectors \(P_l\).
Let \(P\) be a projector on a subspace spanned by the signal states \(|s_k\rangle\), i.e.~\(P|s_k\rangle = |s_k\rangle\).
The dimension \(d\) of this subspace is given by \(d = \operatorname{tr}P\).
We shall assume, without any loss of generality, that Bob designed his measurement in such a way that, whenever he gets outcome \(P_k\), he concludes that Alice sent state \(|s_k\rangle\).
His probability of success is given by
\[
  \Pr(\text{success})
  = \frac{1}{N} \sum_k \langle s_k|P_k|s_k\rangle
\]
which is the probability that signal state \(|s_k\rangle\) is selected (here equal to \(1/N\), since all the signal states are equally likely) times the probability that the selected signal state is correctly identified by Bob (which is \(\langle s_k|P_k|s_k\rangle\)), and we sum over all signal states.

\begin{idea}
We have the following \textbf{trace identities}:

\begin{itemize}
\tightlist
\item
  \(\operatorname{tr}(ABC) = \operatorname{tr}(BCA) = \operatorname{tr}(CAB)\)
\item
  \(\operatorname{tr}|a\rangle\langle b| = \langle b|a\rangle\)
\item
  \(\operatorname{tr}A|a\rangle\langle b| = \langle b|A|a\rangle\)
\item
  \(\operatorname{tr}BP \leqslant\operatorname{tr}B\) for any positive semi-definite \(B\) and projector \(P\).
\end{itemize}

(To prove this last identity, consider the projector \(Q=\mathbf{1}-P\), and note that
\[
  \begin{aligned}
    \operatorname{tr}B
    &= \operatorname{tr}B(P+Q)
  \\&= \operatorname{tr}BP + \operatorname{tr}BQ
  \end{aligned}
\]
and that \(\operatorname{tr}BQ\) is non-negative.)

\end{idea}

Let us use this case to practice some of the trace identities.
It is often convenient to write expressions such as \(\langle\psi|A|\psi\rangle\) in terms of the trace: for any vector \(|\psi\rangle\) and operator \(A\) we have
\[
  \begin{aligned}
    \langle\psi|A|\psi\rangle
    &= \operatorname{tr}(A|\psi\rangle\langle\psi|)
  \\&= \operatorname{tr}(|\psi\rangle\langle\psi| A).
  \end{aligned}
\]
In our case,
\[
  \begin{aligned}
    \Pr(\text{success})
    &= \frac{1}{N} \sum_k \langle s_k|P_k|s_k\rangle
  \\&= \frac{1}{N} \sum_k \langle s_k|PP_kP|s_k\rangle
  \\&= \frac{1}{N} \sum_k \operatorname{tr}(PP_kP|s_k\rangle\langle s_k|)
  \end{aligned}
\]
where we have also used that \(P|s_k\rangle=|s_k\rangle\).
Let us bound this expression above by using the aforementioned trace identities:
\[
  \begin{aligned}
    \sum_k\frac{1}{N} \langle s_k|P_k|s_k\rangle
    &= \frac{1}{N} \sum_k \operatorname{tr}(PP_kP|s_k\rangle\langle s_k|)
  \\&\leqslant\frac{1}{N} \sum_k \operatorname{tr}(PP_kP)
  \\&= \frac{1}{N} P\left(\sum_k P_k\right)P
  \\&= \frac{1}{N} \operatorname{tr}(P\mathbf{1}P)
  \\&= \frac{1}{N} \operatorname{tr}(P)
  \\&= \frac{d}{N}.
  \end{aligned}
\]

So if Alice encodes \(N\) equally likely messages as states in a quantum system that, mathematically speaking, lives in the Hilbert space of dimension \(d\), and if Bob decodes by performing a measurement and inferring the message from the result, then Bob's probability of success is bounded by \(\frac{d}{N}\).
If the number \(N\) of possible signals exceeds the dimension \(d\), then Bob will not be able to reliably distinguish between the signals by any measurement.
In particular:

\begin{idea}
In this setting\footnote{There is something called \href{https://en.wikipedia.org/wiki/Superdense_coding}{\textbf{superdense coding}}, where one qubit can actually store \emph{two} classical bits, but this relies on Alice and Bob both having access to a shared entangled state right from the very start of the experiment.}, one qubit can store \emph{at most} one bit of information that can \emph{reliably} be read by a measurement.

\end{idea}

\hypertarget{distinguishability-of-non-orthogonal-states}{%
\subsection{Distinguishability of non-orthogonal states}\label{distinguishability-of-non-orthogonal-states}}

We have already mentioned that non-orthogonal states cannot be reliably distinguished, and now it is time to make this statement more precise.
Suppose Alice sends Bob a message by choosing one of the two non-orthogonal states \(|s_1\rangle\) and \(|s_2\rangle\), where both are equally likely to be chosen.
What is the probability that Bob will decode the message correctly and what is the best (i.e.~the one that maximises this probability) measurement?
As a general rule, before you embark on any calculations, check for symmetries, special cases, and anything that may help you to visualise the problem and make intelligent guesses about the solution.
One of the most powerful research tools is a good guess.
In fact, this is what real research is about: educated guesses that guide your calculations.
In this particular case you can use symmetry arguments to guess the optimal measurement --- see Figure \ref{fig:optimal-measurement}.
Once you have guessed the answer, you might as well do the calculations.



\begin{figure}[H]

{\centering \includegraphics{iqis-book_files/figure-latex/optimal-measurement-1} 

}

\caption{The optimal measurement to distinguish between the two equally likely non-orthogonal signal states \(|s_1\rangle\) and \(|s_2\rangle\) is described by the two orthogonal vectors \(|d_1\rangle\) and \(|d_2\rangle\) placed symmetrically around the signal states.}\label{fig:optimal-measurement}
\end{figure}

Suppose Bob's measurement is described by projectors \(P_1\) and \(P_2\), with the inference rule ``\(P_1\) implies \(|s_1\rangle\); \(P_2\) implies \(|s_2\rangle\)''.
Then
\[
  \begin{aligned}
    \Pr(\text{success})
    &= \frac12\left(
        \langle s_1|P_1|s_1\rangle + \langle s_2|P_2|s_2\rangle
      \right)
  \\&= \frac12\left(
        \operatorname{tr}P_1|s_1\rangle\langle s_1| + \operatorname{tr}P_2|s_2\rangle\langle s_2|
      \right)
  \\&= \frac12\left(
        \operatorname{tr}P_1|s_1\rangle\langle s_1| + \operatorname{tr}(\mathbf{1}-P_1)|s_2\rangle\langle s_2|
      \right)
  \\&= \frac12\left(
        1 + \operatorname{tr}P_1\left( |s_1\rangle\langle s_1| - |s_2\rangle\langle s_2| \right)
      \right).
\end{aligned}
\]
Let us look at the operator \(D = |s_1\rangle\langle s_1| - |s_2\rangle\langle s_2|\) that appears in the last expression.
This operator acts on the subspace spanned by \(|s_1\rangle\) and \(|s_2\rangle\); it is Hermitian; the sum of its two (real) eigenvalues is zero; and \(\operatorname{tr}D=\langle s_1|s_1\rangle-\langle s_2|s_2\rangle=0\).
Let us write \(D\) as \(\lambda(|d_+\rangle\langle d_+| - |d_-\rangle\langle d_-|)\), where \(|d_\pm\rangle\) are the two orthonormal eigenstates of \(D\), and \(\pm\lambda\) are the corresponding eigenvalues.
Now we write
\[
\begin{aligned}
  \Pr (\text{success})
  &= \frac12\left(
      1 + \lambda\operatorname{tr}P_1\left( |d_+\rangle\langle d_+|-|d_-\rangle\langle d_-| \right)
    \right)
\\&\leqslant\frac12\left(
      1+\lambda \langle d_+|P_1|d_+\rangle
    \right)
\end{aligned}
\]
where we have dropped the non-negative term \(\operatorname{tr}P_1|d_-\rangle\langle d_-|\).
In fact, it is easy to see that we will maximise the expression above by choosing \(P_1 = |d_+\rangle\langle d_+|\) (and \(P_2 = |d_-\rangle\langle d_-|\)).
The probability of success is then bounded by \(\frac12(1+\lambda)\).
All we have to do now is to find the positive eigenvalue \(\lambda\) for the operator \(D\).
We can do this, of course, by solving the characteristic equation for a matrix representation of \(D\), but, as we are now practising the trace operations, we can also notice that \(\operatorname{tr}D^2 = 2\lambda^2\), and then evaluate the trace of \(D^2\).
We use the trace identities and obtain
\[
  \begin{aligned}
    \operatorname{tr}D^2
    &= \operatorname{tr}\left( |s_1\rangle\langle s_1|-|s_2\rangle\langle s_2| \right) \left( |s_1\rangle\langle s_1|-|s_2\rangle\langle s_2| \right)
  \\&= 2-2|\langle s_1|s_2\rangle|^2
  \end{aligned}
\]
which gives \(\lambda = \sqrt{1-|\langle s_1|s_2\rangle|^2}\).
Bringing it all together we have the final expression:
\[
 \Pr (\text{success})
 = \frac12\left( 1+ \sqrt{1-|\langle s_1|s_2\rangle|^2} \right).
\]

We can parametrise \(|\langle s_1|s_2\rangle| = \cos\alpha\), and interpret \(\alpha\) as the angle between \(|s_1\rangle\) and \(|s_2\rangle\).

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-32-1} \end{center}

This allows us to express our findings in a clearer way: given two equally likely states, \(|s_1\rangle\) and \(|s_2\rangle\), such that \(|\langle s_1|s_2\rangle| = \cos\alpha\), the probability of correctly identifying the state by a projective measurement is bounded by
\[
 \Pr (\text{success})
 = \frac12(1 + \sin\alpha),
\]
and the optimal measurement that achieves this bound is determined by the eigenvectors of \(D = |s_1\rangle\langle s_1|-|s_2\rangle\langle s_2|\) (try to visualise these eigenvectors).

It makes sense, right?
If we try just guessing the state, without any measurement, then we expect \(\Pr (\text{success}) = \frac12\).
This is our lower bound, and in any attempt to distinguish the two states we should do better than that.
If the two signal states are very close to each other then \(\sin\alpha\) is small and we are slightly better off than guessing.
As we increase \(\alpha\), the two states become more distinguishable, and, as we can see from the formula, when the two states become orthogonal they also become completely distinguishable.

\hypertarget{wiesners-quantum-money}{%
\subsection{Wiesner's quantum money}\label{wiesners-quantum-money}}

\textbf{!!!TO-DO!!!}

\emph{(cf.~\href{https://arxiv.org/abs/1404.1507}{arXiv:1404.1507})}

\hypertarget{quantum-theory-formally}{%
\subsection{Quantum theory, formally}\label{quantum-theory-formally}}

Even though multiplying and adding probability amplitudes is essentially all there is to quantum theory, we hardly ever multiply and add amplitudes in a pedestrian way.
Instead, as we have seen, we neatly tabulate the amplitudes into vectors and matrices and let the matrix multiplication take care of multiplication and addition of amplitudes corresponding to different alternatives.
Thus vectors and matrices appear naturally as our bookkeeping tools: we use vectors to describe quantum states, and matrices (operators) to describe quantum evolutions and measurements.
This leads to a convenient mathematical setting for quantum theory, which is a complex vector space with an inner product, often referred to as a Hilbert space.
It turns out, somewhat miraculously, that this pure mathematical construct is exactly what we need to formalise quantum theory.
It gives us a precise language which is appropriate for making empirically testable predictions.
At a very instrumental level, quantum theory is a set of rules designed to answer questions such as ``given a specific preparation and a subsequent evolution, how can we compute probabilities for the outcomes of such-and-such measurement''.
Here is how we represent preparations, evolutions and measurements in mathematical terms, and how we get probabilities.

Note that we have already said much of the below, but we are summarising it again now in a more precise way, formally defining the mathematical framework of quantum theory that we use.

We also need to point out that a vital part of the formalism of quantum theory is missing from the following description, namely the idea of \textbf{tensor products}.
To talk about this, we need to introduce the notion of \textbf{entanglement}, and this will be the subject of \protect\hyperlink{quantum-entanglement}{Chapter 5}.

\hypertarget{quantum-states}{%
\subsubsection{Quantum states}\label{quantum-states}}

With any isolated quantum system which can be prepared in \(n\) perfectly distinguishable states, we can associate a Hilbert space \(\mathcal{H}\) of dimension \(n\) such that each vector \(|v\rangle\in\mathcal{H}\) of unit length (\(\langle v|v\rangle =1\)) represents a quantum state of the system.
The overall phase of the vector has no physical significance: \(|v\rangle\) and \(e^{i\varphi}|v\rangle\), for any real \(\varphi\), describe the same state.
The inner product \(\langle u|v\rangle\) is the probability amplitude that a quantum system prepared in state \(|v\rangle\) will be found in state \(|u\rangle\).
States corresponding to orthogonal vectors, \(\langle u|v\rangle=0\), are perfectly distinguishable, since the system prepared in state \(|v\rangle\) will never be found in state \(|u\rangle\), and vice versa.
In particular, states forming orthonormal bases are always perfectly distinguishable from each other.

\hypertarget{quantum-evolutions}{%
\subsubsection{Quantum evolutions}\label{quantum-evolutions}}

\begin{idea}
Any physically admissible evolution of an isolated quantum system is represented by a unitary operator.

\end{idea}

Unitary operators describing evolutions of quantum systems are usually derived from the \textbf{Schrödinger equation}.\footnote{Recall our previous discussion of this equation in \protect\hyperlink{quantum-gates}{Chapter 3}.}
\[
  \frac{\mathrm{d}}{\mathrm{d}t} |\psi(t)\rangle
  = -\frac{i}{\hbar} H |\psi(t)\rangle
\]
where \(H\) is a Hermitian operator called the Hamiltonian.

This equation contains a complete specification of all interactions both within the system and between the system and the external potentials.
For time independent Hamiltonians, the formal solution of the Schrödinger equation reads
\[
  \begin{gathered}
    |\psi(t)\rangle = U(t) |\psi(0)\rangle
  \\\text{where}\quad U(t) = e^{-\frac{i}{\hbar}Ht}.
  \end{gathered}
\]
Any unitary matrix can be represented\footnote{We ignore convergence issues.} as the exponential of some Hermitian matrix \(H\) and some real coefficient \(t\):
\[
  \begin{aligned}
    e^{-itH}
    &\equiv \mathbf{1}- itH + \frac{(-it)^2}{2}H^2 + \frac{(-it)^3}{2\cdot3}H^3 +\ldots
  \\&= \sum_{n=0}^\infty \frac{(-it)^n}{n!}H^n.
  \end{aligned}
\]
The state vector changes smoothly: for \(t=0\) the time evolution operator is merely the unit operator \(\mathbf{1}\), and when \(t\) is very small \(U(t)\approx \mathbf{1}-itH\) is close to the unit operator, differing from it by something of order \(t\).

\hypertarget{quantum-circuits}{%
\subsubsection{Quantum circuits}\label{quantum-circuits}}

In this course we will hardly refer to the Schrödinger equation.
Instead we will assume that our clever colleagues, experimental physicists, are able to implement certain unitary operations and we will use these unitaries, like lego blocks, to construct other, more complex, unitaries.
We refer to preselected elementary quantum operations as \textbf{quantum logic gates} and we often draw diagrams, called \textbf{quantum circuits}, to illustrate how they act on qubits.
For example, two unitaries, \(U\) followed by \(V\), acting on a single qubit are represented as

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-33-1} \end{center}

This diagram should be read from left to right, and the horizontal line represents a qubit that is inertly carried from one quantum operation to another.

\hypertarget{measurements-1}{%
\subsubsection{Measurements}\label{measurements-1}}

A complete measurement in quantum theory is determined by the choice of an orthonormal basis \(\{|e_i\rangle\}\) in \(\mathcal{H}\), and every such basis (in principle) represents a possible measurement.
Given a quantum system in state \(|\psi\rangle\) such that
\[
  |\psi\rangle = \sum_i |e_i\rangle\langle e_i|\psi\rangle,
\]
the measurement in the basis \(\{|e_i\rangle\}\) gives the outcome labelled by \(e_k\) with probability \(|\langle e_k\psi||\rangle^2\), and leaves the system in state \(|e_k\rangle\).
This is consistent with our interpretation of the inner product \(\langle e_k|\psi\rangle\) as the probability amplitude that a quantum system prepared in state \(|\psi\rangle\) will be found in state \(|e_k\rangle\).
State vectors forming orthonormal bases are perfectly distinguishable from each other (\(\langle e_i|e_j\rangle=\delta_{ij}\)), so there is no ambiguity about the outcome.
A complete measurement is the best we can do in terms of resolving state vectors in the basis states.

In general, for any decomposition of the identity \(\sum_k P_k=\mathbf{1}\) into orthogonal projectors \(P_k\) (i.e.~\(P_kP_l = P_k\delta_{kl}\)), there exists a measurement that takes a quantum system in state \(|\psi\rangle\), outputs label \(k\) with probability \(\langle\psi|P_k|\psi\rangle\), and leaves the system in the state \(P_k|\psi\rangle\) (multiplied by the normalisation factor i.e.~divided by the length of \(P_k|\psi\rangle\)):
\[
  |\psi\rangle
  \mapsto
  \frac{P_k|\psi\rangle}{\sqrt{\langle\psi|P_k|\psi\rangle}}.
\]
The projector formalism covers both complete and incomplete measurements.
The complete measurements are defined by rank one projectors, \(P_k=|e_k\rangle\langle e_k|\), projecting on vectors from some orthonormal basis \(\{|e_k\rangle\}\).

\hypertarget{remarks-and-exercises-4}{%
\subsection{\texorpdfstring{\emph{Remarks and exercises}}{Remarks and exercises}}\label{remarks-and-exercises-4}}

\hypertarget{projector}{%
\subsubsection{Projector?}\label{projector}}

Consider two unit vectors \(|a\rangle\) and \(|b\rangle\).
Is \(|a\rangle\langle a|+|b\rangle\langle b|\) a projector?

\hypertarget{knowing-the-unknown}{%
\subsubsection{Knowing the unknown}\label{knowing-the-unknown}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Suppose you are given a single qubit in some unknown quantum state \(|\psi\rangle\).
  Can you determine \(|\psi\rangle\)?
\item
  You measure a random qubit in the standard basis and register \(|0\rangle\).
  What does it tell you about the pre-measurement state \(|\psi\rangle\)?
\item
  How many real parameters do you need to determine \(|\psi\rangle\)?
  Would you be able to reconstruct \(|\psi\rangle\) from \(\langle\psi|X|\psi\rangle\), \(\langle\psi|Y|\psi\rangle\), and \(\langle\psi|Z|\psi\rangle\)?
  (It may help you to visualise \(|\psi\rangle\) as a Bloch vector).
\item
  You are given zillions of qubits, all prepared in the same quantum state \(|\psi\rangle\).
  How would you determine \(|\psi\rangle\)?
\end{enumerate}

\hypertarget{measurement-and-idempotents}{%
\subsubsection{Measurement and idempotents}\label{measurement-and-idempotents}}

The \(Z\) measurement is defined by the projectors
\[
  \begin{aligned}
    P_0 &= \frac12(\mathbf{1}+ Z),
  \\P_1 &= \frac12(\mathbf{1}- Z).
  \end{aligned}
\]
Consider the measurement associated to some Hermitian operator \(S\) that satisfies \(S^2=\mathbf{1}\).
Show that the two outcomes \(\pm 1\) correspond to the projectors \(\frac12(\mathbf{1}\pm S)\).

\hypertarget{unitary-transformations-of-measurements}{%
\subsubsection{Unitary transformations of measurements}\label{unitary-transformations-of-measurements}}

In our quantum circuits, unless specified otherwise, all measurements are assumed to be performed in the standard basis.
This is because any measurement can be reduced to the standard measurement by performing some prior unitary transformation.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Show that any two orthonormal bases \(\{|e_k\rangle\}\) and \(\{|d_l\rangle\}\) are always related by some unitary \(U\) (i.e.~show that \(\sum_k |d_k\rangle\langle e_k|\) is unitary).
\item
  Suppose that the projectors \(P_k\) define the standard measurement.
  Show that, for any unitary \(U\), the projectors \(UP_kU^\dagger\) also define a measurement.
\end{enumerate}

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-34-1} \end{center}

\hypertarget{optimal-measurement}{%
\subsubsection{Optimal measurement}\label{optimal-measurement}}

The optimal measurement to distinguish between the two equally likely non-orthogonal signal states, \(|s_1\rangle\) and \(|s_2\rangle\), is described by the two orthogonal vectors \(|d_1\rangle\) and \(|d_2\rangle\), placed symmetrically around the signal states.
But suppose the states are not equally likely: say \(|s_1\rangle\) is chosen with probability \(p_1\) and \(|s_2\rangle\) with probability \(p_2\).
How would you modify the measurement to maximise the probability of success in this case?

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-35-1} \end{center}

\hypertarget{alice-knows-what-bob-did}{%
\subsubsection{Alice knows what Bob did}\label{alice-knows-what-bob-did}}

(This is a simplified version of a beautiful quantum puzzle proposed in 1987 by Lev Vaidman, Yakir Aharonov, and David Z. Albert in a paper with the somewhat provocative title ``How to ascertain the values of \(\sigma_x\), \(\sigma_y\), and \(\sigma_z\) of a spin-\(\frac12\) particle''. For the original, see \emph{Phys. Rev.~Lett.} \textbf{58} (1987), 1385.)

Alice prepares a qubit in any state of her choosing and gives it to Bob, who secretly measures either \(\sigma_x\) or \(\sigma_y\).
The outcome of the measurement is seen only by Bob.
Alice has no clue which measurement was chosen by Bob, but right after his measurement she gets her qubit back and she can measure it as well.
Some time later, Bob tells Alice which of the two measurements was chosen, i.e.~whether he measured \(\sigma_x\) or \(\sigma_y\).
Alice then tells him the outcome he obtained in his measurement.
Bob is surprised, since the two measurements have mutually unbiased bases and yet Alice always gets it right.
How does she do it?

\hypertarget{the-zeno-effect}{%
\subsubsection{The Zeno effect}\label{the-zeno-effect}}

\textbf{!!!TO-DO!!!}

\hypertarget{quantum-entanglement}{%
\section{Quantum entanglement}\label{quantum-entanglement}}

\begin{quote}
About the fundamental tool of quantum computing: \textbf{entanglement}, via the formalism of \textbf{tensor products}, which was the missing ingredient from our previous formalism of quantum theory.
Also about various \textbf{controlled gates}, including the always useful \textbf{controlled-\(\texttt{NOT}\)}.
\end{quote}

We now know everything we need to know about a single qubit and its quantum behaviour.
But if we want to understand quantum computation --- a complicated quantum interference of many interacting qubits --- then we will need few more mathematical tools.
Stepping up from one qubit to two or more is a bigger leap than you might expect.
Already, with just two qubits, we will encounter the remarkable phenomenon of quantum entanglement and have a chance to discuss some of the most puzzling features of quantum theory that took people decades to understand.

\hypertarget{a-small-history}{%
\subsection{A small history}\label{a-small-history}}

The notion of \textbf{quantum entanglement} was the subject of many early debates that focused on the meaning of quantum theory.
Back in the 1930s, Albert Einstein, Niels Bohr, Werner Heisenberg, and Erwin Schrödinger (to mention just the usual suspects) were trying hard to understand its conceptual consequences.\footnote{E. Schrödinger, Discussion of probability relations between separated system, \emph{Mathematical Proceedings of the Cambridge Philosophical Society} \textbf{31} (1935), pp.~555--563.}
Einstein, the most sceptical of them all, claimed that it was pointing toward the fatal flaw in quantum theory, and referred to it as ``\emph{spooky action-at-a-distance}''.
In contrast, Schrödinger was much more prepared to accept quantum theory exactly as it was formulated, along with all its predictions, no matter how weird they might be.
In his 1935 paper, which introduced quantum entanglement, he wrote ``I would not call it \emph{one} but rather \emph{the} characteristic trait of quantum mechanics, the one that enforces its entire departure from classical lines of thought''.
Today we still talk a lot about quantum entanglement, but more often it is viewed as a physical resource which enables us to communicate with perfect security, build very precise atomic clocks, and even teleport small quantum objects!
But what exactly is quantum entanglement?

\hypertarget{one-two-many}{%
\subsection{One, two, many\ldots{}}\label{one-two-many}}

In classical physics, the transition from a single object to a composite system of many objects is trivial: in order to describe the state of, say, 42 objects at any given moment of time, it is sufficient to describe the state of each of the objects separately.
Indeed, the classical state of 42 point-like particles is described by specifying the position and the momentum of each particle.

\begin{idea}
In the \emph{classical} world, ``the whole is the sum of its parts'', but the \emph{quantum} world is very different.

\end{idea}

Consider, for example, a pair of qubits.
Suppose that each one is described by a state vector: the first one by \(|a\rangle\), and the second one by \(|b\rangle\).
One might therefore think that the most general state of the two qubits should be represented by a pair of state vectors, \(|a\rangle|b\rangle\), with one for each qubit.
Indeed, such a state is certainly possible, but there are other states that \emph{cannot} be expressed in this form.
In order to write down the most general state of two qubits we first focus on the basis states.

For a single qubit we have been using the standard basis \(\{|0\rangle,|1\rangle\}\).
For two qubits we may choose the following as our standard basis states:\footnote{It looks like we are defining some sort of ``multiplication rule'' for kets here, saying that \(|a\rangle|b\rangle:=|ab\rangle\). This is indeed the case, but to talk about this properly we need to introduce the idea of \textbf{tensor products} (which we do very soon).}
\[
  \begin{array}{cc}
    |00\rangle \equiv |0\rangle|0\rangle
    & |01\rangle \equiv |0\rangle|1\rangle
  \\|10\rangle \equiv |1\rangle|0\rangle
    &|11\rangle \equiv |1\rangle|1\rangle.
  \end{array}
\]
Within each ket, the first symbol refers to the first qubit, and the second to the second, and we have tacitly assumed that we can distinguish the two qubits by their location, or some other means.
Now, the most general state of the two qubits is a normalised linear combination of these four basis states, i.e.~a vector of the form
\[
  |\psi\rangle
  = c_{00}|00\rangle + c_{01}|01\rangle + c_{10}|10\rangle + c_{11}|11\rangle.
\]
Physical interpretation aside, let us count how many real parameters are needed to specify this state.
Six, right?
We have four complex numbers (eight real parameters) restricted by the normalisation condition, along with the fact that states differing only by a global phase factor are equivalent, which leaves us with six real parameters.
Now, by the same line of argument, we need only two real parameters to specify the state of a single qubit, and hence need four real parameters to specify any state of two qubits of the form \(|a\rangle|b\rangle\).
So it cannot be the case that every state of two qubits can be expressed as a pair of states \(|a\rangle|b\rangle\), simply for ``dimension reasons''.

For example, compare the two states of two qubits,
\[
  \begin{gathered}
    \frac{1}{\sqrt 2}|00\rangle + \frac{1}{\sqrt 2}|01\rangle
  \\\text{and}
  \\\frac{1}{\sqrt 2}|00\rangle + \frac{1}{\sqrt 2}|11\rangle.
  \end{gathered}
\]
The first one is \textbf{separable}, i.e.~we can view it as a pair of state vectors where each one pertains to one of the two qubits:
\[
  \frac{1}{\sqrt 2}|00\rangle + \frac{1}{\sqrt 2}|01\rangle
  = \underbrace{\vphantom{\frac{1}{\sqrt 2}}|0\rangle}_{\text{qubit 1}}
  \;\;
  \underbrace{\frac{1}{\sqrt 2}(|0\rangle+|1\rangle)}_{\text{qubit 2}},
\]
The second state, however, does \emph{not} admit such a decomposition: there do \emph{not} exist any \(\psi_1,\psi_2\) such that
\[
  \frac{1}{\sqrt 2}|00\rangle + \frac{1}{\sqrt 2}|11\rangle
  =
  |\psi_1\rangle|\psi_2\rangle
\]
and so we say that it is an \textbf{entangled} state.
Informally, any bipartite state that cannot be viewed as a pair of two states pertaining to the constituent subsystems is said to be entangled.

With this discussion in our minds, we can now give more formal account of the states of composite quantum systems.

\hypertarget{quantum-theory-formally-continued}{%
\subsection{Quantum theory, formally (continued)}\label{quantum-theory-formally-continued}}

Recalling \protect\hyperlink{measurements}{Chapter 4}, where we said that we were missing a key part of the formalism of quantum theory, we can now fill in this hole.
Our mathematical formalism of choice behind the quantum theory of composite systems is based on the \textbf{tensor product} of Hilbert spaces.

\hypertarget{tensor-products}{%
\subsubsection{Tensor products}\label{tensor-products}}

Let the states of some system \(\mathcal{A}\) be described by vectors in an \(n\)-dimensional Hilbert space \(\mathcal{H}_{\mathcal{A}}\), and the states of some system \(\mathcal{B}\) by vectors in an \(m\)-dimensional Hilbert space \(\mathcal{H}_{\mathcal{B}}\).
The combined system of \(\mathcal{A}\) and \(\mathcal{B}\) is then described by vectors in the \((nm)\)-dimensional \textbf{tensor product space} \(\mathcal{H}_{\mathcal{A}}\otimes\mathcal{H}_{\mathcal{B}}\).
Given bases \(\{|a_1\rangle,\ldots,|a_n\rangle\}\) of \(\mathcal{H}_{\mathcal{A}}\) and \(\{|b_1\rangle,\ldots,|b_m\rangle\}\) of \(\mathcal{H}_{\mathcal{B}}\), we form a basis of the tensor product by taking the ordered pairs \(|a_i\rangle\otimes|b_j\rangle\), for \(i=1,\ldots,n\) and \(j=1,\ldots,m\).
The tensor product space \(\mathcal{H}_{\mathcal{A}}\otimes\mathcal{H}_{\mathcal{B}}\) then consists of all linear combination of such tensor product basis vectors:\footnote{If the bases \(\{|a_i\rangle\}\) and \(\{|b_j\rangle\}\) are orthonormal then so too is the tensor product basis \(\{|a_i\rangle\otimes|b_j\rangle\}\).}
\[
  |\psi\rangle
  = \sum_{ij} c_{ij}|a_i\rangle\otimes|b_j\rangle.
\tag{5.3.1}
\]

The tensor product operation \(\otimes\) is distributive:
\[
  \begin{gathered}
    |a\rangle \otimes \left( \beta_1|b_1\rangle + \beta_2|b_2\rangle \right)
    = \beta_1|a\rangle\otimes|b_1\rangle + \beta_2|a\rangle\otimes|b_2\rangle
  \\\left( \alpha_1|a_1\rangle + \alpha_2|a_2\rangle \right) \otimes |b\rangle
    = \alpha_1|a_1\rangle\otimes|b\rangle + \alpha_2|a_2\rangle\otimes|b\rangle.
  \end{gathered}
\]
The tensor product of Hilbert spaces is again a Hilbert space: the inner products on \(\mathcal{H}_{\mathcal{A}}\) and \(\mathcal{H}_{\mathcal{B}}\) give a natural inner product on \(\mathcal{H}_{\mathcal{A}}\otimes\mathcal{H}_{\mathcal{B}}\), defined for any two product vectors by
\[
  \left( \langle a'|\otimes\langle b'| \right) \left( |a\rangle\otimes|b\rangle \right)
  = \langle a'|a\rangle\langle b'|b\rangle
\]
and extended by linearity to sums of tensor products of vectors, and, by associativity\footnote{\(({\mathcal{H}}_a \otimes {\mathcal{H}}_b)\otimes {\mathcal{H}}_c = {\mathcal{H}}_a \otimes ({\mathcal{H}}_b\otimes {\mathcal{H}}_c)\).}, to any number of subsystems.
Note that the bra corresponding to the tensor product state \(|a\rangle\otimes|b\rangle\) is written as \((|a\rangle\otimes|b\rangle)^\dagger = \langle a|\otimes\langle b|\), where the order of the factors on either side of \(\otimes\) does not change when the dagger operation is applied.

Some joint states of \(\mathcal{A}\) and \(\mathcal{B}\) can be expressed as a single tensor product, say \(|\psi\rangle=|a\rangle\otimes|b\rangle\) (often written as \(|a\rangle|b\rangle\), or \(|a, b\rangle\), or even \(|ab\rangle\)), meaning that the subsystem \(\mathcal{A}\) is in state \(|a\rangle\), and the subsystem \(\mathcal{B}\) in state \(|b\rangle\).
If we expand \(|a\rangle=\sum_i\alpha_i|a_i\rangle\) and \(|b\rangle=\sum_i\beta_j|b_j\rangle\), then \(|\psi\rangle=\sum_{ij}\alpha_i\beta_j|a_i\rangle\otimes|b_j\rangle\) and we see that, for all such states, the coefficients \(c_{ij}\) in Equation (5.3.1) are of a rather special form:
\[
  c_{ij} = \alpha_i\beta_j.
\]
We call such states \textbf{separable} (or just \textbf{product states}).
States that are not separable are said to be \textbf{entangled}.

A useful fact about tensor products is that \(\lambda a\otimes b = a\otimes\lambda b\) (where \(a\) and \(b\) are vectors, and \(\lambda\) is a scalar).
This means that we don't need to worry about brackets, and can write something like \(\lambda(a\otimes b)\).

We will also need the concept of the tensor product of two operators.
If \(A\) is an operator on \(\mathcal{H}_{\mathcal{A}}\) and \(B\) an operator on \(\mathcal{H}_{\mathcal{B}}\), then the tensor product operator \(A\otimes B\) is an operator on \(\mathcal{H}_{\mathcal{A}}\otimes\mathcal{H}_{\mathcal{B}}\) defined by its action on product vectors via
\[
  (A\otimes B)(|a\rangle\otimes|b\rangle) = (A|a\rangle)\otimes (B|b\rangle)
\]
and with its action on all other vectors determined by linearity:
\[
  A\otimes B \left( \sum_{ij} c_{ij}|a_i\rangle\otimes|b_j\rangle \right)
  = \sum_{ij}c_{ij} A|a_i\rangle\otimes B|b_j\rangle.
\]

\hypertarget{back-to-qubits}{%
\subsection{Back to qubits}\label{back-to-qubits}}

Let's see how this formalism works for qubits.
The \(n\)-fold tensor product of vectors from the standard basis \(\{|0\rangle,|1\rangle\}\) represent binary strings of length \(n\).
For example, for \(n=3\),\footnote{We often drop the \(\otimes\) symbol, especially when we deal with the standard tensor product basis. For example, a state of a quantum register composed of four qubits holding the binary string \(1001\) may be written as \(|1\rangle\otimes|0\rangle\otimes|0\rangle\otimes|1\rangle\), as \(|1\rangle|0\rangle|0\rangle|1\rangle\), or even simply as \(|1001\rangle\).}
\[
  \begin{aligned}
    |0\rangle\otimes|1\rangle\otimes|1\rangle
    & \equiv |011\rangle
  \\|1\rangle\otimes|1\rangle\otimes|1\rangle
    & \equiv |111\rangle.
  \end{aligned}
\]
A \emph{classical} register composed of three bits can store \emph{only one} of these two binary strings at any time; a \emph{quantum} register composed of three qubits can store \emph{both of them} in a superposition.

Indeed, if we start with the state \(|011\rangle\) and apply the Hadamard gate to the first qubit (which is the same as applying \(H\otimes\mathbf{1}\otimes\mathbf{1}\)), then, given that linear combinations distribute over tensor products, we obtain\footnote{We often simply write \(H\otimes H\otimes H\) as \(H^{\otimes 3}\).}
\[
  \begin{aligned}
    |011\rangle
    \longmapsto
    &\frac{1}{\sqrt2} \big(|0\rangle + |1\rangle\big) \otimes|1\rangle\otimes|1\rangle
  \\\equiv
    &\frac{1}{\sqrt2} \big(|011\rangle + |111\rangle\big).
  \end{aligned}
\]
In fact, we can even prepare this register in a superposition of all eight possible binary strings: if we apply the tensor product operation \(H\otimes H\otimes H\) to the state \(|0\rangle\otimes|0\rangle\otimes|0\rangle = |000\rangle\) then we get

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-36-1} \end{center}

The resulting state is exactly a superposition of all binary string of length 3, and can also be written as
\[
  \frac{1}{\sqrt2} \big(|0\rangle + |1\rangle\big)
  \otimes
  \frac{1}{\sqrt2} \big(|0\rangle + |1\rangle\big)
  \otimes
  \frac{1}{\sqrt2} \big(|0\rangle + |1\rangle\big).
\]

In general, the tensor product operation \(H^{\otimes n}\), which means ``apply the Hadamard gate to each of your \(n\) qubits'', is known as the \textbf{Hadamard transform}, and it maps product states to product states.
Like the Hadamard gate in the typical quantum interference circuit, the Hadamard transform opens and closes a multi-qubit interference.

\hypertarget{separable-or-entangled}{%
\subsection{Separable or entangled?}\label{separable-or-entangled}}

\begin{idea}
\emph{Most} vectors in \(\mathcal{H}_a\otimes \mathcal{H}_b\) are entangled and \emph{cannot} be written as product states \(|a\rangle\otimes|b\rangle\) with \(|a\rangle\in\mathcal{H}_a\) and \(|b\rangle\in\mathcal{H}_b\).

\end{idea}

In order to see this, let us write any joint state \(|\psi\rangle\) of \(\mathcal{A}\) and \(\mathcal{B}\) in a product basis as
\[
  \begin{aligned}
    |\psi\rangle
    &= \sum_{ij} c_{ij}|a_i\rangle\otimes|b_j\rangle
  \\&= \sum_i|a_i\rangle\otimes\left(\sum_j c_{ij}|b_j\rangle\right)
  \\&= \sum_i|a_i\rangle\otimes|\phi_i\rangle
  \end{aligned}
\tag{5.5.1}
\]
where the \(|\phi_i\rangle=\sum_j c_{ij}|b_j\rangle\) are vectors in \(\mathcal{H}_{\mathcal{B}}\) that need not be normalised.
For any \emph{product} state, these vectors have a special form.
Indeed, if \(|\psi\rangle= |a\rangle\otimes|b\rangle\) then, after expanding the first state in the \(|a_i\rangle\) basis, we obtain
\[
  |\psi\rangle
  = \sum_{i}|a_i\rangle\otimes\left(\sum_i\alpha_i|b\rangle\right).
\]
This expression has the same form as Equation (5.5.1) with \(|\phi_i\rangle=\alpha_i|b\rangle\), i.e.~each of the \(|\phi_i\rangle\) vectors in this expansion is a multiple of the same vector \(|b\rangle\).
Conversely, if \(|\phi_i\rangle = \alpha_i|b\rangle\) for all \(i\) in Equation (5.5.1), then \(|\psi\rangle\) must be a product state.\footnote{Even though an entangled state cannot be written as a tensor product, it can always be written as a linear combination of vectors from the tensor product basis. In fact, any state of \(n\) qubits \(|\psi\rangle\) can be expressed in the standard \emph{product} basis. In general, given \(n\) qubits, we need \(2(2^n-1)\) real parameters to describe their state vector, but only \(2n\) to describe separable states.}
So if we want to identify which joint states are product states and which are not, we simply write the joint state according to Equation (5.5.1) and check if all the vectors \(|\phi_i\rangle\) are multiples of a single vector.
Needless to say, if we choose the states \(|\phi\rangle\) randomly, it is very unlikely that this condition is satisfied, and we almost certainly pick an entangled state.

Quantum entanglement is one of the most fascinating aspects of quantum theory.
We will now explore some of its implications.

\hypertarget{controlled-not}{%
\subsection{Controlled-NOT}\label{controlled-not}}

How do entangled states arise in real physical situations?
The short answer is that \emph{entanglement is the result of interactions}.
It is easy to see that tensor product operations \(U_1\otimes\ldots\otimes U_n\) map product states to product states:

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-37-1} \end{center}

and so any collection of separable qubits remains separable.

As soon as qubits start interacting with one another, however, they become entangled, and things start to get really interesting.
We will describe interactions that cannot be written as tensor products of unitary operations on individual qubits.
The most popular two-qubit entangling gate is the \textbf{controlled-\(\texttt{NOT}\)} (or \(\texttt{c-NOT}\)), also known as the \textbf{controlled-\(X\)} gate.\footnote{Here the \(X\) refers to the Pauli operator \(\sigma_x\equiv X\) that implements the bit-flip.}
The gate acts on two qubits: it flips the second qubit (referred to as the \textbf{target}) if the first qubit (referred to as the \textbf{control}) is \(|1\rangle\), and does nothing if the control qubit is \(|0\rangle\).
In the standard basis \(\{|00\rangle,|01\rangle,|10\rangle,|11\rangle\}\), it is represented by the following unitary matrix:

\begin{idea}

\begin{longtable}[]{@{}c@{}}
\toprule
\begin{minipage}[b]{0.97\columnwidth}\centering
controlled-\(\texttt{NOT}\)\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.97\columnwidth}\centering
\(\left[\begin{array}{c|c}\begin{matrix}1&0\\0&1\end{matrix}&\begin{matrix}0&0\\0&0\end{matrix}\\\hline\begin{matrix}0&0\\0&0\end{matrix}&\begin{matrix}0&1\\1&0\end{matrix}\end{array}\right]\)\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}


\end{idea}

We can also represent the \(\texttt{c-NOT}\) gate using the circuit notation, as in Figure \ref{fig:c-not-diagram}.



\begin{figure}[H]

{\centering \includegraphics{iqis-book_files/figure-latex/c-not-diagram-1} 

}

\caption{Where \(x,y\in\{0,1\}\), and \(\oplus\) denotes \(\texttt{XOR}\), or addition modulo 2.}\label{fig:c-not-diagram}
\end{figure}

Note that this gate does not admit any tensor product decomposition, but can be written as a sum of tensor products:\footnote{Make sure that you understand how the Dirac notation is used here. More generally, think why \[|0\rangle\langle 0|\otimes A + |1\rangle\langle 1|\otimes B\] means ``\emph{if the first qubit is in state \(|0\rangle\) then apply \(A\) to the second one, and if the first qubit is in state \(|1\rangle\) then apply \(B\) to the second one}''. What happens if the first qubit is in a superposition of \(|0\rangle\) and \(|1\rangle\)?}
\[
  \texttt{c-NOT}
  = |0\rangle\langle 0|\otimes\mathbf{1}+ |1\rangle\langle 1|\otimes X
\]
where \(X\) is the Pauli bit-flip operation.

The \(\texttt{c-NOT}\) gate lets us do many interesting things, and can act in a rather deceptive way.
Let us now study some of these things.

\hypertarget{the-bell-states-and-the-bell-measurement}{%
\subsubsection{The Bell states, and the Bell measurement}\label{the-bell-states-and-the-bell-measurement}}

We start with the generation of entanglement.
Here is a simple circuit that demonstrates the entangling power of \(\texttt{c-NOT}\):\footnote{John Stewart Bell (1928--1990) was a Northern Irish physicist.}

\begin{circuit}

(Generating entanglement).

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-38-1} \end{center}


\end{circuit}

In this circuit, the separable input \(|0\rangle|0\rangle\) evolves as
\[
  \begin{aligned}
    |0\rangle|0\rangle
    \overset{H}{\longmapsto}& \frac{1}{\sqrt2} (|0\rangle + |1\rangle) |0\rangle
  \\=& \frac{1}{\sqrt2}|0\rangle|0\rangle + \frac{1}{\sqrt2}|1\rangle|0\rangle
  \\\overset{\texttt{c-NOT}}{\longmapsto}& \frac{1}{\sqrt2}|0\rangle|0\rangle + \frac{1}{\sqrt2}|1\rangle|1\rangle
  \end{aligned}
\]
resulting in the entangled output \(\frac{1}{\sqrt 2}(|00\rangle+|11\rangle)\).
In fact, this circuit implements the unitary operation which maps the standard computational basis into the four entangled states, known as the \textbf{Bell states}.

\begin{idea}
The \textbf{Bell states}, \(|\psi_{ij}\rangle\), as generated by the above circuit:
\[
  \begin{aligned}
    |00\rangle
    &\mapsto
    |\psi_{00}\rangle = \frac{1}{\sqrt 2}(|00\rangle+|11\rangle)
  \\|01\rangle
    &\mapsto
    |\psi_{01}\rangle = \frac{1}{\sqrt 2}(|01\rangle+|10\rangle)
  \\|10\rangle
    &\mapsto
    |\psi_{10}\rangle = \frac{1}{\sqrt 2}(|00\rangle-|11\rangle)
  \\|11\rangle
    &\mapsto
    |\psi_{11}\rangle = \frac{1}{\sqrt 2}(|01\rangle-|10\rangle)
  \end{aligned}
\]
The more standard notation for these states, however, is the following:
\[
  \begin{aligned}
    \Phi^+ &= |\psi_{00}\rangle
  \\\Psi^+ &= |\psi_{01}\rangle
  \\\Phi^- &= |\psi_{10}\rangle
  \\\Psi^-&= |\psi_{11}\rangle
  \end{aligned}
\]
(and this is the notation that we will use from now on).

\end{idea}

The Bell states form an orthonormal basis in the Hilbert space \(\mathcal{H}_1\otimes\mathcal{H}_2\) of two qubits.
We can perform measurements in the Bell basis: the easiest way to do it in practice is to ``rotate'' the Bell basis to the standard basis, and then perform the measurement in the standard basis.\footnote{For any state \(|\psi\rangle\) of two qubits, the amplitude \(\langle\psi_{xy}|\psi\rangle\) can be written as \(\langle xy|U^\dagger|\psi\rangle\), where \(U^\dagger\) is such that \(|\psi_{xy}\rangle = U|xy\rangle\).}
Indeed, if we reverse the circuit, then we get a circuit which maps the Bell state \(|\psi_{xy}\rangle\) to the corresponding state \(|xy\rangle\) in the standard basis.
This unitary mapping allows us to ``implement'' the projections on Bell states by applying the reversed circuit followed by the usual qubit-by-qubit measurement in the standard basis.

\hypertarget{quantum-teleportation}{%
\subsubsection{Quantum teleportation}\label{quantum-teleportation}}

A wonderful fact, that sounds more like science fiction than actual science, is the following: \emph{an unknown quantum state can be teleported from one location to another.}
Consider the following circuit:\footnote{\emph{Divide et impera}, or ``divide and conquer'': a good approach to solving problems in mathematics (and in life). Start with the smaller circuits in the dashed boxes.}

\begin{circuit}

(Quantum teleportation).

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-39-1} \end{center}


\end{circuit}

The first input qubit (counting from the top) is in some arbitrary state.
After the action of the part of the circuit in the first dashed box (counting from the left), the state of the three qubits reads\footnote{We neglect to write the normalisation factors.}
\[
  \big( \alpha|0\rangle+\beta|1\rangle \big)
  \big( |00\rangle+|11\rangle \big).
\]
By regrouping the terms, but keeping the qubits in the same order, this state can be written as the sum
\[
  \begin{aligned}
    &(|00\rangle + |11\rangle) \otimes (\alpha|0\rangle + \beta|1\rangle)
  \\+ &(|01\rangle + |10\rangle) \otimes (\alpha|1\rangle + \beta|0\rangle)
  \\+ &(|00\rangle - |11\rangle) \otimes (\alpha|0\rangle - \beta|1\rangle)
  \\+ &(|01\rangle - |10\rangle) \otimes (\alpha|1\rangle - \beta|0\rangle).
  \end{aligned}
\]
Then the part of the circuit in the second dashed box maps the four Bell states of the first two qubits to the corresponding states from the computational basis:
\[
  \begin{aligned}
    &|00\rangle \otimes (\alpha|0\rangle + \beta|1\rangle)
  \\+ &|01\rangle \otimes (\alpha|1\rangle + \beta|0\rangle)
  \\+ &|10\rangle \otimes (\alpha|0\rangle - \beta|1\rangle)
  \\+ &|11\rangle \otimes (\alpha|1\rangle - \beta|0\rangle).
  \end{aligned}
\]
Upon performing the standard measurement and learning the values of \(x\) and \(y\), we choose one of the four following transformations depending on these values:
\[
  \begin{array}{ll}
    00 \mapsto \mathbf{1}
    &\quad 01 \mapsto X
  \\[1em]
    10 \mapsto Z
    &\quad 11 \mapsto ZX
  \end{array}
\tag{5.6.2}
\]
(e.g.~if \(x=0\) and \(y=1\), then we choose \(X\)).
We then apply this transformation to the third qubit, which restores the original state of the first qubit.

If you understand how this circuit works then you are ready for quantum teleportation.
Here is a dramatic version.

\begin{quote}
Suppose three qubits, which look very similar, are initially in the possession of an absent-minded Oxford student, Alice.
The first qubit is in a precious quantum state and this state is needed urgently for an experiment in Cambridge.
The other two qubits are entangled, in the \(|\psi_{00}\rangle\) state. Alice's colleague, Bob, pops in to collect the qubit.
Once he is gone, Alice realises that, by mistake, she gave him not the first but the third qubit: the one which is entangled with the second qubit.

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-40-1} \end{center}

The situation seems to be hopeless --- Alice does not know the quantum state of the first qubit, and Bob is now miles away and her communication with him is limited to few bits.
However, Alice and Bob are both very clever and they both diligently attended their ``Introduction to Quantum Information Science'' classes.
Can Alice rectify her mistake and save Cambridge science?

Hmmm\ldots{} (pause for thought)\ldots{}

Of course: Alice can teleport the state of the first qubit!
She performs the Bell measurement on the first two qubits, which gives her two binary digits, \(x\) and \(y\).
She then broadcasts \(x\) and \(y\) to Bob, who chooses the corresponding transformation, as in Equation (5.6.2), performs it, and recovers the original state.
\end{quote}

This raises a natural ``philosophical'' question: what do we really \emph{mean} by teleportation?
A key part of this question is understanding what happens to our original qubit when we teleport it.
As it turns out, it must necessarily be \emph{destroyed}, as we now explain.

\hypertarget{thou-shalt-not-clone}{%
\subsubsection{Thou shalt not clone}\label{thou-shalt-not-clone}}

Let us now look at something that controlled-\(\texttt{NOT}\) \emph{seems} to be doing but, in fact, \emph{isn't}.
It is easy to see that the \(\texttt{c-NOT}\) can copy the bit value of the first qubit:
\[
  |x\rangle|0\rangle \overset{\texttt{c-NOT}}{\longmapsto} |x\rangle|x\rangle
  \qquad\text{(for $x=0,1$)}
\]
so one might suppose that this gate could also be used to copy superpositions, such as \(|\psi\rangle = \alpha|0\rangle+\beta|1\rangle\), so that
\[
  |\psi\rangle|0\rangle \overset{\texttt{c-NOT}}{\longmapsto} |\psi\rangle|\psi\rangle
\]
for any \(|\psi\rangle\).

\textbf{This is not so!}

The unitarity of the \(\texttt{c-NOT}\) means that it turns superpositions in the control qubit into \emph{entanglement} of the control and the target: if the control qubit is in the a superposition state \(|\psi\rangle = \alpha|0\rangle+\beta|1\rangle\) (with \(\alpha,\beta\neq0\)), and the target is in \(|0\rangle\), then the \(\texttt{c-NOT}\) gate generates the entangled state
\[
  \big( \alpha|0\rangle+\beta|1\rangle \big) |0\rangle
  \overset{\texttt{c-NOT}}{\longmapsto}
  \alpha|00\rangle + \beta|11\rangle.
\]
In fact, it is \emph{impossible} to clone an unknown quantum state, and we can prove this!

To prove this via contradiction, let's assume that we \emph{could} build a universal quantum cloner, and then take any two normalised states \(|\psi\rangle\) and \(|\phi\rangle\) that are \emph{non-identical} (i.e.~\(|\langle\psi|\phi\rangle|\neq1\)) and \emph{non-orthogonal} (i.e.~\(\langle\psi|\phi\rangle\neq0\)).
If we then run our hypothetical cloning machine we get
\[
  \begin{aligned}
    |\psi\rangle|0\rangle|W\rangle
    &\mapsto |\psi\rangle|\psi\rangle|W'\rangle
  \\|\phi\rangle|0\rangle|W\rangle
    &\mapsto |\phi\rangle|\phi\rangle|W''\rangle
  \end{aligned}
\]
where the third system, initially in state \(|W\rangle\), represents everything else (say, the internal state of the cloning machine).
For this transformation to be unitary, it must preserve the inner product, and so we require that
\[
  \langle\psi|\phi\rangle
  = \langle\psi|\phi\rangle^2 \langle W'|W''\rangle
\]
which can only be satisfied if \(|\langle\psi|\phi\rangle|\) is equal to \(1\) or \(0\), but this contradicts our assumptions!

Thus, states of qubits, unlike states of classical bits, cannot be faithfully cloned.
Note that, in quantum teleportation, the original state must therefore be \emph{destroyed}, since otherwise we would be producing a clone of an unknown quantum state.
The no-cloning property of quantum states leads to interesting applications, of which quantum cryptography is one.

\begin{idea}
Universal quantum cloners are \emph{impossible}.

\end{idea}

\hypertarget{other-controlled-gates}{%
\subsection{Other controlled gates}\label{other-controlled-gates}}

\hypertarget{controlled-phase}{%
\subsubsection{Controlled-phase}\label{controlled-phase}}

Needless to say, not everything is about the controlled-\(\texttt{NOT}\) gate.
Another common two-qubit gate is the \textbf{controlled-phase} gate \(\texttt{c-}P_\varphi\).

\begin{idea}

\begin{longtable}[]{@{}c@{}}
\toprule
\begin{minipage}[b]{0.97\columnwidth}\centering
controlled-phase\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.97\columnwidth}\centering
\(\left[\begin{array}{c|c}\begin{matrix}1&0\\0&1\end{matrix}&\begin{matrix}0&0\\0&0\end{matrix}\\\hline\begin{matrix}0&0\\0&0\end{matrix}&\begin{matrix}1&0\\0&e^{i\varphi}\end{matrix}\end{array}\right]\)\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}


\end{idea}

We can also represent the \(\texttt{c-}P_\varphi\) gate using the circuit notation, as in Figure \ref{fig:c-phase-diagram}.



\begin{figure}[H]

{\centering \includegraphics{iqis-book_files/figure-latex/c-phase-diagram-1} 

}

\caption{Where \(x,y\in\{0,1\}\).}\label{fig:c-phase-diagram}
\end{figure}

Again, the matrix is written in the computational basis \(\{|00\rangle,|01\rangle,|10\rangle,|11\rangle\}\).
If we do not specify the phase then we usually assume that \(\varphi=\pi\), in which case we call this operation the \textbf{controlled-\(Z\) gate}, which acts as \(|0\rangle\langle 0|\otimes\mathbf{1}+ |1\rangle\langle 1|\otimes Z\).
Here \(Z\) refers again to the Pauli phase-flip \(\sigma_z\equiv Z\) operation.

In order to see the entangling power of the controlled-phase shift gate, consider the following circuit.

\begin{circuit}

(Generating entanglement, again).

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-41-1} \end{center}


\end{circuit}

In this circuit, first the two Hadamard gates prepare the equally-weighted superposition of all states from the computational basis

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-42-1} \end{center}

and then the controlled-\(Z\) operation flips the sign in front of \(|11\rangle\)

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-43-1} \end{center}

which results in the entangled state.

\hypertarget{controlled-u}{%
\subsubsection{Controlled-U}\label{controlled-u}}

Both the above two-qubit controlled gates (i.e.~\(\texttt{c-NOT}\) and \(\texttt{c-}P_\varphi\)) are specific examples of the more general construction of a \textbf{controlled-\(U\) gate}:
\[
  \texttt{c-}U
  =
  |0\rangle\langle 0|\otimes\mathbf{1}+ |1\rangle\langle 1|\otimes U
\]
where \(U\) is an arbitrary single-qubit unitary transformation \(U\).

\begin{idea}

\begin{longtable}[]{@{}c@{}}
\toprule
\begin{minipage}[b]{0.97\columnwidth}\centering
controlled-\(U\)\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.97\columnwidth}\centering
\(\left[\begin{array}{c|c}\begin{matrix}1&0\\0&1\end{matrix}&\begin{matrix}0&0\\0&0\end{matrix}\\\hline\begin{matrix}0&0\\0&0\end{matrix}&U\end{array}\right]\)\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}


\end{idea}

We can also represent the \(\texttt{c-}U\) gate using the circuit notation, as in Figure \ref{fig:c-U-diagram}.



\begin{figure}[H]

{\centering \includegraphics{iqis-book_files/figure-latex/c-U-diagram-1} 

}

\caption{Where \(x,y\in\{0,1\}\).}\label{fig:c-U-diagram}
\end{figure}

We can go even further and consider a more general unitary operation: the two-qubit \textbf{\(x\)-controlled-\(U\) gate}:
\[
  \sum_x |x\rangle\langle x|\otimes U_x
  \equiv
  |0\rangle\langle 0|\otimes U_0 + |1\rangle\langle 1|\otimes U_1
\]
where each \(U_x\) is a unitary transformation that is applied to the second qubit only if the first one is in state \(|x\rangle\).
In general, an \(x\)-controlled-\(U\) gate can be defined on two registers of arbitrary size \(n\) and \(m\), with \(x\in\{0,1\}^n\) and the \(U_x\) being \((2^m\times 2^m)\) unitary matrices acting on the second register.

\hypertarget{phase-kick-back}{%
\subsubsection{Phase kick-back}\label{phase-kick-back}}

Before moving on to the next section, we first describe a simple ``trick'' --- an unusual way of introducing phase shifts that will be essential for our analysis of quantum algorithms.
Consider the following circuit.

\begin{circuit}

(Controlled-\(U\) interference).

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-44-1} \end{center}

where \(|u\rangle\) is an \emph{eigenstate} of \(U\) (that is, \(U|u\rangle = e^{i\varphi}|u\rangle\) for some \(\varphi\)).


\end{circuit}

This should look familiar: it is the usual interference circuit, but with the phase gate replaced by a controlled-\(U\) gate, which will mimic the phase gate, as we shall soon see.
Note that the second qubit is prepared in state \(|u\rangle\), which is \emph{required to be an eigenstate of \(U\)}.
The circuit effects the following sequence of transformations (omitting the normalisation factors):
\[
  \begin{aligned}
    |0\rangle|u\rangle
    &\overset{H}{\longmapsto}
    (|0\rangle+|1\rangle)|u\rangle
  \\&\quad = |0\rangle|u\rangle + |1\rangle|u\rangle
  \\&\overset{\texttt{c-}U}{\longmapsto}
    |0\rangle|u\rangle + |1\rangle U|u\rangle
  \\&\quad = |0\rangle|u\rangle + e^{i\varphi}|1\rangle|u\rangle
  \\&\quad = (|0\rangle + e^{i\varphi}|1\rangle) |u\rangle
  \\&\overset{H}{\longmapsto}
    \left(
      \cos\frac{\varphi}{2}|0\rangle
      - i\sin\frac{\varphi}{2}|1\rangle
    \right) |u\rangle.
  \end{aligned}
\]
Note that the second qubit does \emph{not} get entangled with the first one: it remains in its original state \(|u\rangle\).
However, the interaction between the two qubits introduces a phase shift on the first qubit.
This may look like an unnecessarily complicated way of introducing phase shifts, but, as we shall soon see, this is how quantum computers do it.
Let me give you a preview of things to come.

Consider the following \(x\)-controlled-\(U\) operation:
\[
  \begin{gathered}
    \left[
      \begin{array}{cccc}
        \mathbf{1}& 0 & 0 & 0
      \\0 & \mathbf{1}& 0 & 0
      \\0 & 0 & \mathbf{1}& 0
      \\0 & 0 & 0 & X
      \end{array}
    \right]
  \\[1em]
    =|00\rangle\langle 00|\otimes\mathbf{1}
  \\+ |01\rangle\langle 01|\otimes\mathbf{1}
  \\+ |10\rangle\langle 10|\otimes\mathbf{1}
  \\+ |11\rangle\langle 11|\otimes X.
  \end{gathered}
\]
The first register is of size \(2\), and the second register is of size \(1\).
If the first register is prepared in state \(|11\rangle\), then the qubit in the second register is flipped (by the Pauli bit-flip \(X\)); otherwise, nothing happens.
This unitary operation is a quantum version of the Boolean function evaluation: it corresponds to the Boolean function
\[
  \begin{aligned}
    f\colon\{0,1\}^2 &\to \{0,1\}
  \\00&\mapsto0
  \\01&\mapsto0
  \\10&\mapsto0
  \\11&\mapsto1.
  \end{aligned}
\]
If \(f(x)=1\), then we flip the bit value in the second register (with operation \(X\)); if \(f(x)=0\), then we do nothing.

Now, prepare the qubit in the second register in state \(|0\rangle-|1\rangle\), which is an eigenstate of \(X\) with eigenvalue \(e^{\pi i}=-1\).
So whenever \(X\) is applied to the second register, the phase factor \(-1\) appears in front of the corresponding term in the first register.
If we prepare the first register in the superposition \(|00\rangle+|01\rangle+|10\rangle+|11\rangle\) then the result of applying the above \(x\)-controlled-\(U\) operation is the entangled state \(|00\rangle+|01\rangle+|10\rangle-|11\rangle\).
That is, \emph{the phase kick-back mechanism introduced a relative phase in the equally-weighted superposition of all binary strings of length two}.

\begin{idea}
Phase kick-back is how we control quantum interference in quantum computation.

\end{idea}

We will return to this topic later on, when we discuss quantum evaluation of Boolean functions and quantum algorithms.

\hypertarget{universality-revisited}{%
\subsubsection{Universality, revisited}\label{universality-revisited}}

We will come across few more gates in this course, but at this stage you already know all the elementary unitary operations that are needed to construct any unitary operation on any number of qubits:

\begin{itemize}
\tightlist
\item
  the Hadamard gate,
\item
  all phase gates, and
\item
  the \(\texttt{c-NOT}\)
\end{itemize}

These gates form a \textbf{universal set of gates}: with \(O(4^{n}n)\) of these gates, we can construct any \(n\)-qubit unitary operation.\footnote{Recall the big-\(O\) asymptotic notation: given a \emph{positive} function \(f(n)\), we write \(O(f(n))\) to mean ``bounded above by \(c\,f(n)\) for some constant \(c > 0\) (for sufficiently large \(n\))''. For example, \(15n^2+4n+7\) is \(O(n^2)\).}
We should mention that there are many universal sets of gates.
In fact, almost any gate that can entangle two qubits can be used as a universal gate.

We are particularly interested in any \emph{finite} universal set of gates (such as the one containing the Hadamard, \(P_{\frac{\pi}{4}}\) (the \(T\) gate), and the \(\texttt{c-NOT}\)), which can approximate any unitary operation on \(n\) qubits with arbitrary precision.
The price to pay is the number of gates --- better precision requires more gates.
We shall elaborate on this later.

\hypertarget{density-operators-and-the-like}{%
\subsubsection{Density operators and the like}\label{density-operators-and-the-like}}

The existence of entangled states leads to an obvious question: if we cannot attribute a state vector to an individual qubit, then how can we describe its quantum state?
In the next few chapters we will see that, when we limit our attentions to a part of a larger system, states are not represented by vectors, measurements are not described by orthogonal projections, and evolution is not unitary.
As a spoiler, here is a dictionary of some of the new concepts that will soon be introduced:

\begin{longtable}[]{@{}rcl@{}}
\toprule
\endhead
state vectors & \(\longmapsto\) & density operators\tabularnewline
unitary evolutions & \(\longmapsto\) & completely-positive trace-preserving maps\tabularnewline
orthogonal projectors & \(\longmapsto\) & positive operator-valued measures\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{why-qubits-subsystems-and-entanglement}{%
\subsection{Why qubits, subsystems, and entanglement?}\label{why-qubits-subsystems-and-entanglement}}

One question that is rather natural to ask at this point is the following:

\begin{quote}
If entanglement is so fragile and difficult to control, then why bother?
Why not perform the whole computation in one physical system that has as many quantum states as we normally have labels for the states of qubits, so that we can label these quantum states in the same way as we normally label the qubits, and give \emph{them} computational meaning?
\end{quote}

This suggestion, although possible, gives a very inefficient way of representing data (it is describing the \textbf{unary encoding}).
For serious computations \emph{we need subsystems}.
Here is why.

Suppose you have \(n\) physical objects, and each object has \(k\) distinguishable states.
If you can access each object \emph{separately} and put it into any of the \(k\) states, then, with only \(n\) operations, you can prepare any of the \(k^{n}\) different configurations of the combined systems.
Without any loss of generality, let us take \(k=2\) and refer to each object of this type as a \textbf{physical bit}.
We label the two states of a physical bit as \(0\) and \(1\).
Any collection of \(n\) physical bits can be prepared in \(2^{n}\) different configurations, which can be used to store up to \(2^{n}\) messages/binary strings/different numbers.
In order to represent numbers from \(0\) to \(N-1\) we just have to choose \(n\) such that \(N\leqslant 2^n\).

Suppose the two states in the physical bit are separated by the energy difference \(\Delta E\).
Then a preparation of any particular configuration will cost no more than \(E=n \Delta E=(\log_2 N)\Delta E\) units of energy.

In contrast, if we choose to encode \(N\) configurations into one chunk of matter, say, into the first \(N\) energy states of a single harmonic oscillator with the interstate energy separation \(\Delta E\) then, in the worst case, one has to use \(E=N\Delta E\) units of energy, e.g.~to go from the ground state (labelled as \(0\)) to the most excited state (labelled as \(N\)).
For large \(N\) this gives an exponential gap in the energy expenditure between the binary encoding using physical bits and unary encoding, using energy levels of harmonic oscillators.

One can, of course, try to switch from harmonic oscillators to quantum systems which have a finite spread in the energy spectrum.
For example, by operating on the energy states of the hydrogen atom one can encode any number from \(0\) to \(N-1\), and one is guaranteed not to spend more than \(E_{\mathrm{max}}=\) \(13.6\,\mathrm{eV}\) (otherwise the atom is ionised).
The snag is that, in this case, some of the electronic states will be separated by the energy difference to the order of \(E_{\mathrm{max}}/N\), and to drive the system selectively from one state to another one has to tune into the frequency \(E_{\mathrm{max}}/\hbar N\), which requires a sufficiently long wave-packet (so that the frequency is well defined), and consequently the
interaction time is of order \(N(\hbar/E_{\mathrm{max}})\).

That is, we have to trade energy for time.

It turns out that whichever way we try to represent the number \(N\) using the unary encoding (i.e.~using \(N\) different states of a single chunk of matter), we end up depleting our physical resources (such as energy, time, space) at a much greater rate than in the case when we use subsystems.
This plausibility argument indicates that, for efficient processing of information, the system must be divided into subsystems --- for example, into physical bits.

\hypertarget{remarks-and-exercises-5}{%
\subsection{\texorpdfstring{\emph{Remarks and exercises}}{Remarks and exercises}}\label{remarks-and-exercises-5}}

\hypertarget{entangled-or-not}{%
\subsubsection{Entangled or not?}\label{entangled-or-not}}

Let a joint state of \(\mathcal{A}\) and \(\mathcal{B}\) be written in a product basis as
\[
  |\psi\rangle = \sum_{ij} c_{ij}|a_i\rangle\otimes|b_j\rangle.
\]
Assume that \(\mathcal{H}_a\) and \(\mathcal{H}_b\) are of the same dimension.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Show that, if \(|\psi\rangle\) is a product state, then \(\det (c_{ij}) = 0\).
\item
  Show that the converse (\(\det(c_{ij})=0\) implies that \(|\psi\rangle\) is a product state) holds only for qubits. Explain why.
\item
  Deduce that the state
  \[
     \frac12\big(|00\rangle + |01\rangle + |10\rangle + (-1)^k|11\rangle\big)
   \]
  is entangled for \(k=1\) and unentangled for \(k=0\). Express the latter case explicitly as a product state.
\end{enumerate}

There is a lot of interesting physics behind the previous innocuous-looking mathematical statement.
For example, think again about the state \((|00\rangle+|11\rangle)/\sqrt2\).
What happens if you measure just the first qubit?
It is equally likely that you get \(|0\rangle\) or \(|1\rangle\), right?
But after your measurement the two qubits are either in state \(|00\rangle\) or in \(|11\rangle\), i.e.~they show the same bit value.
Now, why might that be disturbing?
Well, imagine the second qubit to be light-years away from the first one.
It seems that the measurement of the first qubit affects the second qubit right away, which seems to imply faster-than-light communication!
This is what Einstein called ``spooky action as a distance''.\footnote{``Spooky action at a distance'' is a loose translation of the German ``spukhafte Fernwirkung'', which is the phrase that Albert Einstein used in his 1947 letter to Max Born.}
But can you actually use this effect to send a message faster than light?
What would happen if you tried?

Hopefully you can see that it would not work, since the result of the measurement is random --- you cannot choose the bit value you want to send.
We shall return to this, and other related phenomena, later on.

\hypertarget{swap-circuit}{%
\subsubsection{SWAP circuit}\label{swap-circuit}}

Show that, for any states \(|\psi_1\rangle\) and \(|\psi_2\rangle\), the circuit below implements the \(\texttt{SWAP}\) operation \(|\psi_1\rangle|\psi_2\rangle \mapsto |\psi_2\rangle|\psi_1\rangle\).

\begin{circuit}

(Swapping).

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-45-1} \end{center}


\end{circuit}

\hypertarget{controlled-not-circuit}{%
\subsubsection{Controlled-NOT circuit}\label{controlled-not-circuit}}

Show that the circuit below implements the controlled-\(\texttt{NOT}\) gate.

\begin{circuit}

(Controlled-\(\texttt{NOT}\), again).

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-46-1} \end{center}


\end{circuit}

\hypertarget{measuring-with-controlled-not}{%
\subsubsection{Measuring with controlled-NOT}\label{measuring-with-controlled-not}}

The controlled-\(\texttt{NOT}\) gate can act as a measurement gate: if you prepare the target in state \(|0\rangle\) then the gate acts as \(|x\rangle|0\rangle\mapsto|x\rangle|x\rangle\), and so the target learns the bit value of the control qubit.
If you wish, you can think about a subsequent measurement of the target qubit in the computational basis as an observer learning about the bit value of the control qubit.

Take a look at the circuit below, where \(M\) stands for measurement in the standard basis.

\begin{circuit}

(?).

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-47-1} \end{center}


\end{circuit}

Now assume that the top two qubits are in the state
\[
  |\psi\rangle
  = \frac{1}{\sqrt3}\big( |01\rangle - |10\rangle + i|11\rangle \big).
\]
The measurement \(M\) gives two outcomes: \(0\) and \(1\).
What are the probabilities of each outcome, and what is the post-measurement state in each case?
Further, what is actually being measured here?

\hypertarget{arbitrary-controlled-u-on-two-qubits}{%
\subsubsection{Arbitrary controlled-U on two qubits}\label{arbitrary-controlled-u-on-two-qubits}}

Any unitary operation \(U\) on a single qubit can be expressed as
\[
  U = B^\dagger XBA^\dagger XA
\]
where \(X\equiv\sigma_x\) is the Pauli bit-flip operator, and \(A\) and \(B\) are unitaries.
Suppose that you can implement any single qubit gate, and that you have a bunch of controlled-\(\texttt{NOT}\) gates at your disposal.
How would you implement any controlled-\(U\) operation on two qubits?

\hypertarget{entangled-qubits}{%
\subsubsection{Entangled qubits}\label{entangled-qubits}}

Two entangled qubits in the state \(\frac{1}{\sqrt2}(|00\rangle+|11\rangle)\) are generated by some source \(S\).
One qubit is sent to Alice, and one to Bob, who then both perform measurements in the computational basis.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  What is the probability that Alice and Bob will register identical results?
  Can any correlations they observe be used for instantaneous communication?
\item
  Prior to the measurements in the computational basis, Alice and Bob apply unitary operations \(R_\alpha\) and \(R_\beta\) (respectively) to their respective qubits:

  \begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-48-1} \end{center}

  The gate \(R_\theta\) is defined by its action on the basis states:
  \[
     \begin{aligned}
       |0\rangle
       &\longmapsto
       \cos\theta|0\rangle + \sin\theta|1\rangle
     \\|1\rangle
       &\longmapsto
       -\sin\theta|0\rangle + \cos\theta|1\rangle.
     \end{aligned}
   \]
  Show that the state of the two qubits prior to the measurements is
  \[
     \begin{aligned}
       &\frac{1}{\sqrt2}\cos(\alpha-\beta)\big( |00\rangle + |11\rangle \big)
     \\- &\frac{1}{\sqrt2}\sin(\alpha-\beta)\big( |01\rangle - |10\rangle \big).
     \end{aligned}
   \]
\item
  What is the probability that Alice and Bob's outcomes are identical?
\end{enumerate}

\hypertarget{quantum-dense-coding}{%
\subsubsection{Quantum dense coding}\label{quantum-dense-coding}}

\textbf{!!!TO-DO!!!}

\hypertarget{playing-with-conditional-unitaries}{%
\subsubsection{Playing with conditional unitaries}\label{playing-with-conditional-unitaries}}

The swap gate \(S\) on two qubits is defined first on product vectors by \(S\colon|a\rangle|b\rangle\mapsto|b\rangle|a\rangle\) and then extended to sums of product vectors by linearity.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Show that the four Bell states \(\frac{1}{\sqrt2}(|00\rangle\pm|11\rangle)\) and \(\frac{1}{\sqrt2}(|01\rangle\pm|10\rangle)\) are eigenvectors of \(S\) that form an orthonormal basis in the Hilbert space associated to two qubits.
  Which Bell states span the \emph{symmetric subspace} (i.e.~the space spanned by all eigenvectors with eigenvalue \(1\)), and which the \emph{antisymmetric} one (i.e.~that spanned by eigenvectors with eigenvalue \(-1\))?
  Can \(S\) have any eigenvalues apart from \(\pm1\)?
\item
  Show that \(P_\pm = \frac12(\mathbf{1}\pm S)\) are two orthogonal projectors which form the decomposition of the identity and project on the symmetric and antisymmetric subspaces.
  Decompose the state vector \(|a\rangle|b\rangle\) of two qubits into symmetric and antisymmetric components.
\item
  Consider the quantum circuit below, composed of two Hadamard gates, one controlled-\(S\) operation (also known as the \textbf{controlled-swap}, or \textbf{Fredkin} gate), and the measurement \(M\) in the computational basis.
  Suppose that the state vectors \(|a\rangle\) and \(|b\rangle\) are normalised but \emph{not} orthogonal to one another.
  Step through the execution of this network, writing down the quantum states of the three qubits after each computational step.
  What are the probabilities of observing \(0\) or \(1\) when the measurement \(M\) is performed?
\end{enumerate}

\begin{circuit}

(Symmetric and antisymmetric projection).

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-49-1} \end{center}


\end{circuit}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\item
  Explain why this quantum network implements projections on the symmetric and antisymmetric subspaces of the two qubits.
\item
  Two qubits are transmitted through a quantum channel which applies the same, randomly chosen, unitary operation \(U\) to each of them.
  Show that the symmetric and antisymmetric subspaces are invariant under \(U\otimes U\).
\item
  Polarised photons are transmitted through an optical fibre.
  Due to the variation of the refractive index along the fibre, the polarisation of each photon is rotated by the same unknown angle.
  This makes communication based on polarisation encoding unreliable.
  However, if you can prepare any polarisation state of the two photons then you can still use the channel to communicate without any errors.
  How can this be achieved?
\end{enumerate}

\hypertarget{appendices}{%
\subsection{\texorpdfstring{\emph{Appendices}}{Appendices}}\label{appendices}}

\hypertarget{tensor-products-in-components}{%
\subsubsection{Tensor products in components}\label{tensor-products-in-components}}

In our discussion of tensor products we have so far taken a rather abstract approach.
There are, however, situations in which we have to put numbers in, and write tensor products of vectors and matrices explicitly.
For example, here is the standard basis of two qubits written explicitly as column vectors:
\[
  \begin{aligned}
    |00\rangle &\equiv |0\rangle\otimes|0\rangle
    = \begin{bmatrix}1\\0\end{bmatrix} \otimes \begin{bmatrix}1\\0\end{bmatrix}
    = \begin{bmatrix}1\\0\\0\\0\end{bmatrix}
  \\[1em]
    |01\rangle &\equiv |0\rangle\otimes|1\rangle
    = \begin{bmatrix}1\\0\end{bmatrix} \otimes \begin{bmatrix}0\\1\end{bmatrix}
    = \begin{bmatrix}0\\1\\0\\0\end{bmatrix}
  \\[1em]
    |10\rangle &\equiv |1\rangle\otimes|0\rangle
    = \begin{bmatrix}0\\1\end{bmatrix} \otimes \begin{bmatrix}1\\0\end{bmatrix}
    = \begin{bmatrix}0\\0\\1\\0\end{bmatrix}
  \\[1em]
    |11\rangle &\equiv |1\rangle\otimes|1\rangle
    = \begin{bmatrix}0\\1\end{bmatrix} \otimes \begin{bmatrix}0\\1\end{bmatrix}
    = \begin{bmatrix}0\\0\\0\\1\end{bmatrix}
  \end{aligned}
\]
Given \(|a\rangle = \alpha_0|0\rangle + \alpha_1|1\rangle\) and \(|b\rangle = \beta_0|0\rangle +\beta_1|1\rangle\), we write \(|a\rangle\otimes|b\rangle\) as
\[
  \begin{aligned}
    |a\rangle\otimes|b\rangle
    &= \begin{bmatrix}\alpha_0\\\alpha_1\end{bmatrix} \otimes \begin{bmatrix}\beta_0\\\beta_1\end{bmatrix}
  \\&= \begin{bmatrix}\alpha_0\begin{bmatrix}\beta_0\\\beta_1\end{bmatrix}\\\alpha_1\begin{bmatrix}\beta_0\\\beta_1\end{bmatrix}\end{bmatrix}
  \\&= \begin{bmatrix}\alpha_0\beta_0\\\alpha_0\beta_1\\\alpha_1\beta_0\\\alpha_1\beta_1\end{bmatrix}.
  \end{aligned}
\]
Note that each element of the first vector multiplies the entire second vector.
This is often the easiest way to get the tensor products in practice.

The matrix elements of the tensor product operation \(A\otimes B\)

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-50-1} \end{center}

are given by
\[
  (A\otimes B)_{ik,jl} = A_{ij}B_{kl}
\]
where \(ik\in\{00,01,10,11\}\) labels the rows, and \(kl\in\{00,01,10,11\}\) labels columns, when forming the block matrix:\footnote{We always use the lexicographic order \(00<01<10<11\).}
\[
  \begin{aligned}
    A\otimes B
    &= \begin{bmatrix}A_{00}&A_{01}\\A_{10}&A_{11}\end{bmatrix} \otimes \begin{bmatrix}B_{00}&B_{01}\\B_{10}&B_{11}\end{bmatrix}
  \\&= \begin{bmatrix}A_{00}B&A_{01}B\\A_{10}B&A_{11}B\end{bmatrix}
  \\&=
  \left[
  \,
    \begin{array}{c|c}
      \begin{matrix}A_{00}B_{00}&A_{00}B_{01}\\A_{00}B_{10}&A_{00}B_{11}\end{matrix}
      & \begin{matrix}A_{01}B_{00}&A_{01}B_{01}\\A_{01}B_{10}&A_{01}B_{11}\end{matrix}
    \\\hline
    \begin{matrix}A_{10}B_{00}&A_{10}B_{01}\\A_{10}B_{10}&A_{10}B_{11}\end{matrix}
      & \begin{matrix}A_{11}B_{00}&A_{11}B_{01}\\A_{11}B_{10}&A_{11}B_{11}\end{matrix}
    \end{array}
  \,
  \right]
  \end{aligned}
\]

The tensor product induces a natural partition of matrices into blocks.
Multiplication of block matrices works pretty much the same as regular matrix multiplication (assuming the dimensions of the sub-matrices are appropriate), except that the entries are now matrices rather than numbers, and so may not commute.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Evaluate the following matrix product of \((4\times 4)\) block matrices:
  \[
     \left[
     \,
       \begin{array}{c|c}
         \mathbf{1}& X
       \\\hline
         Y & Z
       \end{array}
     \,
     \right]
     \left[
     \,
       \begin{array}{c|c}
         \mathbf{1}& Y
       \\\hline
         X & Z
       \end{array}
     \,
     \right]
   \]
  (where \(X\), \(Y\), and \(Z\) are the Pauli matrices).
\item
  Using the block matrix form of \(A\otimes B\) expressed in terms of \(A_{ij}\) and \(B_{ij}\) (as described above), explain how the following operations are performed on the block matrix:

  \begin{itemize}
  \tightlist
  \item
    transposition \((A\otimes B)^T\); partial transpositions \(A^T\otimes B\) and \(A\otimes B^T\);
  \item
    trace \(\operatorname{tr}(A\otimes B)\); partial traces \((\operatorname{tr}A )\otimes B\) and \(A\otimes (\operatorname{tr}B)\).
  \end{itemize}

  Consider the Hadamard transform \(H\otimes H\otimes H\) on three qubits, which is described by a \((2^3\times2^3)\) matrix.
  We know that
  \[
     H = \frac{1}{\sqrt2}\begin{bmatrix}1&1\\1&-1\end{bmatrix}
   \]
  and so we can calculate that
  \[
     H\otimes H
     = \frac12
     \left[
     \,
       \begin{array}{c|c}
         \begin{matrix}1&1\\1&-1\end{matrix}
         & \begin{matrix}1&1\\1&-1\end{matrix}
       \\\hline
         \begin{matrix}1&1\\1&-1\end{matrix}
         & \begin{matrix}-1&-1\\-1&1\end{matrix}
       \end{array}
     \,
     \right]
   \]
  and thus that
  \[
     H\otimes H\otimes H
     = \frac12
     \left[
     \,
       \begin{array}{c|c|c|c}
         \begin{matrix}1&1\\1&-1\end{matrix}
         & \begin{matrix}1&1\\1&-1\end{matrix}
         & \begin{matrix}1&1\\1&-1\end{matrix}
         & \begin{matrix}1&1\\1&-1\end{matrix}
       \\\hline
         \begin{matrix}1&1\\1&-1\end{matrix}
         & \begin{matrix}-1&-1\\-1&1\end{matrix}
         & \begin{matrix}1&1\\1&-1\end{matrix}
         & \begin{matrix}-1&-1\\-1&1\end{matrix}
       \\\hline
         \begin{matrix}1&1\\1&-1\end{matrix}
         & \begin{matrix}1&1\\1&-1\end{matrix}
         & \begin{matrix}-1&-1\\-1&1\end{matrix}
         & \begin{matrix}-1&-1\\-1&1\end{matrix}
       \\\hline
         \begin{matrix}1&1\\1&-1\end{matrix}
         & \begin{matrix}-1&-1\\-1&1\end{matrix}
         & \begin{matrix}-1&-1\\-1&1\end{matrix}
         & \begin{matrix}1&1\\1&-1\end{matrix}
       \end{array}
     \,
     \right].
   \]
  The rows and columns of \(H\otimes H\otimes H\) are labelled by the triples \(000,001,\ldots,111\).
  Now, suppose we apply \(H\otimes H\otimes H\) to the state \(|110\rangle\):
\end{enumerate}

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-51-1} \end{center}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\item
  The output state is a superposition of all binary strings: \(\sum_x c_x|x\rangle\), with \(x\in\{0,1\}^3\).
  Where in the \(H^{\otimes 3}\) matrix will you find the coefficients \(c_x\)?

  Now, do you want to write down \(H\otimes H\otimes H\otimes H\)?
  I don't think so.
  This is an exponentially growing monster and you may soon run out of space if you actually do try to write it down.
  Instead, let's spot the pattern of the entries \(\pm1\) in these matrices.
\item
  Consider the Hadamard gate matrix \(H_{ab}\), where \(a,b=0,1\) are the labels for the rows and the columns.
  Observe that \(H_{ab}=(-1)^{ab}/\sqrt{2}\).
  (This may look like a fancy way of writing the entries of the Hadamard matrix but it will pay off in a moment).
  Using the fact that \((A\otimes B)_{ik,jl} = A_{ij}B_{kl}\), or any other method, analyse the pattern of the \(\pm1\) in the tensor product of Hadamard matrices.
  What is the entry \(H^{\otimes 4}_{0101,1110}\)?
\item
  For any two binary strings \(a=(a_1,\ldots, a_n)\) and \(b =(b_1,\ldots , b_n)\) of the same length we can define their ``scalar'' product as \(a\cdot b = (a_1b_1\oplus \ldots \oplus a_n b_n)\).
  Show that, up to the constant \((1/\sqrt{2})^n\), the entry \(H^{\otimes n}_{a,b}\), for any \(n\) and for any binary strings \(a\) and \(b\) of length \(n\), is \((-1)^{a\cdot b}\).
\item
  Show that \(H^{\otimes n}\) acts as
  \[
     |a\rangle
     \longmapsto
     \left(\frac{1}{\sqrt 2}\right)^n
     \sum_{b\in\{0,1\}^n} (-1)^{a\cdot b}|b\rangle
   \]
\item
  A quantum register of \(10\) qubits holds the binary string \(0110101001\).
  The Hadamard Transform is then applied to this register yielding a superposition of all binary strings of length \(10\).
  What is the sign in front of the \(|0101010101\rangle\) term?
\end{enumerate}

\hypertarget{the-schmidt-decomposition}{%
\subsubsection{The Schmidt decomposition}\label{the-schmidt-decomposition}}

An arbitrary vector in the Hilbert space \(\mathcal{H}_{\mathcal{A}}\otimes \mathcal{H}_{\mathcal{B}}\) can be expanded in a product basis as
\[
  |\psi\rangle
  = \sum_{ij} c_{ij}|a_i\rangle|b_j\rangle.
\]
Moreover, for each particular joint state \(|\psi\rangle\), we can find orthonormal bases, \(\{|\widetilde{a_i}\rangle\}\) in \(\mathcal{H}_{\mathcal{A}}\) and \(\{|\widetilde{b_j}\rangle\}\) in \(\mathcal{H}_{\mathcal{B}}\), such that \(|\psi\rangle\) can be expressed as
\[
  |\psi\rangle
  = \sum_{i} d_{i}|\tilde a_i\rangle|\tilde b_i\rangle,
\]
where the coefficients \(d_i\) are non-negative numbers.
This is known as the \textbf{Schmidt decomposition} of \(|\psi\rangle\).
Any bipartite state can be expressed in this form, but remember that \emph{the bases used depend on the state being expanded}.
Indeed, given two bipartite states \(|\psi\rangle\) and \(|\phi\rangle\), we usually \emph{cannot} perform the Schmidt decomposition using the \emph{same} orthonormal bases in \(\mathcal{H}_{\mathcal{A}}\) and \(\mathcal{H}_{\mathcal{B}}\).
The number of terms in the Schmidt decomposition is, at most, the minimum of \(\dim\mathcal{H}_{\mathcal{A}}\) and \(\dim\mathcal{H}_{\mathcal{B}}\).

The Schmidt decomposition follows from the \textbf{singular value decomposition} or \textbf{SVD}): \emph{any} \((n\times m)\) matrix \(C\) can be written as
\[
  C = UDV
\]
where \(U\) and \(V\) are (respectively) \((n\times n)\) and \((m\times m)\) unitary matrices and \(D\) is an \((n\times m)\) diagonal matrix with real, non-negative elements in descending order \(d_1\geqslant d_2\geqslant\ldots\geqslant d_{\min{(n,m)}}\) (and with the rest of the matrix is filled with zeros).
The elements \(d_k\) are called the \textbf{singular values} of \(C\).

You can visualize the SVD by thinking of \(C\) as representing a linear
transformation from \(m\)-dimensional to \(n\)-dimensional Euclidean space: it maps the unit ball in the \(m\)-dimensional space to an ellipsoid in
the \(n\)-dimensional space; the singular values are the lengths of
the semi-axes of that ellipsoid; the matrices \(U\) and \(V\) carry
information about the locations of those axes and the vectors in
the first space which map into them.
Thus SVD tells us that the transformation \(C\) is composed of rotating the unit ball (transformation \(V\)), stretching the axes by factors \(d_k\), and then rotating the resulting ellipsoid (transformation \(U\)).

Using the index notation \(C_{ij} = \sum_k U_{ik}d_k V_{kj}\), we can thus apply SVD to \(c_{ij}\),
\[
  \begin{aligned}
    |\psi\rangle
    &= \sum_{ij} c_{ij}|a_ib_j\rangle
  \\&= \sum_{ij} \sum_k U_{ik}d_k V_{kj}|a_ib_j\rangle
  \\&= \sum_k d_k \left(\sum_i U_{ik}|a_i\rangle\right)\otimes\left(\sum_j V_{kj}|b_j\rangle\right).
  \end{aligned}
\]
The Schmidt decomposition of a separable state of the form
\(|a\rangle\otimes|b\rangle\) is trivially just this state.
The Bell states \(\Psi^+\) and \(\Phi^+\) are already written in their Schmidt form, whereas \(\Psi^-\) and \(\Phi^-\) can be easily expressed in the Schmidt form.
For example, for \(|\Psi^-\rangle\) we have \(d_1 = d_2 = \frac{1}{\sqrt 2}\), and the Schmidt basis is \(|\bar a_1\rangle =|0\rangle, |\bar a_2\rangle=|1\rangle\), \(|\bar b_1\rangle = |1\rangle, |\bar b_2\rangle=-|0\rangle\).
The number of non-zero singular values of \(c_{ij}\) is called the \textbf{rank} of \(c_{ij}\), or the rank of the corresponding quantum state, or sometimes, the \textbf{Schmidt number}.
Clearly, all bipartite states of rank one are separable.

The Schmidt decomposition is \emph{almost} unique.
The ambiguity arises when we have two or more identical singular values, as, for example, in the case of the Bell states.
Then any unitary transformation of the basis vectors corresponding to a degenerate singular value, both in \(\mathcal{H}_a\) and in \(\mathcal{H}_b\), generates another set of basis vectors.

\hypertarget{density-matrices}{%
\section{Density matrices}\label{density-matrices}}

\begin{quote}
About \textbf{density matrices}, and how they help to solve the problem introduced by entangled states, as well as how they let us talk about mixtures and subsystems.
Also a first look at the \textbf{partial trace}.
\end{quote}

We cannot always assign a definite state vector to a quantum system.
It may be that the system is part of a composite system that is in an entangled state, or it may be that our knowledge of the preparation of a particular system is insufficient to determine its state (for example, someone may prepare a particle in one of the states \(|\psi_1\rangle, |\psi_2\rangle, \ldots, |\psi_n\rangle\), with (respective) probabilities \(p_1, p_2, \ldots, p_n\)).
Nevertheless, in either case we are able to make statistical predictions about the outcomes of measurements performed on the system using a more general description of quantum states.

We have already mentioned that the existence of entangled states begs an obvious question: if we cannot attribute a state vectors to an individual quantum system then how shall we describe its quantum state?
In this chapter we will introduce an alternate description of quantum states that can be applied both to a composite system and to any of its subsystems.
Our new mathematical tool is called a \textbf{density operator}.\footnote{If we choose a particular basis, operators become matrices. Here I will use both terms (density \emph{operators} and density \emph{matrices}) interchangeably.}
We will start with the density operator as a description of the mixture of quantum states, and will then discuss the partial trace, which is a unique operation that takes care of the reduction of a density operator of a composite system to density operators of its components.

\hypertarget{definitions}{%
\subsection{Definitions}\label{definitions}}

If you are an impatient mathematically minded person, who feels more comfortable when things are properly defined right from the beginning, here is your definition:\footnote{A self-adjoint matrix \(M\) is said to be \textbf{non-negative}, or \textbf{positive semi-definite}, if \(\langle v|M|v\rangle\geqslant 0\) for any vector \(|v\rangle\), or if all of its eigenvalues are non-negative, or if there exists a matrix \(A\) such that \(M=A^\dagger A\). (This is called a \textbf{Cholesky factorization}.)}

\begin{idea}
A \textbf{density operator} \(\rho\) on a finite dimensional Hilbert space \(\mathcal{H}\) is any non-negative self-adjoint operator with trace equal to one.

\end{idea}

It follows that any such \(\rho\) can always be diagonalised, that the eigenvalues are all real and non-negative, and that the eigenvalues sum to one.
Moreover, given two density operators \(\rho_1\) and \(\rho_2\), we can always construct another density operator as a convex sum of the two:
\[
  \rho = p_1\rho_1 + p_2\rho_2
  \qquad\text{where}\quad
  p_1, p_2 \geqslant 0
  \text{ and }
  p_1+p_2 = 1.
\]
You should check that \(\rho\) has all the defining properties of a density matrix, i.e.~that it is self-adjoint, non-negative, and that its trace is one.
This means that density operators form a convex set.\footnote{A subset of a vector space is said to be \textbf{convex} if, for any two points in the subset, the straight line segment joining them is also entirely contained inside the subset.}

An important example of a density operator is a rank one projector.\footnote{The \textbf{rank} of a matrix is the number of its non-zero eigenvalues.}
Any quantum state that can be described by the state vector \(|\psi\rangle\), called a \textbf{pure state}, can be also described by the density operator \(\rho=|\psi\rangle\langle\psi|\).
Pure states are the extremal points in the convex set of density operators: they cannot be expressed as a convex sum of other elements in the set.
In contrast, all other states, called \textbf{mixed states}, can be always written as the convex sum of pure states: \(\sum_i p_i |\psi_i\rangle\langle\psi_i|\) (\(p_i\geqslant 0\) and \(\sum_i p_i=1\)).
Now that we have cleared the mathematical essentials, we will turn to physical applications.

\hypertarget{statistical-mixtures}{%
\subsection{Statistical mixtures}\label{statistical-mixtures}}

Let us start with probability distributions over state vectors.
Suppose Alice prepares a quantum system and hands it over to Bob who subsequently measures observable \(M\).
If Alice's preparation is described by a state vector \(|\psi\rangle\), then, quantum theory declares, the average value of any observable \(M\) is given by \(\langle\psi|M|\psi\rangle\), which can be also written as\footnote{If \(M\) is one of the orthogonal projectors \(P_k\) describing the measurement, then the average \(\langle P_k\rangle\) is the probability of the outcome \(k\) associated with this projector.}
\[
  \langle M\rangle = \operatorname{tr}M|\psi\rangle\langle\psi|.
\]
This way of expressing the average value makes a clear separation between the contributions from the state preparation and from the choice of the measurement.
We have two operators under the trace: one of them, \(|\psi\rangle\langle\psi|\), describes the state preparation, and the other one, \(M\), the measurement.
Now, suppose Alice prepares the quantum system in one of the states \(|\psi_1\rangle,\ldots,|\psi_m\rangle\), choosing state \(|\psi_i\rangle\) with probability \(p_i\), and hands the system to Bob without telling him which state was chosen.
The possible states \(|\psi_i\rangle\) are normalised but need not be orthogonal.
We call this situation a \textbf{mixture of the states} \(|\psi_i\rangle\), or a \textbf{mixed state} for short.

\begin{idea}
Remember, a mixture of states is very different from a superposition of states: a superposition \emph{always} yields a definite state vector, whereas a mixture does \emph{not}, and so must be described by a density operator.

\end{idea}

Bob knows the ensemble of states \(|\psi_1\rangle,\ldots,|\psi_m\rangle\) and the corresponding probability distribution \(p_1,\ldots,p_m\), and can hence calculate \(\langle M\rangle\) as\footnote{A pure state can be seen as a special case of a mixed state, where all but one the probabilities \(p_i\) equal zero.}
\[
  \begin{aligned}
    \langle M\rangle
    &= \sum_i p_i\left( \operatorname{tr}M|\psi_i\rangle\langle\psi_i| \right)
  \\&= \operatorname{tr}M \underbrace{\left( \sum_i p_i|\psi_i\rangle\langle\psi_i| \right)}_{\rho}
  \\&=\operatorname{tr}M\rho.
  \end{aligned}
\]
Again, we have two operators under the trace: \(\rho=\sum_i p_i|\psi_i\rangle\langle\psi_i|\), which pertains to the state preparation, and \(M\), which describes the measurement.
We shall call the operator
\[
  \rho = \sum_i p_i |\psi_i\rangle\langle\psi_i|
\]
the \textbf{density operator}, since it has all the defining properties of the density operator (the convex sum of rank one projectors).
It depends on the constituent states \(|\psi_i\rangle\) and their probabilities, and it describes our ignorance about the state preparation.

Once we have \(\rho\) we can make statistical predictions: for any observable \(M\) we have
\[
  \langle M\rangle = \operatorname{tr}M\rho.
\]
We see that the exact composition of the mixture does not enter this formula: for computing the statistics associated with any observable property of a system, all that matters is the density operator itself, and not its decomposition into the mixture of states.
This is important because any given density operator, with the remarkable exception of a pure state, can arise from many different mixtures of pure states.
Consider, for example, the following three scenarios:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Alice flips a fair coin.
  If the result is \(\texttt{Heads}\) then she prepares the qubit in the state \(|0\rangle\), and if the result is \(\texttt{Tails}\) then she prepares the qubit in the state \(|1\rangle\).
  She gives Bob the qubit without revealing the result of the coin-flip.
  Bob's knowledge of the qubit is described by the density matrix
  \[
     \frac12|0\rangle\langle 0| + \frac12|1\rangle\langle 1|
     =
     \begin{bmatrix}
       \frac12 & 0
     \\0 & \frac12
     \end{bmatrix}.
   \]
\item
  Suppose Alice flips a fair coin, as before, but now if the result is \(\texttt{Heads}\) then she prepares the qubit in the state \(|\bar{0}\rangle = \frac{1}{\sqrt{2}}(|0\rangle + |1\rangle)\), and if the result is \(\texttt{Tails}\) then she prepares the qubit in the state \(|\bar{1}\rangle = \frac{1}{\sqrt{2}}(|0\rangle - |1\rangle)\).
  Bob's knowledge of the qubit is now described by the density matrix
  \[
     \begin{aligned}
       \frac12|\bar{0}\rangle\langle\bar{0}| + \frac12|\bar{1}\rangle\langle\bar{1}|
       &=
       \frac12
       \begin{bmatrix}
       \frac12 & \frac12
       \\\frac12 & \frac12
       \end{bmatrix}
       +
       \frac12
       \begin{bmatrix}
       \frac12 & -\frac12
       \\-\frac12 & \frac12
       \end{bmatrix}
     \\&=
       \begin{bmatrix}
       \frac12 & 0
       \\0 & \frac12
       \end{bmatrix}.
     \end{aligned}
   \]
\item
  Suppose Alice picks up any pair of orthogonal states of a qubit and then flips the coin to chose one of them.
  Any two orthonormal states of a qubit, \(|u_1\rangle\), \(|u_2\rangle\), form a complete basis, so the mixture \(\frac12|u_1\rangle\langle u_1|+\frac12|u_2\rangle\langle u_2|\) gives \(\frac12\mathbf{1}\).
\end{enumerate}

As you can see, these three different preparations yield precisely the same density matrix and are hence statistically indistinguishable.
In general, two different mixtures can be distinguished (in a statistical sense) if and only if they yield different density matrices.
In fact, the optimal way of distinguishing quantum states with different density operators is still an active area of research.

\hypertarget{a-few-instructive-examples-and-some-less-instructive-remarks}{%
\subsection{A few instructive examples, and some less instructive remarks}\label{a-few-instructive-examples-and-some-less-instructive-remarks}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  The density matrix corresponding to the state vector \(|\psi\rangle\) is the rank one projector \(|\psi\rangle\langle\psi|\).
  Observe that there is no phase ambiguity, since \(|\psi\rangle\mapsto e^{i\phi}|\psi\rangle\) leaves the density matrix unchanged, and each \(|\psi\rangle\) gives rise to a distinct density matrix.
\item
  If Alice prepares a qubit in the state \(|\psi\rangle = \alpha|0\rangle + \beta|1\rangle\) then the corresponding density matrix is the projector
  \[
     |\psi\rangle\langle\psi|
     =
     \begin{bmatrix}
       |\alpha|^2 & \alpha\beta^\star
     \\\alpha^\star\beta & |\beta|^2
     \end{bmatrix}.
   \]
\item
  You are given a qubit and you are told that it was prepared either in state \(|0\rangle\) with probability \(|\alpha|^2\) or in state \(|1\rangle\) with probability \(|\beta|^2\).
  In this case all you can say is that your qubit is in a mixed state described by the density matrix
  \[
     |\alpha|^2|0\rangle\langle 0| + |\beta|^2|1\rangle\langle 1|
     =
     \begin{bmatrix}
       |\alpha|^2 & 0
     \\0 & |\beta|^2
     \end{bmatrix}.
   \]
  Diagonal density matrices correspond to classical probability distributions on the set of basis vectors.
\item
  Suppose you want to distinguish between preparations described by the density matrices in examples 2 and 3.
  Assume that you are given sufficiently many identically prepared qubits described either by the density matrix in example 2 or by the density matrix in example 3.
  Which of the two measurements would you choose: the measurement in the standard basis \(\{|0\rangle,|1\rangle\}\), or the measurement in the basis \(\{|\psi\rangle,|\psi_\perp\rangle\}\)?
  One of the two measurements is completely useless.
  Which one, and why?
\item
  In general, the diagonal entries of a density matrix describe the probability distributions on the set of basis vectors.
  They must add up to one, which is why the trace of any density matrix is one.
  The off-diagonal elements, often called \textbf{coherences}, signal departure from the classical probability distribution and quantify the degree to which a quantum system can interfere (we will discuss this in detail later on).
  The process in which off-diagonal entries (the parameter \(\epsilon\) in the matrices below) go to zero is called \textbf{decoherence}.
  \[
     \begin{bmatrix}
       |\alpha|^2 & \alpha\beta^\star
     \\\alpha^\star\beta & |\beta|^2
     \end{bmatrix}
     \mapsto
     \begin{bmatrix}
       |\alpha|^2 & \epsilon
     \\\epsilon^\star & |\beta|^2
     \end{bmatrix}
     \mapsto
     \begin{bmatrix}
       |\alpha|^2 & 0
     \\0 & |\beta|^2
     \end{bmatrix}
   \]
  For \(\epsilon = \alpha\beta^\star\) we have a pure quantum state (``full interference capability'') and for \(\epsilon=0\) we have a classical probability distribution over the standard basis (``no interference capability'').
\item
  Suppose it is equally likely that your qubit was prepared either in state \(\alpha|0\rangle + \beta|1\rangle\) or in state \(\alpha|0\rangle - \beta|1\rangle\).
  This means that your qubit is in a mixed state described by the density matrix
  \[
     \frac12
     \begin{bmatrix}
       |\alpha|^2 & \alpha\beta^\star
     \\\alpha^\star\beta & |\beta|^2
     \end{bmatrix}
     +
     \frac12
     \begin{bmatrix}
       |\alpha|^2 & -\alpha\beta^\star
     \\-\alpha^\star\beta & |\beta|^2
     \end{bmatrix}
     =
     \begin{bmatrix}
       |\alpha|^2 & 0
     \\0 & |\beta|^2
     \end{bmatrix}.
   \]
  You cannot tell the difference between the equally weighted mixture of \(\alpha|0\rangle\pm\beta|1\rangle\) and a mixture of \(|0\rangle\) and \(|1\rangle\) with (respective) probabilities \(|\alpha|^2\) and \(|\beta|^2\).
\item
  For any density matrix \(\rho\), the most natural mixture that yields \(\rho\) is its spectral decomposition: \(\rho=\sum_i p_i|u_i\rangle\langle u_i|\), with eigenvectors \(|u_i\rangle\) and eigenvalues \(p_i\).
\item
  If the states \(|u_1\rangle,\ldots,|u_m\rangle\) form an orthonormal basis, and each occurs with equal probability \(1/m\), then the resulting density matrix is proportional to the identity:
  \[
     \frac{1}{m}\sum_{i=1}^m |\psi_i\rangle\langle\psi_i|
     = \frac{1}{m}\mathbf{1}.
   \]
  This is called the \textbf{maximally mixed state}.
  For qubits, any pair of orthogonal states taken with equal probabilities gives the maximally mixed state \(\frac12\mathbf{1}\).
  In maximally mixed states, outcomes of \emph{any} measurement are completely random.
\item
  It is often convenient to write density operators in terms of projectors on states which are not normalised, incorporating the probabilities into the length of the state vector:
  \[
     \rho = \sum_i|\widetilde\psi_i\rangle\langle\widetilde\psi_i|
   \]
  where \(|\widetilde\psi_i\rangle = \sqrt{p_i}|\psi_i\rangle\), i.e.~\(p_i=\langle\widetilde\psi_i|\widetilde\psi_i\rangle\).
  This form is more compact, but you have to remember that the state vectors are \emph{not} normalised.
  We tend to mark such states with the tilde, e.g.~\(|\widetilde\psi\rangle\), but you may have your own way to remember.
\end{enumerate}

\hypertarget{the-bloch-ball}{%
\subsection{The Bloch ball}\label{the-bloch-ball}}

We have already talked in some depth about the Bloch sphere in \protect\hypertarget{qubits}{}{Chapter 2} and \protect\hypertarget{quantum-gates}{}{Chapter 3}, but now that we are considering density operators (which are strictly more general than state vectors), we are actually interested in the Bloch \emph{ball}, i.e.~not just the sphere of vectors of magnitude \(1\), but instead the ball of vectors of magnitude \emph{less than or equal to} \(1\).

The most general Hermitian \((2\times 2)\) matrix has four real parameters and can be expanded in the basis composed of the identity and the three Pauli matrices: \(\{\mathbf{1}, \sigma_x, \sigma_y, \sigma_z\}\).
Since the Pauli matrices are traceless, the coefficient of \(\mathbf{1}\) in the expansion of a density matrix \(\rho\) must be \(\frac12\), so that \(\operatorname{tr}\rho=1\).
Thus \(\rho\) may be expressed as\footnote{Physicists usually still refer to the Bloch \emph{ball} as the Bloch \emph{sphere}, even though it really is a ball now, not a sphere.}
\[
  \begin{aligned}
    \rho
    &= \frac12\left( \mathbf{1}+\vec{s}\cdot\vec{\sigma} \right)
  \\&= \frac12\left( \mathbf{1}+ s_x\sigma_x + s_y\sigma_y + s_z\sigma_z \right)
  \\&= \frac12
    \begin{bmatrix}
      1 + s_z & s_x - is_y
    \\s_x + is_y & 1 - s_z
    \end{bmatrix}.
  \end{aligned}
\]
The vector \(\vec{s}\) is called the \textbf{Bloch vector} for the density operator \(\rho\).
Any real Bloch vector \(\vec{s}\) defines a trace one Hermitian operator \(\rho\), but in order for \(\rho\) to be a density operator it must also be non-negative.
Which Bloch vectors yield legitimate density operators?

Let us compute the eigenvalues of \(\rho\).
The sum of the two eigenvalues of \(\rho\) is, of course, equal to one (\(\operatorname{tr}\rho=1\)) and the product is equal to the determinant of \(\rho\), which can be computed from the matrix form above:
\[
  \det\rho
  = \frac{1}{4}(1-s^2)
  = \frac12(1+s)\frac12(1-s)
\]
where \(s=|\vec{s}|\).
It follows that the two eigenvalues of \(\rho\) are \(\frac12(1\pm s)\).
They have to be non-negative, and so \(s\), the length of the Bloch vector, cannot exceed one.\footnote{One might hope that there is an equally nice visualisation of the density operators in higher dimensions. Unfortunately there isn't.}
We can now visualise the convex set of \((2\times 2)\) density matrices as a unit ball in three-dimensional Euclidean space: the extremal points, which represent pure states, are the points on the boundary (\(s=1\)), i.e.~the surface of the ball; the maximally mixed state \(\mathbf{1}/2\) corresponds to \(s=0\), i.e.~the centre of the ball.
In general, the length of the Bloch vector \(s\) can be thought of as a ``purity'' of a state.

\hypertarget{subsystems-of-entangled-systems}{%
\subsection{Subsystems of entangled systems}\label{subsystems-of-entangled-systems}}

We have already trumpeted that one of the most important features of the density operator formalism is its ability to describe the quantum state of a subsystem of a composite system.
Let me now show you how it works.

Given a quantum state of the composite system \(\mathcal{AB}\), described by some density operator \(\rho^{\mathcal{AB}}\), we obtain reduced density operators \(\rho^{\mathcal{A}}\) and \(\rho^{\mathcal{B}}\) of subsystems \(\mathcal{A}\) and \(\mathcal{B}\), respectively, by the partial trace:
\[
  \begin{aligned}
    \rho^{\mathcal{AB}}
    &\longmapsto
    \underbrace{\rho^\mathcal{A}=\operatorname{tr}_{\mathcal{B}}\rho^{\mathcal{AB}}}_{\mathrm{partial\,trace\,over}\,\mathcal{B}}\qquad
  \\\rho^{\mathcal{AB}}
    &\longmapsto
    \underbrace{\rho^\mathcal{B}=\operatorname{tr}_{\mathcal{A}}\rho^{\mathcal{AB}}}_{\mathrm{partial\,trace\,over}\,\mathcal{A}}
  \end{aligned}
\]
We define the partial trace over \(\mathcal{B}\), or \(\mathcal{A}\), first on a tensor product of two operators \(A\otimes B\) as
\[
  \begin{aligned}
    \operatorname{tr}_{\mathcal{B}} (A\otimes B)
    &= A(\operatorname{tr}B)
  \\\operatorname{tr}_{\mathcal{A}} (A\otimes B)
    &= (\operatorname{tr}A) B,
  \end{aligned}
\]
and then extend to any operator on \(\mathcal{H}_{\mathcal{A}}\otimes\mathcal{H}_{\mathcal{B}}\) by linearity.

Here is a simple example.
Suppose a composite system \(\mathcal{AB}\) is in a pure entangled state, which we can always write as
\[
  |\psi_{\mathcal{AB}}\rangle
  = \sum_{i} c_{i} |a_i\rangle\otimes|b_i\rangle,
\]
where \(|a_i\rangle\) and \(|b_j\rangle\) are two orthonormal bases (e.g.~the Schmidt bases), and where \(\sum_i |c_i|^2 = 1\) (due to the normalisation).
The corresponding density operator of the composite system is the projector \(\rho^{\mathcal{AB}}= |\psi_{\mathcal{AB}}\rangle\langle\psi_{\mathcal{AB}}|\), which we can write as
\[
  \rho^{\mathcal{AB}}
  = |\psi_{\mathcal{AB}}\rangle\langle\psi_{\mathcal{AB}}|
  = \sum_{ij} c_i c^\star_j |a_i\rangle\langle a_j| \otimes |b_i\rangle\langle b_j|
\]
Let us compute the reduced density operator \(\rho^{\mathcal{A}}\) by taking the partial trace over \(\mathcal{B}\):
\[
  \begin{aligned}
    \rho^\mathcal{A}
    &= \operatorname{tr}_{\mathcal{B}}\rho^{\mathcal{AB}}
  \\&= \operatorname{tr}_{\mathcal{B}} |\psi_{\mathcal{AB}}\rangle\langle\psi_{\mathcal{AB}}|
  \\&= \operatorname{tr}_{\mathcal{B}} \sum_{ij} c_i c^\star_j |a_i\rangle\langle a_j| \otimes |b_i\rangle\langle b_j|
  \\&= \sum_{ij} c_i c^\star_j |a_i\rangle\langle a_j|(\operatorname{tr}|b_i\rangle\langle b_j|)
  \\&= \sum_{ij} c_i c^\star_j |a_i\rangle\langle a_j| \underbrace{\langle b_i|b_j\rangle}_{\delta_{ij}}
  \\& = \sum_{i} |c_i|^2 |a_i\rangle\langle a_i|
  \end{aligned}
\]
where we have used the fact that \(\operatorname{tr}|b_i\rangle\langle b_j| = \langle b_j|b_i\rangle=\delta_{ij}\).
In the \(|a_i\rangle\) basis, the reduced density matrix \(\rho^{\mathcal{A}}\) is diagonal, with entries \(p_i=|c_i|^2\).
We can also take the partial trace over \(\mathcal{A}\) and obtain \(\rho^\mathcal{B} = \sum_{i} |c_i|^2 |b_i\rangle\langle b_i|\).
In particular, for the maximally entangled states in the \((d\times d)\)-dimensional Hilbert spaces \(\mathcal{H}_{\mathcal{A}}\otimes\mathcal{H}_{\mathcal{B}}\),
\[
  |\psi_{\mathcal{AB}}\rangle
  = \frac{1}{\sqrt{d}} \sum_{i}^d |a_i\rangle|b_i\rangle,
\]
and the reduced density operators, \(\rho^\mathcal{A}\) and \(\rho^\mathcal{B}\), are the maximally mixed states: \(\rho^\mathcal{A}=\rho^\mathcal{B}=\frac{1}{d}\mathbf{1}\).
It follows that the quantum states of individual qubits in any of the Bell states are maximally mixed: their density matrix is \(\frac12\mathbf{1}\).
A state such as
\[
  \frac{1}{\sqrt 2} \left( |00\rangle + |11\rangle \right)
\]
guarantees perfect correlations when each qubit is measured in the standard basis: the two equally likely outcomes are (\(0\) and \(0\)) or (\(1\) and \(1\)), but any single qubit outcome, be it \(0\) or \(1\) or anything else, is completely random.

\hypertarget{partial-trace-revisited}{%
\subsection{Partial trace, revisited}\label{partial-trace-revisited}}

If you are given a matrix you calculate the trace by summing its diagonal entries.
How about the partial trace?
Suppose someone writes down for you a density matrix of two qubits in the standard basis, \(\{|00\rangle, |01\rangle, |10\rangle, |11\rangle\}\), and asks you to find the reduced density matrices of the individual qubits.
The tensor product structure of this \((4\times 4)\) matrix means that it is has a block form:
\[
  \rho^{\mathcal{AB}}
  =
  \left[
    \begin{array}{c|c}
      P & Q
    \\\hline
      R & S
    \end{array}
  \right]
\]
where \(P,Q,R,S\) are \((2\times 2)\) sized sub-matrices.
The two partial traces can then be evaluated as\footnote{Take any of the Bell states, write its \((4\times 4)\)-density matrix explicitly, and then trace over each qubit. In each case you should get the maximally mixed state.}
\[
  \begin{aligned}
    \rho^\mathcal{A}
    &=
    \operatorname{tr}_{B}\rho^{\mathcal{AB}}
    =
    \left[
      \begin{array}{c|c}
        \operatorname{tr}P & \operatorname{tr}Q
      \\\hline
        \operatorname{tr}R & \operatorname{tr}S
      \end{array}
    \right]
  \\\rho^\mathcal{B}
    &= \operatorname{tr}_{A}\rho^{\mathcal{AB}}
    = P+S.
  \end{aligned}
\]
The same holds for a general \(\rho^{\mathcal{AB}}\) on any \(\mathcal{H}_{\mathcal{A}}\otimes\mathcal{H}_{\mathcal{B}}\) with corresponding block form (\((m\times m)\) blocks of \((n\times n)\)-sized sub-matrices, where \(m\) and \(n\) are the dimensions of \(\mathcal{H}_{\mathcal{A}}\) and \(\mathcal{H}_{\mathcal{B}}\), respectively).

\hypertarget{mixtures-and-subsystems}{%
\subsection{Mixtures and subsystems}\label{mixtures-and-subsystems}}

We have used the density operators to describe two distinct situations: the statistical properties of the mixtures of states, and the statistical properties of subsystems of composite systems.
In order to see the relationship between the two, consider a joint state of a bipartite system \(\mathcal{AB}\), written in a product basis in \(\mathcal{H}_{\mathcal{A}}\otimes\mathcal{H}_{\mathcal{B}}\) as
\[
  \begin{aligned}
    |\psi_{\mathcal{AB}}\rangle
    &= \sum_{ij} c_{ij}|a_i\rangle\otimes|b_j\rangle
  \\&= \sum_{j=1} |\widetilde\psi_j\rangle|b_j\rangle
  \\&= \sum_{j=1} \sqrt{p_j}|\psi_j\rangle|b_j\rangle
  \end{aligned}
\tag{9.7.1}
\]
where \(|\widetilde\psi_j\rangle = \sum_i c_{ij}|a_i\rangle = \sqrt{p_j}|\psi_j\rangle\), and the vectors \(|\psi_j\rangle\) are the normalised versions of the \(|\widetilde\psi_j\rangle\).
Note that \(p_j=\langle\widetilde\psi_j|\widetilde\psi_j\rangle\).

Then the partial trace over \(\mathcal{B}\) gives the reduced density operator of subsystem \(\mathcal{A}\):
\[
  \begin{aligned}
    \rho^{\mathcal{A}}
    &=\operatorname{tr}_{\mathcal{B}} \sum_{ij} |\widetilde\psi_i\rangle\langle\widetilde\psi_j| \otimes |b_i\rangle\langle b_j|
  \\&= \sum_{ij} |\widetilde\psi_i\rangle\langle\widetilde\psi_j| (\operatorname{tr}|b_i\rangle\langle b_j|)
  \\&= \sum_{ij} |\widetilde\psi_i\rangle\langle\widetilde\psi_j| \langle b_j|b_i\rangle
  \\&= \sum_{i} |\widetilde\psi_i\rangle\langle\widetilde\psi_i|
    = \sum_{i} p_i |\psi_i\rangle\langle\psi_i|.
  \end{aligned}
\]

Now, let us see how \(\rho^{\mathcal{A}}\) can be understood in terms of mixtures.
Let us place subsystems \(\mathcal{A}\) and \(\mathcal{B}\) in separate labs, run by Alice and Bob, respectively.
When Bob measures part \(\mathcal{B}\) in the \(|b_j\rangle\) basis and obtains result \(k\), which happens with the probability \(p_k\), he prepares subsystem \(\mathcal{A}\) in the state \(|\psi_k\rangle\):
\[
  \sum_{i=1} \sqrt{p_j}|\psi_i\rangle|b_i\rangle
  \overset{\mathrm{outcome}\,k}{\longmapsto}
  |\psi_k\rangle|b_k\rangle.
\]
Bob does not communicate the outcome of his measurement.
Thus, from Alice's perspective, Bob prepares a mixture of \(|\psi_1\rangle,\ldots,|\psi_m\rangle\), with probabilities \(p_1,\ldots,p_m\), which means that Alice, who knows the joint state but not the outcomes of Bob's measurement, may associate density matrix \(\rho^\mathcal{A}=\sum_i p_i|\psi_i\rangle\langle\psi_i|\) with her subsystem \(\mathcal{A}\).
This is the same \(\rho^{\mathcal{A}}\) which we obtained by the partial trace.

But suppose Bob chooses to measure his subsystem in some other basis.
Will it have any impact on Alice's statistical predictions?
Measurement in the new basis will result in a different mixture, but Alice's density operator will not change.
Suppose Bob chooses basis \(|d_i\rangle\) for his measurement.
Any two orthonormal bases are connected by some unitary transformation, and so we can write \(|b_i\rangle = U|d_i\rangle\) for some unitary \(U\).
In terms of components, \(|b_i\rangle = \sum_j U_{ij}|d_j\rangle\).
The joint state can now be expressed as
\[
  \begin{aligned}
    |\psi_{\mathcal{AB}}\rangle
    &= \sum_{i} |\widetilde\psi_i\rangle|b_i\rangle
  \\&= \sum_{i} |\widetilde\psi_i\rangle \left( \sum_j U_{ij}|d_j\rangle \right)
  \\&= \sum_j \underbrace{\left( \sum_i U_{ij}|\widetilde\psi_i\rangle \right)}_{|\widetilde\phi_j\rangle}|d_j\rangle
  \\&= \sum_j|\widetilde\phi_j\rangle|d_j\rangle.
  \end{aligned}
\]

If Bob measures in the \(|d_i\rangle\) basis then he generates a new mixture of states \(|\phi_1\rangle,\ldots|\phi_m\rangle\), which are the normalised versions of \(|\widetilde\phi_1\rangle,\ldots|\widetilde\phi_m\rangle\), with each \(|\phi_k\rangle\) occurring with probability \(p_k=\langle\widetilde\phi_k|\widetilde\phi_k\rangle\).
But this new mixture has exactly the same density operator as the previous one:\footnote{The \(U_{ij}\) are the components of a unitary matrix, hence \(\sum_k U_{ik}U^\star_{jk}=\delta_{ij}\).}
\[
  \begin{aligned}
    \sum_j|\widetilde\phi_j\rangle\langle\widetilde\phi_j|
    &= \sum_{ijl} U_{ij}|\widetilde\psi_i\rangle\langle\widetilde\psi_l|U^\star_{lj}
  \\&= \sum_{il} \underbrace{\left(\sum_j U_{ij}U^\star_{lj}\right)}_{\delta_{il}}|\widetilde\psi_i\rangle\langle\widetilde\psi_l|
  \\&= \sum_i|\widetilde\psi_j\rangle\langle\widetilde\psi_j|,
  \end{aligned}
\]
which is exactly \(\rho^\mathcal{A}\).
So does it really matter whether Bob performs the measurement or not?

\emph{It does not.}

After all, Alice and Bob may be miles away from each other, and if any of Bob's actions were to result in something that is physically detectable at the Alice's location that would amount to instantaneous communication between the two of them.

From the operational point of view it does not really matter whether the density operator represents our ignorance of the actual state (mixtures) or provides the only description we can have after discarding one part of an entangled state (partial trace).\footnote{The two interpretations of density operators filled volumes of academic papers. The terms \textbf{proper mixtures} and \textbf{improper mixtures} are used, mostly by philosophers, to describe the statistical mixture and the partial trace approach, respectively.}
In the former case, the system is in some definite pure state but we do not know which.
In contrast, when the density operator arises from tracing out irrelevant, or unavailable, degrees of freedom, the individual system cannot be thought to be in some definite state of which we are ignorant.
Philosophy aside, the fact that the two interpretations give exactly the same predictions is useful: switching back and forth between the two pictures often offers additional insights and may even simplify lengthy calculations.

\hypertarget{partial-trace-yet-again}{%
\subsection{Partial trace, yet again}\label{partial-trace-yet-again}}

The partial trace is the only map \(\rho^{\mathcal{AB}}\mapsto\rho^{\mathcal{A}}\) such that\footnote{One can repeat the same argument for \(\rho^{\mathcal{AB}}\mapsto\rho^{\mathcal{B}}\): the partial trace is the unique map \(\rho^{\mathcal{AB}}\mapsto\rho^{\mathcal{B}}\) such that \(\rho^{\mathcal{B}}\) satisfies \(\operatorname{tr}[Y\rho^{\mathcal{B}}] = \operatorname{tr}[(1\otimes Y)\rho^{\mathcal{AB}}]\) for any observable \(Y\) on \(\mathcal{B}\).}
\[
  \operatorname{tr}[X\rho^{\mathcal{A}}] = \operatorname{tr}[(X\otimes\mathbf{1})\rho^{\mathcal{AB}}]
\]
holds for any observable \(X\) acting on \(\mathcal{A}\).
This condition concerns the consistency of statistical predictions.
Any observable \(X\) on \(\mathcal{A}\) can be viewed as an observable \(X\otimes\mathbf{1}\) on the composite system \(\mathcal{AB}\), where \(\mathbf{1}\) is the identity operator acting on \(\mathcal{B}\).
When constructing \(\rho^{\mathcal{A}}\) we had better make sure that for any observable \(X\) the average value of \(X\) in the state \(\rho^\mathcal{A}\) is the same as the average value of \(X\otimes\mathbf{1}\) in the state \(\rho^{\mathcal{AB}}\).
This is indeed the case for the partial trace.

For example, let us go back to the state in Equation (9.7.1) and assume that Alice measures some observable \(X\) on her part of the system.
Technically, such an observable can be expressed as \(X\otimes \mathbf{1}\), where \(\mathbf{1}\) is the identity operator acting on the subsystem \(\mathcal{B}\).
The expected value of this observable in the state \(|\psi_{\mathcal{AB}}\rangle\) is \(\operatorname{tr}(X\otimes\mathbf{1})|\psi_{\mathcal{AB}}\rangle\langle\psi_{\mathcal{AB}}|\), i.e.
\[
  \begin{aligned}
    \operatorname{tr}[(X\otimes \mathbf{1}) \rho^{\mathcal{AB}}]
    &= \operatorname{tr}\left[
        (X\otimes\mathbf{1}) \left(
          \sum_{ij} |\widetilde\psi_i\rangle\langle\widetilde\psi_j| \otimes |b_i\rangle\langle b_j|
        \right)
      \right]
  \\&= \sum_{ij} \left[
        \operatorname{tr}\left(X |\widetilde\psi_i\rangle\langle\widetilde\psi_j|\right)
      \right]
      \underbrace{\left[\operatorname{tr}\left(|b_i\rangle\langle b_j|\right)\right]}_{\delta_{ij}}
  \\&= \sum_i \operatorname{tr}\big[X |\widetilde\psi_i\rangle\langle\widetilde\psi_i|\big]
  \\&= \operatorname{tr}\left[
      X \underbrace{\sum_i p_i|\psi_i\rangle\langle\psi_i|}_{\rho^{\mathcal{A}} = \operatorname{tr}_{\mathcal{B}}\rho^{\mathcal{AB}}}
    \right]
  \\&= \operatorname{tr}[X\rho^{\mathcal{A}}]
  \end{aligned}
\]
as required.

\textbf{!!!TO-DO!!! The uniqueness of the partial trace, for now see Nielsen \& Chuang Box 2.6.}

\hypertarget{remarks-and-exercises-6}{%
\subsection{\texorpdfstring{\emph{Remarks and exercises}}{Remarks and exercises}}\label{remarks-and-exercises-6}}

\hypertarget{exercise31}{%
\subsubsection{Some density operator calculations}\label{exercise31}}

Consider two qubits in the state
\[
  |\psi\rangle =
  \frac{1}{\sqrt2}\left(
    |0\rangle\otimes\left(
      \sqrt{\frac23}|0\rangle
      - \sqrt{\frac13}|1\rangle
    \right)
    + |1\rangle\otimes\left(
      \sqrt{\frac23}|0\rangle
      + \sqrt{\frac13}|1\rangle
    \right)
  \right).
\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  What is the density operator \(\rho\) of the two qubits corresponding to the state \(|\psi\rangle\)?
  Write it in both Dirac notation and explicitly as a matrix in the computational basis \(\{|00\rangle,|01\rangle,|10\rangle,|11\rangle\}\).
\item
  Find the reduced density operators \(\rho_1\) and \(\rho_2\) of the first and second qubit (respectively).
  Again, write them in both Dirac notation and explicitly as a matrix in the computational basis.
\end{enumerate}

\hypertarget{purification-of-mixed-states}{%
\subsubsection{Purification of mixed states}\label{purification-of-mixed-states}}

Given a mixed state \(\rho\), a \textbf{purification} of \(\rho\) is a pure state \(|\psi\rangle\langle\psi|\) of some potentially larger system such that \(\rho\) is equal to a partial trace of \(|\psi\rangle\langle\psi|\).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Show that an arbitrary mixed state \(\rho\) always has a purification.
\item
  Show that purification is unique up to unitary equivalence.
\item
  Let \(|\psi_1\rangle\) and \(|\psi_2\rangle\) in \(\mathcal{H}_{\mathcal{A}}\otimes\mathcal{H}_{\mathcal{B}}\) be two pure states such that \(\operatorname{tr}_{\mathcal{B}}|\psi_1\rangle\langle\psi_1| = \operatorname{tr}_{\mathcal{B}}|\psi_2\rangle\langle\psi_2|\).
  Show that \(|\psi_1\rangle = \mathbf{1}\otimes U|\psi_2\rangle\) for some unitary operator \(U\) on \(\mathcal{H}_{\mathcal{B}}\).
\end{enumerate}

\hypertarget{pure-partial-trace}{%
\subsubsection{Pure partial trace}\label{pure-partial-trace}}

Two qubits are in the state described by the density operator \(\rho = \rho^\mathcal{A}\otimes\rho^\mathcal{B}\).
What is the partial trace of \(\rho\) over each qubit?

\hypertarget{maximally-bell}{%
\subsubsection{Maximally Bell}\label{maximally-bell}}

Write the density matrix of two qubits corresponding to the mixture of the Bell state \(\frac{1}{\sqrt 2}\left(|00\rangle + |11\rangle\right)\) with probability \(\frac12\) and the maximally mixed state of two qubits (which is a \((4\times 4)\) matrix in \(\mathcal{H}_{\mathcal{A}}\otimes\mathcal{H}_{\mathcal{B}}\)) with probability \(\frac12\).

\hypertarget{trace-norm}{%
\subsubsection{Trace norm}\label{trace-norm}}

The \textbf{trace norm} of a matrix \(A\) is defined as
\[
  \|A\|_{\operatorname{tr}} = \operatorname{tr}\left(\sqrt{A^\dagger A}\right).
\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Show that, if \(A\) is self-adjoint, then its trace norm is equal to the sum of the absolute values of its eigenvalues.
\item
  What is the trace norm of an arbitrary density matrix?
\end{enumerate}

The distance induced by the trace norm is called the \textbf{trace distance}, defined as
\[
  d_{\operatorname{tr}}(\rho_1,\rho_2) = \frac12\|\rho_2-\rho_1\|_{\operatorname{tr}}.
\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  What is the trace distance between two arbitrary pure states?
\end{enumerate}

\hypertarget{distinguishability-and-the-trace-distance}{%
\subsubsection{Distinguishability and the trace distance}\label{distinguishability-and-the-trace-distance}}

Say we have a physical system which is been prepared in one of two states (say, \(\rho_1\) and \(\rho_2\)), each with equal probability.
Then a single measurement can distinguish between the two preparations with probability at most
\[
  \frac12\big(1+d_{\operatorname{tr}}(\rho_1,\rho_2)\big).
\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Suppose that \(\rho_1\) and \(\rho_2\) commute.\footnote{The commutativity assumption makes this problem essentially a special case of a purely classical one: distinguishing between two probability distributions.}
  Using the spectral decompositions of \(\rho_1\) and \(\rho_2\) in their common eigenbasis, describe the optimal measurement that can distinguish between the two states. What is its probability of success?
\item
  Suppose that you are given one of the two, randomly selected, qubits of the state
  \[
     |\psi\rangle =
     \frac{1}{\sqrt2}\left(
       |0\rangle\otimes\left(
         \sqrt{\frac23}|0\rangle
         - \sqrt{\frac13}|1\rangle
       \right)
       + |1\rangle\otimes\left(
         \sqrt{\frac23}|0\rangle
         + \sqrt{\frac13}|1\rangle
       \right)
     \right)
   \]
  from \protect\hyperlink{exercise31}{above}.
  What is the maximal probability with which you can determine whether it is the first or second qubit?
\end{enumerate}

\hypertarget{spectral-decompositions-and-common-eigenbases}{%
\subsubsection{Spectral decompositions and common eigenbases}\label{spectral-decompositions-and-common-eigenbases}}

\textbf{!!!TO-DO!!!}

\hypertarget{quantum-channels}{%
\section{Quantum channels}\label{quantum-channels}}

\begin{quote}
Quantum evolution of any \emph{isolated} system is unitary but its constituent parts may evolve in a more complicated way. In this chapter we will go beyond unitary evolutions and describe physically realisable transformations of density operators, called quantum channels. Be prepared for some name dropping; you will hear about Karl Kraus, Woody Stinespring, Andrzej Jamiołkowski and Man-Duen Choi. To be sure, knowing names will not give you more insights, but at least you will not be intimidated when you hear about the \textbf{Stinespring} and the \textbf{Kraus representations}, the \textbf{Jamiołkowski isomorphism}, or the \textbf{Choi matrix}.
\end{quote}

We discussed how entanglement forced us to describe quantum states of open quantum systems (ones which are part of a larger system) in terms of density operators.
In this chapter we will describe how open systems evolve.
The question we are asking here is: what are the most general physically admissible transformations of density operators?
At the fundamental level --- and this should be your quantum mantra\footnote{\ldots there is only one unitary evolution, there is only one unitary evolution, there only one unitary evolution\ldots{} \ldots and everything else is cheating} --- there is \emph{only one} unitary evolution, and if there is any other evolution then it has to be derived from a unitary evolution.
From this perspective, any non-unitary evolution of an open system is induced by a unitary evolution of a larger system.
But how?
The short answer is: by adding (tensoring) and removing (partial trace) physical systems.
A typical combination of these operations is shown in the following diagram:

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-52-1} \end{center}

First, we prepare our system of interest in an input state \(\rho\).
Then we dilate the system by ``adding'' (or ``taking into account'') an auxiliary system\footnote{Depending on the context, the auxiliary system is either called the \textbf{ancilla} (usually when we can control it) or the \textbf{environment} (usually when we cannot control it).} which is large enough to include everything our system will interact with, and also large enough to be in a pure state \(|a\rangle\).
Mathematically, we do this by tensoring the input state \(\rho\) with \(|a\rangle\langle a|\) to obtain \(|a\rangle\langle a|\otimes\rho\) (here we place the auxiliary system first and our system of interest second).
The dilated system is assumed to be closed so that it undergoes some unitary evolution \(U\).
After all the interactions have taken place, we \emph{trace out} the auxiliary system, turning the joint state \(U|a\rangle\langle a|\otimes\rho U^\dagger\) of the dilated system into the final state of our system of interest: the output state \(\rho'\).
The net effect of this composition, as we shall see in a moment, is the input-output transformation which can be written, as long as the initial state of the auxiliary system in \emph{not} correlated with the input state, in a nice compact way:
\[
  \rho\longmapsto\rho' = \sum_i E_i\rho E_i^\dagger
\]
where the \(E_i\) are some operators that satisfy \(\sum_i E_i^\dagger E_i=\mathbf{1}\).
This linear map is called a \textbf{completely positive trace-preserving map}, or, in the parlance of quantum information science, a \textbf{quantum channel}.
We will elaborate on the mathematics behind quantum channels shortly, but for now let us only check the essential properties, i.e.~that this map preserves both trace and positivity (as its name suggests).

\begin{itemize}
\tightlist
\item
  Trace preserving: since the trace is linear, invariant under cyclic permutations of operators, and we ask that \(\sum_i E_i^\dagger E_i=\mathbf{1}\), we see that
  \[
      \operatorname{tr}\left(\sum_k E_k\rho E_k^\dagger\right)
      = \operatorname{tr}\left(\sum_k E^\dagger_k E_k \rho\right)
      = \operatorname{tr}\rho.
    \]
\item
  Positivity preserving: since \(\rho\) is a positive\footnote{Recall that an operator is positive if and only if it can be written in the form \(XX^\dagger\) for some \(X\) (here \(X=E_k\sqrt{\rho}\)). Also, the sum of positive operators is again a positive operator.} (semi-definite) operator, and so is \(\sqrt{\rho}\), we see that
  \[
      \sum_k E_k\rho E_k^\dagger
      = \sum_k (E_k\sqrt{\rho})(\sqrt{\rho} E_k^\dagger).
    \]
\end{itemize}

These conditions are certainly \emph{necessary} if we want to map density operators into legal density operators, but we shall see in a moment that they are not \emph{sufficient}: quantum channels are not just positive maps, they are \textbf{completely} positive maps.
We will discuss their special properties, describe the most common examples, and, last but not least, specify when the action of quantum channels can be reversed, or corrected, so that we can recover the original input state.
This will set the stage for our subsequent discussion of quantum error correction.

\hypertarget{random-unitaries}{%
\subsection{Random unitaries}\label{random-unitaries}}

As a first step toward understanding the quantum description of an evolving open system, consider a ``two-qubit universe'' in which we observe \emph{only one} of the qubits.
Let us revisit the controlled-\(\texttt{NOT}\) gate, in which two qubits undergo the unitary transformation
\[
  U
  = |0\rangle\langle 0|\otimes\mathbf{1}+|1\rangle\langle 1|\otimes X
  = \begin{bmatrix}\mathbf{1}&0\\0&X\end{bmatrix}
\]
and let us focus on the transformation of the target qubit alone.
We know that it depends on the state of the control qubit:

\begin{itemize}
\tightlist
\item
  if the input state of the control qubit is \(|0\rangle\), the target qubit evolves unitarily according to the identity operator \(\mathbf{1}\);
\item
  if the input state of the control qubit is \(|1\rangle\), the target qubit evolves unitarily according to the bit flip operator \(X\);
\item
  but for input states of the control that are superpositions of \(|0\rangle\) and \(|1\rangle\) the evolution of the target qubit is \emph{not} unitary.
\end{itemize}

To justify this last point, note that, if the control qubit is in the state \(\alpha_0|0\rangle+\alpha_1|1\rangle\) and the target qubit is in some state \(|\psi\rangle\), then the output state can be written as
\[
  \alpha_0|0\rangle\otimes\mathbf{1}|\psi\rangle + \alpha_1|1\rangle\otimes X|\psi\rangle
\]
which shows that the control and the target become entangled.
The target qubit alone ends up in the statistical mixture of states \(|\psi\rangle\) (with probability \(|\alpha_0|^2\)) and \(X|\psi\rangle\) (with probability \(|\alpha_1|^2\)).
This can be easily verified by expressing the above output state of the two qubits as the density matrix
\[
  \begin{aligned}
    |\alpha_0|^2|0\rangle\langle 0|\otimes \mathbf{1}|\psi\rangle\langle\psi|\mathbf{1}
    \quad &+\quad |\alpha_1|^2|1\rangle\langle 1|\otimes X|\psi\rangle\langle\psi|X
  \\+\, \alpha_0\alpha_1^\star|0\rangle\langle 1| \otimes \mathbf{1}|\psi\rangle\langle\psi|X
    \quad &+\quad \alpha_0^\star\alpha_1|1\rangle\langle 0| \otimes X|\psi\rangle\langle\psi|\mathbf{1}
  \end{aligned}
\]
and then tracing over the control qubit, which gives\footnote{Recall that, for the basis states, \(\operatorname{tr}|i\rangle\langle j|=\langle i|j\rangle=\delta_{ij}\).}
\[
  |\alpha_0|^2 \mathbf{1}|\psi\rangle\langle\psi|\mathbf{1}
  + |\alpha_1|^2 X|\psi\rangle\langle\psi| X.
\]
We can then say that the input state of the target qubit evolves either according to the identity operator (with probability \(|\alpha_0|^2\)) or according to the operator \(X\) (with probability \(|\alpha_1|^2\)).

This argument works even if the target qubit is initially in a mixed state, since we are dealing with a linear transformation, and any mixed state can be expressed as a statistical ensemble of pure states (via the convex decomposition of a density matrix).
Thus, in general, we can express the evolution of the target qubit\footnote{We can also focus on the evolution of the control qubit: see \protect\hyperlink{control-controlled-NOT}{the examples and exercises section}. In fact, we can choose any subset of qubits for our inputs and outputs. For example, our input could be the control qubit, and the output could be \emph{both} the control \emph{and} the target qubits.} as

\[
  \rho\longmapsto
  \rho'= |\alpha_0|^2 \mathbf{1}\rho\mathbf{1}+ |\alpha_1|^2 X\rho X
\]
where \(\rho\) and \(\rho'\) are the input and the output states, respectively.
We may think about this input-output relation as a mathematical representation of a quantum communication channel in which an input qubit is bit-flipped (via the operator \(X\)) with some prescribed probability.
But we may also take a more ``global'' view and see the action of the channel as arising from a unitary evolution on a larger (dilated) system, here composed of two qubits.

Our discussion can easily be extended beyond the qubits to cover any conditional dynamics of the type
\[
  U
  = \sum_i |i\rangle\langle i|\otimes U_i
  =
  \begin{bmatrix}
    U_1 & 0 & 0 & \ldots
  \\0 & U_2 & 0 & \ldots
  \\0 & 0 & U_3 & \ldots
  \\\vdots & \vdots &\vdots & \ddots
  \end{bmatrix}
\]
where the vectors \(|i\rangle\) form an orthonormal basis in the Hilbert space associated with a control system, and the \(U_i\) are the corresponding unitary operations performed on a target system.
If the control system is prepared in state \(\sum_i\alpha_i|i\rangle\) and the target in state \(|\psi\rangle\), then the final state of the two systems is
\[
  \sum_i \alpha_i|i\rangle\otimes U_i|\psi\rangle
\]
and, by the same sequence of arguments as before, we obtain the evolution of the target system alone, and express it as
\[
  \rho\longmapsto
  \rho' = \sum_{i=1} p_i U_i \rho U^\dagger_i
\]
where \(p_i=|\alpha_i|^2\).
That is, the state of the target system is modified by the unitary \(U_i\), chosen randomly with probability \(p_i\).

The reason we are paying particular attention to the random unitaries is that each unitary is invertible, and, as such, they offer a sliver of hope for reversing the action of the channel.
If we can learn, post factum, which particular unitary operation \(U_i\) was chosen then we can simply apply the inverse of that unitary and recover the original state.
For example, if we can measure the control system in the \(|i\rangle\) basis, then measuring the outcome to be \(k\) tells us that we have to apply \(U_k^\dagger\) to the target to recover its input state.
However, if we do not have access to the control system, then there is very little we can do: \emph{we cannot figure out which particular unitary was applied by inspecting the target system alone}.
In this case the best we can do is to apply the inverse of the most likely unitary, which will then recover the input state, \emph{but only with some probability of success}.
In order to do better than that we have to look at slightly different channels.

First though, a fundamental example of a random unitary evolution: a \textbf{single qubit Pauli channel} applies one of the Pauli operators, \(X\), \(Y\) or \(Z\), chosen randomly with some prescribed probabilities \(p_x\), \(p_y\) and \(p_z\), giving
\[
  \rho\longmapsto
  p_0 \mathbf{1}\rho\mathbf{1}+ p_x X\rho X+ p_y Y\rho Y+  p_z Z\rho Z.
\]
The Pauli operators represent \textbf{quantum errors}: bit-flip \(X\), phase-flip \(Z\), and the composition of the two \(Y=iXZ\).

\hypertarget{random-isometries}{%
\subsection{Random isometries}\label{random-isometries}}

There is another invertible operation in quantum theory: an \textbf{isometry}, which is a combination of adding another quantum system and then applying a unitary transformation to the resulting composite system.
So let us take a quick look at a simple generalisation of random unitaries, namely random isometries \(V_i\), which give
\[
  \rho\longmapsto
  \rho' = \sum_{i=1} p_i V_i \rho V^\dagger_i.
\]
An isometry \(V\) is similar to a unitary operator except that it maps states in the Hilbert space \(\mathcal{H}\) to states in a larger Hilbert space \(\mathcal{H}'\) (cf.~\{the appendix on isometries\}(\#isometries)).
Here \(\mathcal{H}\) is associated with the input and \(\mathcal{H}'=\mathcal{H}_\mathcal{A}\otimes\mathcal{H}\) with the dilated system (i.e.~the ancilla \(\mathcal{A}\) plus our system of interest).
Isometries satisfy \(V^\dagger V=\mathbf{1}\), and they are usually implemented by adding an ancilla in a fixed state and then applying a unitary operation to the resulting composed system.
They can be then reversed by applying the inverse of that unitary and discarding the ancilla.

Now, if \(\mathcal{H}'\) is sufficiently larger than \(\mathcal{H}\), and if the images \(\mathcal{H}'_i\) of \(\mathcal{H}\) in \(\mathcal{H}'\) under the different isometries \(V_i\) do not overlap\footnote{That is, if the subspaces \(\mathcal{H}'_i\) are mutually orthogonal.}, then we can reverse the action of the channel:
we can, at least in principle, perform a measurement on \(\mathcal{H}'\), defined by the partition \(\mathcal{H}'=\mathcal{H}'_1\oplus\mathcal{H}'_2\oplus\ldots\), and find out which subspace contains the output state;
once we know which subspace the input was sent to, we know which particular isometry \(V_k\) was applied by the channel;
then we simply apply \(V^\dagger_k\).

In order to see this consider the following simple, but important, example, which we will revisit several times in different disguises.

Alice constructs a quantum channel which is a mixture of four isometries.
The input is a single qubit, and the output is a dilated system composed of three qubits.
She prepares the input qubit in a state\footnote{Our arguments here can be easily extended to any mixed state \(\rho\), but for simplicity we consider the case of a pure state.} \(|\psi\rangle\) and then combines it with the two ancillary qubits which are in a fixed state \(|0\rangle|0\rangle\).
Then she applies one of the four, randomly chosen, unitary operations to the three qubits, to generate the following four isometries:
\[
  \begin{aligned}
    V_1 &= |000\rangle\langle 0| + |111\rangle\langle 1|
  \\V_2 &= |001\rangle\langle 0| + |110\rangle\langle 1|
  \\V_3 &= |010\rangle\langle 0| + |101\rangle\langle 1|
  \\V_4 &= |100\rangle\langle 0| + |011\rangle\langle 1|.
  \end{aligned}
\]

The three qubits, which form the output of the channel, are given to Bob, whose task is to recover the original state \(|\psi\rangle\) of the input qubit.
In this scenario, Bob, who knows the four isometries, can find out which particular isometry was applied.
He knows that\footnote{\textbf{!!!to-do!!! picture}}

\begin{itemize}
\tightlist
\item
  \(V_1\) maps \(\mathcal{H}\) to \(\mathcal{H}'_1\), which is a subspace of \(\mathcal{H}'\) spanned by \(|000\rangle\) and \(|111\rangle\);
\item
  \(V_2\) maps \(\mathcal{H}\) to \(\mathcal{H}'_2\), which is a subspace of \(\mathcal{H}'\) spanned by \(|001\rangle\) and \(|110\rangle\);
\item
  \(V_3\) maps \(\mathcal{H}\) to \(\mathcal{H}'_3\), which is a subspace of \(\mathcal{H}'\) spanned by \(|010\rangle\) and \(|101\rangle\);
\item
  \(V_4\) maps \(\mathcal{H}\) to \(\mathcal{H}'_4\), which is a subspace of \(\mathcal{H}'\) spanned by \(|100\rangle\) and \(|011\rangle\).
\end{itemize}

Given that these subspaces are mutually orthogonal, and \(\mathcal{H}'=\mathcal{H}'_1\oplus\mathcal{H}'_2\oplus\mathcal{H}'_3\oplus\mathcal{H}'_4\), Bob can perform a measurement defined by the projectors on these subspaces.
For example, if Alice randomly picked \(V_2\), then the input state \(|\psi\rangle=\alpha_0|0\rangle+\alpha_1|1\rangle\) will be mapped to the output state \(\alpha_0|001\rangle+\alpha_1|110\rangle\) in the \(\mathcal{H}'_2\) subspace.
Bob's measurement will then detect \(\mathcal{H}'_2\) as the subspace where the output state resides, but the measurement (i.e.~the corresponding projection) will not affect any state in that subspace.
Bob can now simply apply \(V_2^\dagger\) and obtain \(|\psi\rangle\).

Just in case you are curious (as you should be!), below is a diagram of how the four isometries are implemented.
How would you reverse these operations?

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-53-1} \end{center}

Single unitaries or isometries apart, it turns out that the only reversible, or \textbf{correctable}, channels (i.e.~channels in which the input state can be recovered) are exactly the mixtures of mutually orthogonal isometries \(V^\dagger_i V_j=\delta_{ij}\mathbf{1}\).
We shall return to these channels later on.

\hypertarget{evolution-of-open-systems}{%
\subsection{Evolution of open systems}\label{evolution-of-open-systems}}

Needless to say, there is more to evolutions of open systems than random isometries, and what follows is the most general scenario we will discuss.
Consider two interacting systems, \(\mathcal{A}\) and \(\mathcal{B}\), but this time we do \emph{not} assume that their interacting dynamics admits a control-target interpretation.
We will view \(\mathcal{A}\) as an auxiliary system, i.e.~an ancilla, and focus on\footnote{For now, when we write tensor products, we will place the ancilla first and the system of interest second: \(\mathcal{H}_\mathcal{A}\otimes\mathcal{H}_\mathcal{B}\). We do this to begin with simply because block matrices on tensor products are easier to interpret when written in this particular order. Later on we will revert to the more common convention in which the system of interest is placed first.} the evolution of system \(\mathcal{B}\).

Let us pick an orthonormal basis \(|i\rangle\) of the Hilbert space \(\mathcal{H}_\mathcal{A}\) associated with the ancilla.
Any unitary transformation of the combined system \(\mathcal{AB}\) can then be written as
\[
  U
  = \sum_{ij}|i\rangle\langle j|\otimes B_{ij}
  =
  \begin{bmatrix}
    B_{11} & B_{12} & B_{13} & \ldots
  \\B_{21} & B_{22} & B_{23} & \ldots
  \\B_{31} & B_{32} & B_{33} & \ldots
  \\\vdots & \vdots & \vdots & \ddots
  \end{bmatrix}
\]
where the \(B_{ij}\) are operators acting on the the Hilbert space \(\mathcal{H}_\mathcal{B}\) associated with system \(\mathcal{B}\).
Note that the \(B_{ij}\) do \emph{not} need to be unitary, but, for the overall transformation \(U\) to be unitary, they must satisfy
\[
  \begin{aligned}
    \sum_i B_{ik}^\dagger B_{il}
    &= \delta_{kl} \mathbf{1}_\mathcal{AB}
  \\\sum_i B_{ki}B_{li}^\dagger
    &= \delta_{kl} \mathbf{1}_\mathcal{B}
  \end{aligned}
  \tag{$\star$}
\]
where \(\mathbf{1}_\mathcal{AB}\) and \(\mathbf{1}_\mathcal{B}\) are the identity operators on \(\mathcal{H}_\mathcal{A}\otimes\mathcal{H}_\mathcal{B}\) and \(\mathcal{H}_\mathcal{B}\), respectively.
These two conditions correspond to the requirement that both column and row vectors must be orthonormal for a matrix to be unitary, except that here \(U\) is a block matrix, and the entries \(B_{ij}\) are complex matrices rather than complex numbers, so some care must be taken with the order of multiplication.
Again, the evolution of the system \(\mathcal{B}\) depends on both \(U\) \emph{and} on the initial state of the auxiliary system \(\mathcal{A}\).

Without any loss of generality, we may assume that system \(\mathcal{A}\) is in a pure state\footnote{If \(\mathcal{A}\) were initially in a mixed state, we could always regard \(\mathcal{A}\) as a subsystem of some larger \(\widetilde{\mathcal{A}}\) that is in an entangled pure state.} which can be chosen to be one of the basis states \(|i\rangle\), say \(|k\rangle\).
In this case, \(U\) acts by
\[
  U\colon |k\rangle\otimes|\psi\rangle \longmapsto
  \sum_i |i\rangle\otimes B_{ik}|\psi\rangle
\tag{$\ddagger$}
\]
for an arbitrary state \(|\psi\rangle\) of \(\mathcal{B}\).

The resulting density operator for \(\mathcal{B}\) is found by taking the density operator of the output state of \(\mathcal{AB}\), which is
\[
  \sum_{ij} |i\rangle\langle j|\otimes B_{ik}|\psi\rangle\langle\psi|B_{jk}^\dagger
\]
and then tracing out \(\mathcal{A}\), obtaining
\[
  \begin{aligned}
    \operatorname{tr}_\mathcal{A} \left(
      \sum_{ij} |i\rangle\langle j|\otimes B_{ik}|\psi\rangle\langle\psi|B_{jk}^\dagger
    \right)
    &= \sum_{ij} \langle i|j\rangle\cdot B_{ik}|\psi\rangle\langle\psi|B_{jk}^\dagger
  \\&= \sum_i B_{ik}|\psi\rangle\langle\psi|B_{ik}^\dagger
  \end{aligned}
\]
where we have used the fact that \(\langle i|j\rangle=\delta_{ij}\).
In general, for any input state \(\rho\), we obtain the map
\[
  \rho\longmapsto
  \rho'= \sum_i B_{ik}\rho B^\dagger_{ik} \equiv \sum_i B_{i}\rho B^\dagger_{i}
\]
where, in the last expression on the right-hand size, we have dropped index \(k\) (remember, it was there only to remind us about the initial state of the ancilla).
Since the overall transformation \(U\) is unitary, recall that the \(B_i\) satisfy \(\sum_i B_i^\dagger B_i=\mathbf{1}\).
This normalisation conditions guarantees that the trace is preserved.

\begin{idea}
In summary, we can think about a quantum evolution of subsystem \(\mathcal{B}\) as a sequence of the three distinct operations:
\[
  \begin{aligned}
    \rho
    \longmapsto &\underbrace{|k\rangle\langle k|\otimes\rho}_{\text{add ancilla}}
  \\\longmapsto &\underbrace{U(|k\rangle\langle k|\otimes\rho) U^\dagger}_{\text{unitary evolution}}
  \\\longmapsto &\underbrace{\operatorname{tr}_\mathcal{A} \left[U(|k\rangle\langle k|\otimes\rho) U^\dagger\right]}_{\text{discard ancilla}}
    = \sum_i B_{i}\rho B_{i}^\dagger
    =\rho'.
  \end{aligned}
\]

\end{idea}

In summary:

\begin{itemize}
\tightlist
\item
  First we pick up a system of interest which, in general, can be in a mixed state \(\rho\). It may be the case that this system is entangled with some other degrees of freedom or with some other physical systems, but these other entities will remain passive and will not enter any subsequent dynamics.
\item
  Then we dilate the system: we add an ancilla which is large enough to include everything our system will interact with, and also large enough to be in a pure state. The expansion ends when the composed system is (for all practical purposes) isolated and follows a unitary evolution \(U\).
\item
  After the unitary evolution takes place, we discard the ancilla and focus on the system alone. In fact we do not have to discard exactly what we added: we can discard only part of the ancilla, or any other part of the dilated system.
\item
  The output system in this scenario does not have to be the original input system, but usually it is.
\end{itemize}

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-54-1} \end{center}

It is adding (i.e.~tensoring) the auxiliary system in a fixed state, and then discarding it (via the partial trace), that is responsible for the \emph{non-unitary} character of this evolution.

\hypertarget{stinesprings-dilation-and-krauss-ambiguity}{%
\subsection{Stinespring's dilation and Kraus's ambiguity}\label{stinesprings-dilation-and-krauss-ambiguity}}

Once we start playing with adding physical systems and increasing the dimension of the underlying Hilbert space, it is convenient to switch from unitaries to isometries.
This is more for mathematical simplicity than physical insight, but it is always good to declutter our equations a bit if we can.
Note that when we fix the initial state of system \(\mathcal{A}\) to be \(|k\rangle\), we can use Equation (\(\ddagger\)) to define an isometry \(V\) from \(\mathcal{H}_\mathcal{B}\) to \(\mathcal{H}_\mathcal{A}\otimes \mathcal{H}_\mathcal{B}\), by
\[
  V\colon |\psi\rangle
  \longmapsto \sum_i|i\rangle\otimes E_i|\psi\rangle
\]
where \(E_i\equiv B_{ik}\) and, according to Equation (\(\star\)), \(\sum_i E_i^\dagger E_i=\mathbf{1}\) (here the identity operator acts on \(\mathcal{H}_\mathcal{B}\)).\footnote{Recall that a map \(V\) is an isometry if \(V^\dagger V=\mathbf{1}\). For example, adding a system in state \(|k\rangle\) gives an isometry \(V\colon|\psi\rangle\mapsto|k\rangle\otimes|\psi\rangle\), and the combination of adding a system in a fixed state followed by a unitary evolution of the combined system is also an isometry. Isometries preserve inner products, and therefore also preserve both the norm and the metric based upon the norm.}
The matrix representation of an isometry is a rectangular matrix given by selecting only a few of the columns from a unitary matrix;
here, with \(|k\rangle\) fixed, it is only the \(k\)-th column of the block matrix \(U\) that determines the evolution of \(\mathcal{B}\), as shown in Figure \ref{fig:unitary-isometry}.



\begin{figure}[H]

{\centering \includegraphics{iqis-book_files/figure-latex/unitary-isometry-1} 

}

\caption{For \(k=2\), the second block column is selected. The matrix representation of the isometry \(V\) on the right-hand side look like a column vector, but remember that the entries \(E_i\) are \emph{matrices}.}\label{fig:unitary-isometry}
\end{figure}

Let us now rephrase our derivation of the evolution of system \(\mathcal{B}\) using isometries.
Note that the isometry \(V\) in Figure \ref{fig:unitary-isometry} acts by
\[
  |\psi\rangle\langle\psi|
  \longmapsto
  V|\psi\rangle\langle\psi|V^\dagger
  = \sum_{ij} |i\rangle\langle j| \otimes E_i|\psi\rangle\langle\psi| E_j^\dagger.
\]
We trace out \(\mathcal{A}\), recall that \(\operatorname{tr}|i\rangle\langle j| = \langle i|j\rangle=\delta_{ij}\), and express the evolution of system \(\mathcal{B}\) as
\[
  \rho
  \longmapsto
  \rho' = \operatorname{tr}_\mathcal{A} V\rho V^\dagger =\sum_i E_i\rho E_i^\dagger,
\]
where \(\sum_iE_i^\dagger E_i=\mathbf{1}\), and we allowed the input states \(\rho\) of \(\mathcal{B}\) to be mixed (since they can always be expressed as statistical mixtures of pure states \(|\psi\rangle\)).
This expression shows two different ways of looking at quantum evolutions, and both even have names associated with them.

\begin{idea}

\begin{itemize}
\item
  \textbf{Stinespring}\footnote{\href{https://en.wikipedia.org/wiki/W.\%5FForrest\%5FStinespring}{William Forrest ``Woody'' Stinespring} (1929--2012) was an American mathematician specialising in operator theory.} \textbf{dilation.}
  Any quantum channel \(\mathcal{E}\) can be thought of as arising from a \emph{unitary} evolution on a \emph{dilated} system.
  When we combine tensoring and the unitary evolution into an isometry \(V\), we can express the action of the channel \(\mathcal{E}\) as
  \[
      \rho \longmapsto \rho'= \operatorname{tr}_\mathcal{A} V\rho V^\dagger,
    \]
  where we trace out a suitably chosen ancilla \(\mathcal{A}\).
  In quantum information science we often refer to this approach as \emph{``the Church of the Larger Hilbert Space''}.
\item
  \textbf{Kraus}\footnote{\href{https://en.wikipedia.org/wiki/Karl\%5FKraus\%5F(physicist)}{Karl Kraus} (1938--1988) was a German physicist known for his contributions to the mathematical foundations of quantum theory. His book \emph{States, effects, and operations} (Lecture Notes in Physics, Vol. \textbf{190}, Springer-Verlag, Berlin 1983) is an early account of the notion of complete positivity in physics.} \textbf{representation} (a.k.a. \textbf{operator-sum decomposition}).
  It is often more convenient to not deal with a larger Hilbert space, but to instead work with operators between the input and output Hilbert spaces
  \[
      \rho \longmapsto \rho'= \sum_i E_i\rho E_i^\dagger.
    \]
  Here we avoid dragging in the ancilla, which can be a good thing, since ancillas typically represent environments that can be very large and complex.
  This operator--sum decomposition is not unique, since the operators \(E_i\) (known as the \textbf{Kraus operators} or \textbf{effects}) depend on the choice of basis in the ancilla.
  The Kraus operators must satisfy the normalisation condition \(\sum_i E^\dagger_iE_i=\mathbf{1}\), also known as the \textbf{completeness relation}.
\end{itemize}


\end{idea}

We can easily switch between these two equivalent representations:

\begin{itemize}
\tightlist
\item
  We have already seen how to go from a unitary evolution \(U\) on a larger system, to an isometry \(V\), and then to a map on density operators represented by a set of Kraus operators \(E_i\) (as in Figure \ref{fig:unitary-isometry}).
\item
  Conversely, once we have an operator-sum representation of the channel with a set of Kraus operators \(E_i\), we can introduce an ancilla of dimension equal to the number of Kraus operators, and use the orthonormal basis \(|i\rangle\) to form the isometry \(V=\sum_i|i\rangle\otimes E_i\).
  In terms of matrices, this corresponds to simply ``stacking up'' the matrices \(E_i\) to form the block column (as shown in Figure \ref{fig:unitary-isometry}), which gives us the matrix representation of \(V\).
  If we want to go further, from an isometry \(V\) to a unitary \(U\), then the next step is somewhat arbitrary: we can choose all the remaining block columns of \(U\) however we please, \emph{as long as} we end up with a unitary matrix \(U\).
\end{itemize}

In summary:

\begin{idea}
All linear transformations of density operators that can be written in the Stinespring (or, equivalently, Kraus) form represent \emph{physically realisable operations}, and we call them \textbf{quantum channels}.\footnote{Quantum channels are also known as \textbf{superoperators} --- this way physicists remind themselves that these transformations take operators to operators.}

\end{idea}

We note again that the Kraus decomposition is \emph{not unique}: the operators \(E_i\) depend on the choice of the ancilla basis.
Indeed, let \(|e_i\rangle\) and \(|f_j\rangle\) be two orthonormal bases in the Hilbert space associated with the ancilla.
Then \(V\) can be expressed as
\[
  \begin{aligned}
    V
    &= \sum_i|e_i\rangle\otimes E_i
  \\&= \sum _{ij} |f_j\rangle\langle f_j|e_i\rangle\otimes E_i
  \\&= \sum_{j} |f_j\rangle \otimes \sum_i \underbrace{\langle f_j|e_i\rangle}_{R_{ji}} E_i
  \\&= \sum_{j} |f_j\rangle \otimes F_j
  \end{aligned}
\]
where we have used the fact that \(\sum_j |f_j\rangle\langle f_j|=\mathbf{1}\), and where \(R_{ji}=\langle f_j|e_i\rangle\) is a unitary matrix connecting the two orthonormal bases (and also the two sets of the Kraus operators) via \(F_j=\sum_i R_{ji} E_i\).
So we have a set of Kraus operators \(E_i\) associated with basis \(|e_i\rangle\) and another, unitarily related, set of Kraus operators associated with basis \(|f_j\rangle\), and the two sets describe the same isometry, and hence the same quantum channel.
This correspondence goes both ways: if two channels \(\mathcal{E}\) and \(\mathcal{F}\) have their Kraus operators related by some unitary \(R_{ji}\), then the two channels are identical:
\[
  \begin{aligned}
    \mathcal{F}(\rho)
    &= \sum_j F_j\rho F^\dagger_j
  \\&= \sum_{ijk} R_{ji}E_i \rho E^\dagger_k R^\star_{jk}
  \\&=\sum_{ik} \underbrace{\left(\sum_j R_{jk}^\star R_{ji}\right)}_{\delta_{ki}} E_i\rho E^\dagger_k
  \\&= \sum_i E_i\rho E^\dagger_i
  \\&= \mathcal{E}(\rho).
  \end{aligned}
\]

In summary:

\begin{idea}
Suppose \(E_1,\ldots,E_n\) and \(F_1,\ldots,F_m\) are Kraus operators associated with quantum channels \(\mathcal{E}\) and \(\mathcal{F}\), respectively.
We can append zero operators to the shorter list\footnote{If you wish, instead of appending zeros, you may view \(R_{ji}\) as an isometry from the the smaller to the larger set of Kraus operators.} to ensure that \(n=m\).
Then \emph{\(\mathcal{E}\) and \(\mathcal{F}\) describe the same channel if and only if \(F_j=\sum_i R_{ji} E_i\) for some unitary \(R\)}.

\end{idea}

In particular, this unitary equivalence of the Kraus operators implies that the identity channel \(\rho\mapsto\rho'=\mathbf{1}\rho\mathbf{1}\) can only have Kraus operators that are proportional to the identity.

\hypertarget{single-qubit-channels}{%
\subsection{Single qubit channels}\label{single-qubit-channels}}

The best way to familiarise ourselves with the concept of a quantum channel is to study a few examples, and we will start with the simplest case: \textbf{single qubit channels}.
The single qubit case is special since we can visualise the action of the channel by looking at the corresponding deformation of the Bloch sphere.
Recall that an arbitrary density matrix for a single qubit can be written in the form
\[
  \begin{aligned}
    \rho
    &= \frac{1}{2}\left(\mathbf{1}+\vec{s}\cdot \vec\sigma\right)
  \\&= \frac{1}{2}\left(\mathbf{1}+s_x X+ s_y Y + s_z Z\right)
  \end{aligned}
\]
where \(\vec{s}\) is the Bloch vector of the qubit with components \((s_x, s_y, s_z)\), and \(X\), \(Y\), and \(Z\) are the Pauli operators.
Recall that unitary operations rotate the Bloch sphere.
In particular the \(X\), \(Y\), and \(Z\) --- viewed as unitary transformations --- rotate the Bloch sphere by \(180^\circ\) around the \(x\), \(y\), and \(z\) axes, respectively.
General quantum channels, however, may deform it further, into spheroids with a displaced centre, as the following examples show.

\begin{itemize}
\item
  \emph{A bit-flip with probability \(p\):}
  \[
      \rho \longmapsto (1-p)\rho+pX\rho X.
    \]
  The Kraus operators are \(\sqrt{1-p}\mathbf{1}\) and \(\sqrt{p}X\);
  the original Bloch sphere shrinks into a prolate spheroid aligned with the \(x\)-axis;
  for the specific case of \(p=\frac{1}{2}\), the Bloch sphere degenerates to the \([-1,1]\) interval on the \(x\)-axis.
\item
  \emph{A phase-flip with probability \(p\):}
  \[
      \rho \longmapsto (1-p)\rho+pZ\rho Z.
    \]
  The Kraus operators are \(\sqrt{1-p}\mathbf{1}\) and \(\sqrt{p}Z\);
  the original Bloch sphere shrinks into a prolate spheroid aligned with the \(z\)-axis;
  for the specific case of \(p=\frac{1}{2}\), the Bloch sphere degenerates to the \([-1,1]\) interval on the \(z\)-axis.
\item
  \emph{The depolarising channel:}
  \[
      \rho\longmapsto (1-p)\rho + \frac{p}{3}\left(X\rho X+Y\rho Y+Z\rho Z\right).
    \]
  Here the qubit remains intact with probability \(1-p\), while a quantum error occurs with probability \(p\).
  The error can be of any one of three types: bit-flip \(X\), phase-flip \(Z\), or and both bit- and phase-flip \(Y\); each type of error is equally likely.
  For \(p<\frac{3}{4}\), the original Bloch sphere contracts uniformly under the action of the channel, and the Bloch vector shrinks by the factor \(1-\frac{4}{3}p\);
  for the specific case of \(p=\frac{3}{4}\), the Bloch sphere degenerates to the point at the centre of the sphere;
  for \(p>\frac{3}{4}\), the Bloch sphere is flipped, and the Bloch vector starts pointing in the opposite direction increasing the magnitude up to \(\frac{1}{3}\) (which occurs for \(p=1\)).
\end{itemize}

There are two interesting points that must be mentioned here.
The first one is about the interpretation of the action of the channel in terms of Kraus operators: our narrative may change when we switch to a different set of effects.
For example, take the phase-flip channel with \(p=\frac{1}{2}\) and switch from the effects
\[
  \begin{aligned}
    E_1 &= \frac{1}{\sqrt{2}}\mathbf{1}
  \\E_2 &= \frac{1}{\sqrt{2}}Z
  \end{aligned}
\]
to
\[
  \begin{aligned}
    F_1 &= \frac{1}{\sqrt{2}}(E_1+E_2)=|0\rangle\langle 0|
  \\F_2 &= \frac{1}{\sqrt{2}}(E_1-E_2)=|1\rangle\langle 1|.
  \end{aligned}
\]
These two sets of Kraus operators \(\{E_1,E_2\}\) and \(\{F_1,F_2\}\) describe the same channel, but the \emph{narrative} is different.
The first set of effects tells us that the channel chooses randomly, with the same probability, between the two options: let the qubit pass undisturbed or apply the phase-flip \(Z\);
the second set tells us that channel essentially performs the measurement in the standard basis, but the outcome of the measurement is not revealed.
In general:

\begin{idea}
Describing actions of quantum channels purely in terms of their effects (i.e.~Kraus operators) can be ambiguous.

\end{idea}

The second interesting point is that not \emph{all} transformations of the Bloch sphere into spheroids are possible.
For example, we cannot deform the Bloch sphere into a pancake-like oblate spheroid.
This is due to \emph{complete} positivity (instead of mere positivity) of quantum channels, which we will explain shortly.

\hypertarget{composition-of-quantum-channels}{%
\subsection{Composition of quantum channels}\label{composition-of-quantum-channels}}

We mentioned that quantum channels are combinations of

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  adding a physical system in a fixed state (via tensoring),
\item
  discarding a physical system (taking a partial trace),
\item
  and unitary transformations.
\end{enumerate}

For consistency let us note that each of these operations admits an operator-sum decomposition. This is obvious for unitary evolution (\(\rho\mapsto U\rho U^\dagger\)), but perhaps less so for the other two operations.

\begin{itemize}
\item
  \textbf{Adding a system.}
  Any quantum system can be expanded by bringing in an auxiliary system in a fixed state \(|a\rangle\).
  This transformation takes vectors in the Hilbert space associated with the original system and tensors them with a fixed vector \(|a\rangle\) in the Hilbert space associated with the auxiliary system:
  \[
      |\psi\rangle
      \longmapsto |a\rangle\otimes|\psi\rangle
      = (|a\rangle\otimes\mathbf{1}) |\psi\rangle.
    \]
  In terms of density operators, we write this ``expansion'' transformation as
  \[
      \begin{aligned}
        \rho
        \longmapsto \rho'
        &= |a\rangle\langle a|\otimes\rho
      \\&= (|a\rangle\otimes\mathbf{1})\rho (\langle a|\otimes\mathbf{1})
      \\&= V\rho V^\dagger
      \end{aligned}
    \]
  where \(V=\mathbf{1}\otimes|a\rangle\).
  We note that \(V^\dagger V = \mathbf{1}\otimes\langle a|a|=\rangle\mathbf{1}\) is the identity in the Hilbert space associated with the system, and so \(V\) is an isometry.
  Indeed, this transformation is an \emph{isometric embedding}.
\item
  \textbf{Discarding a system.}
  Conversely, given a composite system in state \(\rho\), we can discard one of its subsystems.
  The partial trace over an auxiliary system can be written in the Kraus representation as
  \[
      \begin{aligned}
        \rho
        \longmapsto \rho'
        &= \operatorname{tr}_\mathcal{A}\rho
      \\&= (\operatorname{tr}\otimes\mathbf{1})\rho
      \\&= \sum_i (\langle i|\otimes\mathbf{1})\rho(|i\rangle\otimes\mathbf{1})
      \\&= \sum_i E_i\rho E^\dagger_i
      \end{aligned}
    \]
  where the vectors \(|i\rangle\) form an orthonormal basis in the Hilbert space associated with the auxiliary system.
  Again, we can check that the Kraus operators \(E_i=\langle i|\otimes\mathbf{1}\) satisfy the completeness relation \(\sum_i E^\dagger_i E_i =\mathbf{1}\otimes\mathbf{1}\) (using the fact that \(\sum_i|i\rangle\langle i|=\mathbf{1}\)).
\end{itemize}

Any \emph{sequential} composition of two quantum channels \(\mathcal{E}\) and \(\mathcal{F}\) with Kraus operators \(\{A_i\}_{i\in I}\) and \(\{B_j\}_{j\in J}\) (respectively) is another quantum channel\footnote{Here we have tacitly assumed that the dimensions agree, i.e.~that the output of \(\mathcal{E}\) and the input of \(\mathcal{F}\) are of the same dimension, so that the composition makes sense.} described by the Kraus operators \(\{B_jA_i\}_{i\in I,j\in J}\).
Showing this is rather straightforward, at least in the operator-sum representation: let
\[
  \begin{aligned}
    \mathcal{E} &= \sum_i A_i\cdot A^\dagger_i
  \\\mathcal{F} &= \sum_j B_j\cdot B^\dagger_j
  \end{aligned}
\]
where \(\sum_i A^\dagger_i A_i=\sum_j B^\dagger_j B_j=\mathbf{1}\);
then the sequential composition of \(\mathcal{E}\) followed by \(\mathcal{F}\) can be written as
\[
  \mathcal{F} \circ\mathcal{E}
  = \sum_{ij} (B_jA_i) \cdot (B_jA_i)^\dagger
\]
so that the \(B_jA_i\) are the Kraus operators associated with the new channel \(\mathcal{F}\circ\mathcal{E}\), where the normalisation condition (or completeness relation) follows from
\[
  \begin{aligned}
    \sum_{ij} (B_jA_i)^\dagger (B_jA_i)
    &= \sum_i A_i^\dagger\left(\sum_j B_j^\dagger B_j\right)A_i
  \\&= \sum_i A_i^\dagger A_i
  \\&= \mathbf{1}.
  \end{aligned}
\]

You might wonder why we explicitly called the above composition ``sequential'' --- isn't this how we always compose functions?
In actual fact, since we have access to tensor products, there is another sort of composition, namely \textbf{parallel} composition: if we have systems \(\mathcal{A}\) and \(\mathcal{B}\) with channels \(\mathcal{E}_\mathcal{A}\) acting on \(\mathcal{A}\) and \(\mathcal{E}_\mathcal{B}\) acting on \(\mathcal{B}\), then the parallel composition is denoted by \(\mathcal{E}_\mathcal{A}\otimes\mathcal{E}_\mathcal{B}\), acting on the joint system \(\mathcal{A}\otimes\mathcal{B}\), and with Kraus operators given by the \(A_i\otimes B_j\).
The normalisation condition again follows from a simple calculation:
\[
  \begin{aligned}
    \sum_{ij} (A_i\otimes B_j)^\dagger (A_i\otimes B_j)
    &= \sum_{ij} A_i^\dagger A_i \otimes B_j^\dagger B_j
  \\&= \mathbf{1}_A\otimes\mathbf{1}_B.
  \end{aligned}
\]

Now that we know how to compose quantum channels in terms of Kraus operators, we can see that the Stinespring representation is perfectly consistent with the Kraus representation: the three basic operations that we are allowed to use to build channels in the Stinespring representation (i.e.~adding a system, unitary evolution, and discarding a system) are all themselves quantum channels, in that they admit a Kraus decomposition.

Before moving on, we make a small (but important) remark:

\begin{idea}
When we compose quantum channels, each channel needs its own independent ancilla;
\emph{do not share ancillas between different channels}.

\end{idea}

For example, say we have three channels, \(\mathcal{E}_1\), \(\mathcal{E}_2\), and \(\mathcal{E}_3\), with \(\mathcal{E}_i\) defined by the unitary \(U_i\) and the state \(|a_i\rangle\) of its ancilla.
Then the (sequential) composition \(\mathcal{E}_3\circ\mathcal{E}_2\circ\mathcal{E}_1\) is given by

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-55-1} \end{center}

For more on this, see \protect\hyperlink{markov-approximation}{the appendix on Markov approximation}.

\hypertarget{completely-positive-trace-preserving-maps}{%
\subsection{Completely positive trace-preserving maps}\label{completely-positive-trace-preserving-maps}}

It is easy to verify that quantum channels preserve positivity and trace, but the converse is not true!
You may find it surprising, but there are linear maps that preserve positivity and the trace, but which are \emph{not} quantum channels.
The matrix transpose operation \(\rho\mapsto\rho'=\rho^T\) is a good example of such an unphysical operation: it preserves both trace and positivity, and if \(\rho\) is a density matrix then so too is \(\rho'=\rho^T\), but the transpose \emph{cannot} be written in the Stinespring (or the Kraus) form;
it is not induced by a unitary operation on some larger Hilbert space, and it cannot be implemented.
So, we then ask, \emph{what is} the class of physically admissible maps?

Mathematically speaking, a quantum channel \(\mathcal{E}\) is represented by a map
\footnote{Recall that, given a pair of Hilbert spaces \(\mathcal{H}\) and \(\mathcal{H}'\), we denote the set of (bounded) linear operators from \(\mathcal{H}\) to \(\mathcal{H}'\) by \(\mathcal{B}(\mathcal{H},\mathcal{H}')\). We write \(\mathcal{B}(\mathcal{H})\) as shorthand for \(\mathcal{B(H,H)}\)}
\[
  \mathcal{E}\colon \mathcal{B}(\mathcal{H}) \to \mathcal{B}(\mathcal{H}')
\]
mapping states (i.e.~density operators) on some Hilbert space \(\mathcal{H}\) to states on some, possibly different, Hilbert space \(\mathcal{H}'\).
But we are not interested in just any such maps, of course --- the statistical interpretation of quantum theory imposes certain properties on the subset of maps in which we are interested.

\begin{itemize}
\item
  Firstly, for such a map \(\mathcal{E}\) to be a channel it must \emph{respect the mixing of states}.
  Consider an ensemble of systems, with a fraction \(p_1\) of them in the state \(\rho_1\), and the remaining \(p_2\) of them in the state \(\rho_2\).
  The overall ensemble is described by \(\rho=p_1\rho_1+p_2\rho_2\).
  If we apply \(\mathcal{E}\) to each member of the ensemble individually, then the overall ensemble will be described by the density operator \(\rho'=\mathcal{E}(\rho)\), which is given by \(\rho'=p_1\mathcal{E}(\rho_1)+p_2\mathcal{E}(\rho_2)\).
  We conclude that \(\mathcal{E}\) must be a \emph{linear map}.
\item
  Next, since \(\mathcal{E}\) must \emph{map density operators to density operators} it must be both \emph{positive} (\(\mathcal{E}(\rho)\geqslant 0\) whenever \(\rho\geqslant 0\)) and \emph{trace preserving} (\(\operatorname{tr}\mathcal{E}(\rho)=\operatorname{tr}\rho\) for all \(\rho\)).
\item
  Finally comes a subtle point.
  It turns out that being positive is not good enough;
  we must further require that the map \(\mathcal{E}\) \emph{remains positive even when extended to act on a part of a larger system}.
  Suppose that Alice and Bob share a bipartite system \(\mathcal{AB}\) in an entangled state \(\rho_\mathcal{AB}\), and, whilst Alice does nothing, Bob applies the local operation \(\mathcal{E}\) to his subsystems, and his subsystems only.
  Then the resulting map on the whole bipartite system is given by \(\mathbf{1}\otimes\mathcal{E}\), and this must give a proper density operator \(\rho'_\mathcal{AB}\) of the composed system.
  It turns out that this is a strictly stronger property than mere positivity;
  we are asking for something called \textbf{complete positivity}.
  Needless to say, complete positivity of \(\mathcal{E}\) implies positivity, but the converse does not hold: there are maps which are positive but not completely positive.
  The matrix transpose operation \(\rho\rightarrow \rho'=\rho^T\) is a classic example of such a map.
\end{itemize}

In fact, we can study the matrix transpose a bit further.
Consider the transpose operation on a single qubit: \(T\colon(|i\rangle\langle j|)\mapsto|j\rangle\langle i|\) (for \(i,j\in\{0,1\}\)).
It preserves both trace and positivity, and if \(\rho\) is a density matrix then so too is \(\rho'=\rho^T\).
However, if the input qubit is part of a two qubit system, initially in the entangled state \(|\Omega\rangle=\frac{1}{\sqrt{2}}(|0\rangle|0\rangle+|1\rangle|1\rangle)\), and the transpose is applied to \emph{only one} of the two qubits (say, the second one), then the density matrix of the two qubits evolves under the action of the partial transpose \(\mathbf{1}\otimes T\) as
\[
  \begin{aligned}
    |\Omega\rangle\langle\Omega|
    = \frac{1}{2}\sum_{ij} |i\rangle\langle j| \otimes |i\rangle\langle j|
    &\overset{\mathbf{1}\otimes T}{\longmapsto}
    \frac{1}{2}\sum_{ij} |i\rangle\langle j| \otimes T( |i\rangle\langle j|)
  \\&= \frac{1}{2}\sum_{ij} |i\rangle\langle j| \otimes |j\rangle\langle i|.
  \end{aligned}
\]
The output is the \(\texttt{SWAP}\) matrix, since it describes the \(\texttt{SWAP}\) operation: \(|j\rangle|i\rangle\mapsto|i\rangle|j\rangle\).
Since this operation squares to the identity, we know that its eigenvalues must be either \(\pm1\): states which are symmetric under interchange of the two qubits have eigenvalue \(1\), while antisymmetric states have eigenvalue \(-1\).
So the \(\texttt{SWAP}\) matrix has negative eigenvalues, which means that \(\mathbf{1}\otimes T\) does \emph{not} preserve positivity, and therefore \(T\) is \emph{not} a completely positive map.
If you prefer to see this more explicitly, then you can use the matrix representation of \(|\Omega\rangle\langle\Omega|\), apply the partial transpose \(\mathbf{1}\otimes T\), and then inspect the resulting matrix:
\[
  \frac12\left[
  \begin{array}{cc|cc}
    1 & 0 & 0 & 1
  \\0 & 0 & 0 & 0
  \\\hline
    0 & 0 & 0 & 0
  \\1 & 0 & 0 & 1
  \end{array}\right]
  \overset{\mathbf{1}\otimes T}{\longmapsto}
  \frac12\left[
  \begin{array}{cc|cc}
    1 & 0 & 0 & 0
  \\0 & 0 & 1 & 0
  \\\hline
    0 & 1 & 0 & 0
  \\0 & 0 & 0 & 1
  \end{array}\right].
\]
That is, the partial transpose \(\mathbf{1}\otimes T\) maps the density matrix of a maximally entangled state \(|\Omega\rangle\langle\Omega|\) to the \(\texttt{SWAP}\) matrix, which has one negative eigenvalue (\(-1\)) and thus is not a density matrix.

So we have seen that, at the very least, we want to be considering \emph{completely positive trace-preserving} maps, but how do we know whether or not there are any restrictions left to impose?
Needless to say, here is where mathematics alone cannot guide us, since we are trying to characterise maps which are \emph{physically admissible}, and mathematics knows nothing about the reality of our universe!
However, one thing that we can do is compare our abstract approach with the derivations of quantum channels defined in terms of the Stinespring (or the Kraus) representation.
As it happens, we can show that a map is completely positive and trace preserving if and only if it can be written in the Stinespring (or the Kraus) form.
In other words:

\begin{idea}
Quantum channels are exactly the completely positive trace-preserving (CPTP) maps.

\end{idea}

One direction of this claim is much simpler than the other.
Any channel \(\mathcal{E}\) must be completely positive, since the Kraus decomposition guarantees positivity of both \(\mathcal{E}\) \emph{and} the extended map \(\mathbf{1}\otimes\mathcal{E}\): if \(\mathcal{E}\) has the Kraus decomposition \(\sum_i E_i\cdot E_i^\dagger\), then the extended channel \(\mathbf{1}\otimes\mathcal{E}\) has the Kraus decomposition \(\sum_i(\mathbf{1}\otimes E_i)\cdot(\mathbf{1}\otimes E_i^\dagger)\), which means that \(\mathbf{1}\otimes\mathcal{E}\) is also a positive map, and so \(\mathcal{E}\) is completely positive.
Showing that CPTP maps are quantum channels is less obvious, and, in order to prove this, we will introduce a very convenient tool called the \textbf{Choi matrix}\footnote{Man-Duen Choi was brought up in Hong Kong. He received his Ph.D.~degree under the guidance of Chandler Davis at Toronto. He taught at the University of California, Berkeley, from 1973 to 1976, and has worked since then at the University of Toronto. His research has been mainly in operator algebras, operator theory, and polynomial rings. He is particularly interested in examples/counterexamples and two-by-two matrix manipulations.}, which is yet another way to characterise linear maps between operators.

\begin{itemize}
\tightlist
\item
  \textbf{!!to-do: tim footnote: here we work only with finite dimensional spaces, and if \(X\) is f.d. then every linear operator \(f\colon X\to Y\) between normed vector spaces is continuous (and thus bounded)!!}
\item
  talk about \href{https://en.wikipedia.org/wiki/Hilbert_space\#Unbounded_operators}{unbounded operators}
\end{itemize}

\hypertarget{state-channel-duality}{%
\subsection{State-channel duality}\label{state-channel-duality}}

Suppose that \(\mathcal{H}\) is of dimension \(d\) and \(\mathcal{H}'\) is of dimension \(d'\), and pick a basis for each space.
Then any linear map \(\mathcal{E}\colon\mathcal{B}(\mathcal{H})\to\mathcal{B}(\mathcal{H'})\) can be completely characterised by its action on the \(d^2\)-many basis matrices \(|i\rangle\langle j|\) of \(\mathcal{B}(\mathcal{H})\), where \(i,j\in\{1,2\ldots,d\}\), i.e.~for any density operator \(\rho\) on \(\mathcal{H}\) we have
\[
  \mathcal{E}(\rho)
  = \mathcal{E}\left(\sum_{ij}\rho_{ij} |i\rangle\langle j|\right)
  = \sum_i\rho_{ij}\mathcal{E}(|i\rangle\langle j|).
\tag{$\natural$}
\]
We can now tabulate all the \((d'\times d')\) matrices \(\mathcal{E}(|i\rangle\langle j|)\) in \(\mathcal{H}'\) by forming a bigger \((dd'\times dd')\) block matrix in \(\mathcal{H}\otimes\mathcal{H}'\):

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-56-1} \end{center}

We call this block matrix \(\widetilde{\mathcal{E}}\in\mathcal{B}(\mathcal{H}\otimes\mathcal{H}')\) the \textbf{Choi matrix} of \(\mathcal{E}\).

The Choi matrix is essentially another way of representing a linear map \(\mathcal{E}\colon\mathcal{B}(\mathcal{H})\to\mathcal{B}(\mathcal{H'})\): if you are given the Choi matrix \(\widetilde{\mathcal{E}}\) of \(\mathcal{E}\) and you want to evaluate \(\mathcal{E}(\rho)\), then you simply follow Equation (\(\natural\)), taking the values of \(\mathcal{E}(|i\rangle\langle j|)\) from the Choi matrix.
This can be formally written as

\begin{idea}
The Choi matrix \(\widetilde{\mathcal{E}}\) of a linear map \(\mathcal{E}\colon\mathcal{B}(\mathcal{H})\to\mathcal{B}(\mathcal{H'})\) satisfies
\[
  \mathcal{E}(\rho)
  = d(\operatorname{tr}\otimes\mathbf{1})\left[(\rho^T\otimes\mathbf{1})\widetilde{\mathcal{E}}\right]
\]
for all density matrices \(\rho\), where \(d=\dim\mathcal{H}\).

\end{idea}

The expression above may look baffling to an untrained eye, but this is often the case when we turn something conceptually obvious into a precise and compact mathematical notation.
In order to gain some intuition here, recall that, for matrices \(A\) and \(B\),
\[
  \operatorname{tr}A^T B = \sum_{ij} A_{ij}B_{ij}.
\]
If we take \(A\) and \(B\) to be the block matrices \(\rho\otimes\mathbf{1}\) and \(\widetilde{\mathcal{E}}\), respectively, then we can use this to show that
\[
  (\operatorname{tr}\otimes\mathbf{1})\left[(\rho^T\otimes\mathbf{1})\widetilde{\mathcal{E}}\right]
  = \frac{1}{d}\sum_i\rho_{ij}\mathcal{E}(|i\rangle\langle j|).
\]

This state-channel duality thus gives us a one-to-one correspondence between linear maps \(\mathcal{E}\colon\mathcal{B}(\mathcal{H})\to\mathcal{B}(\mathcal{H}')\) and matrices \(\widetilde{\mathcal{E}}\) acting on the tensor product \(\mathcal{H}\otimes\mathcal{H}'\).
This correspondence is sometimes called the \textbf{Choi--Jamiołkowski isomorphism}, and we discuss it further in \protect\hyperlink{choi-jamiolkowski}{the appendix of the same name}.

Mathematically, it is not too surprising that the matrix elements of an operator on a tensor product can be reorganised and reinterpreted as the matrix elements of an operator between operator spaces.
What is interesting, and perhaps not so obvious, however, is that the positivity conditions for maps correspond exactly to conditions on their Choi matrices under this correspondence.
In order to see this, let us express the Choi matrix as the result of \(\mathbf{1}\otimes\mathcal{E}\) acting on the maximally entangled state in \(\mathcal{H}\otimes\mathcal{H}\):

\begin{idea}
The Choi matrix \(\widetilde{\mathcal{E}}\) of a linear map \(\mathcal{E}\colon\mathcal{B}(\mathcal{H})\to\mathcal{B}(\mathcal{H'})\) is given by
\[
  \widetilde{\mathcal{E}}
  = (\mathbf{1}\otimes\mathcal{E})|\Omega\rangle\langle\Omega|
  = \frac{1}{d} \sum_{ij} |i\rangle\langle j|\otimes\mathcal{E}(|i\rangle\langle j|)
\]
where \(|\Omega\rangle=\frac{1}{\sqrt d}\sum_{i=1}^d|i\rangle|i\rangle\) is the maximally entangled state in \(\mathcal{H}\otimes\mathcal{H}\), and where \(d=\dim\mathcal{H}\).

\end{idea}

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-57-1} \end{center}

In this form, the Choi--Jamiołkowski isomorphism gives us a simple necessary and sufficient condition for a linear map to be a quantum channel:

\begin{idea}
\textbf{State-channel duality}: \(\mathcal{E}\) is a quantum channel if and only if \(\widetilde{\mathcal{E}}\) is a density matrix.

\end{idea}

One direction of this claim is immediate: we already know that any quantum channel \(\mathcal{E}\) is, in particular, a completely positive map, and so \(\mathbf{1}\otimes\mathcal{E}\) maps density matrices to density matrices, whence \(\widetilde{\mathcal{E}}=(\mathbf{1}\otimes\mathcal{E})|\Omega\rangle\langle\Omega|\) is a density matrix, since \(|\Omega\rangle\langle\Omega|\) is a density matrix.
The other direction is less obvious.
If \(\widetilde{\mathcal{E}}\) is a density matrix, then it can be written as a mixture of pure states \(|\psi_k\rangle\langle\psi_k|\) with probabilities \(p_k\):
\[
  \widetilde{\mathcal{E}}
  = \sum_k|\widetilde{\psi}_k\rangle\langle\widetilde{\psi}_k|,
\]
where \(|\widetilde{ \psi}_k\rangle=\sqrt{p_k}|\psi_k\rangle\) are (non-normalised) vectors, and any such vector can be written as
\[
  |\widetilde{ \psi}_k\rangle = (\mathbf{1}\otimes E_k)|\Omega\rangle
\]
for some operator \(E_k\).

Now, any vector \(|\psi\rangle\) in \(\mathcal{H}\otimes\mathcal{H}'\) can be written as\footnote{\textbf{Exercise.} Prove this!}
\[
  |\psi\rangle=\mathbf{1}\otimes V|\Omega\rangle
\]
where \(V=\sum_{ij}V_{ij}|j\rangle\langle i|\) is an operator from \(\mathcal{H}\) to \(\mathcal{H}'\), and \(|\Omega\rangle=\frac{1}{d}\sum_i|i\rangle|i\rangle\) is a maximally entangled state in \(\mathcal{H}\otimes\mathcal{H}\).
(Here, the vectors \(|i\rangle\) and \(|j\rangle\) form orthonormal bases in \(\mathcal{H}\) and \(\mathcal{H}'\), respectively).

Using this, we see that
\[
  \begin{aligned}
    \widetilde{\mathcal{E}}
    &= \sum_k|\widetilde{\psi}_k\rangle\langle\widetilde{\psi}_k|
  \\&= \sum_k  (\mathbf{1}\otimes E_k)|\Omega\rangle\langle\Omega| (\mathbf{1}\otimes E^\dagger_k)
  \\&= \frac{1}{d} \sum_{ij} |i\rangle\langle j|\otimes\underbrace{\sum_k E_k(|i\rangle\langle j|) E^\dagger_k}_{\mathcal{E}(|i\rangle\langle j|)}.
  \end{aligned}
\]
Comparing the last expression on the right-hand size with the definition of \(\widetilde{\mathcal{E}}\), or using the Choi--Jamiołkowski isomorphism, we conclude that \(\mathcal{E}\) is of the form
\[
  \mathcal{E}(\rho)
  = \sum_k E_k \rho E^\dagger_k.
\]
Moreover, \(\operatorname{tr}\widetilde{\mathcal{E}}=1\) implies that\footnote{\textbf{Exercise.} Prove this!} \(\sum_k E^\dagger_kE_k=\mathbf{1}\).
So if \(\widetilde{\mathcal{E}}\) is a density operator, then the map \(\mathcal{E}\) can be expressed in the Kraus form.
Thus \(\mathcal{E}\) is a quantum channel, and, therefore, also a CPTP map.
We have now established the desired isomorphism between \emph{states} and \emph{channels}.

The equations\footnote{Where \(\operatorname{tr}\otimes\mathbf{1}\) acts as \((\operatorname{tr}\otimes\mathbf{1})(A\otimes B)\coloneqq(\operatorname{tr}A)\otimes B\).}
\[
  \mathcal{E}(\rho)
  = d(\operatorname{tr}\otimes\mathbf{1})\left[(\rho^T\otimes\mathbf{1})\widetilde{\cal{E}}\right].
\]
and
\[
  \widetilde{\mathcal{E}}
  = (\mathbf{1}\otimes\mathcal{E})|\Omega\rangle\langle\Omega|
  = \frac{1}{d} \sum_{ij} |i\rangle\langle j|\otimes\mathcal{E}(|i\rangle\langle j|)
\]
tell us how to obtain the state \(\widetilde{\mathcal{E}}\) from the channel \(\mathcal{E}\), and vice versa.
We have also shown that quantum channels are exactly the completely positive trace-preserving maps.

We summarise the flow of implications in the following diagram:
\[
\begin{CD}
  \mathcal{E} @>{\widetilde{E}=(\mathbf{1}\otimes\mathcal{E})|\Omega\rangle\langle\Omega|}>> \widetilde{\mathcal{E}}
\\@VVV @VVV
\\E_k\cdot E_k^\dagger @<<{|\widetilde{\psi}_k\rangle=(\mathbf{1}\otimes E_k)|\Omega\rangle}< |\widetilde{\psi}_k\rangle\langle\widetilde{\psi}_k|
\end{CD}
\]
We start in the top left corner with a quantum channel \(\mathcal{E}\).
This channel is a CPTP map, which means that \(\mathbf{1}\otimes\mathcal{E}\) takes a maximally entangled state \(|\Omega\rangle\) to a density matrix \(\widetilde{\mathcal{E}}\).
This is our first implication: \emph{if \(\mathcal{E}\) is a quantum channel, then its Choi matrix \(\widetilde{\mathcal{E}}\) is a density matrix}.
The reverse implication goes as follows.
The density matrix \(\widetilde{\mathcal{E}}\) can be expressed as a mixture of pure states, \(|\widetilde\psi_k\rangle\langle\widetilde\psi_k|\) (and this takes us to the bottom right corner in the diagram).
We use this mixture decomposition when we construct map the \(\mathcal{E}\) from the Choi matrix \(\widetilde{\mathcal{E}}\), via the Choi-Jamiolkowski isomorphism.
We notice that \(\mathcal{E}\) admits the operator-sum representation, and that each of the pure states in the mixture is associated with a Kraus operator, with \(|\widetilde{\psi}_k\rangle = (\mathbf{1}\otimes E_k)|\Omega\rangle\).
All together this gives us the reverse implication: \emph{if the Choi matrix \(\widetilde{\mathcal{E}}\) is a density matrix, then \(\mathcal{E}\) is a quantum channel.}

\hypertarget{the-mathematics-of-can-and-cannot}{%
\subsection{The mathematics of ``can'' and ``cannot''}\label{the-mathematics-of-can-and-cannot}}

So what is state-channel duality good for?
To start with, it can be used to asses whether or not a given map \(\mathcal{B}(\mathcal{H})\to\mathcal{B}(\mathcal{H}')\) can actually be implemented, i.e.~if it is a physically realisable CPTP map.
Indeed, all we have to do is to check if the corresponding Choi matrix is a density matrix.
Let's look at a simple example.

Consider the map
\[
  \mathcal{E}\colon |i\rangle\langle j|
  \longmapsto p|j\rangle\langle i|+(1-p)\delta_{ij} \frac{1}{2}|i\rangle\langle j|
\]
where \(0\leqslant p\leqslant 1\) is some fixed parameter.
This map acts on a density operator \(\rho\) via
\[
  \rho
  \longmapsto \rho'
  = p\rho^T +(1-p) \frac{1}{2}\mathbf{1}
\]
where \(\rho^T\) is the transpose of \(\rho\).

But is this map a quantum channel?
That is, \emph{does it represent a physical process that can be implemented in a lab}?

The expression for \(\mathcal{E}\), i.e.~the convex sum, can be interpreted as follows: take the input state \(\rho\) and either (i) apply the transpose, or (ii) replace it with the maximally mixed state (with probabilities \(p\) and \(1-p\), respectively).
This is fine, except that the transpose operation is not completely positive, and, as such, \emph{is not physically admissible} --- it cannot be implemented.
But does it mean that the map \(\mathcal{E}\) itself cannot be implemented?
Not necessarily!

In fact, the answer depends on the value of \(p\).
The case \(p=0\) corresponds to just replacing the input with the maximally mixed state, which is something that can be easily implemented.
However, as \(p\) increases from \(0\) to \(1\), at some critical point the map switches from \emph{completely positive} to merely \emph{positive}.
In order to find this critical value of \(p\), we first calculate the \(\mathcal{E} (|i\rangle\langle j|)\), as follows:
\[
  \begin{aligned}
    |0\rangle\langle 0|
    &= \begin{bmatrix}1&0\\0&0\end{bmatrix}
    \longmapsto
    \begin{bmatrix}\frac{1+p}{2}&0\\0&\frac{1-p}{2}\end{bmatrix}
  \\|0\rangle\langle 1|
    &= \begin{bmatrix}0&1\\0&0\end{bmatrix}
    \longmapsto
    \begin{bmatrix}0&0\\p&0\end{bmatrix},
  \\|1\rangle\langle 0|
    &= \begin{bmatrix}0&0\\1&0\end{bmatrix}
    \longmapsto
    \begin{bmatrix}0&p\\0&0\end{bmatrix}
  \\|1\rangle\langle 1|
    &= \begin{bmatrix}0&0\\0&1\end{bmatrix}
    \longmapsto
    \begin{bmatrix}\frac{1-p}{2}&0\\0&\frac{1+p}{2}\end{bmatrix},
  \end{aligned}
\]
We can then write down the Choi matrix:
\[
  \widetilde{\mathcal{E}}
  = \frac12
  \begin{bmatrix}
    \mathcal{E}(|0\rangle\langle 0|)
    & \mathcal{E}(|0\rangle\langle 1|)
  \\\mathcal{E}(|1\rangle\langle 0|)
    & \mathcal{E}(|1\rangle\langle 1|)
  \end{bmatrix}
  = \frac{1}{2}
  \left[
    \begin{array}{cc|cc}
    \frac{1+p}{2} & 0 & 0 & 0
  \\0 & \frac{1-p}{2} & p & 0
  \\\hline
    0 & p & \frac{1-p}{2} & 0
  \\0 & 0 & 0 & \frac{1+p}{2}
   \end{array}
  \right]
\]
which lets us apply state-channel duality: \emph{\(\mathcal{E}\) is completely positive (and hence physically realisable) if and only if \(\widetilde{\mathcal{E}}\geqslant 0\)};
the latter is true only when \(p\leqslant\frac13\) (note that the eigenvalues of \(\widetilde{\mathcal{E}}\) are \(\frac{1}{4}(1+p)\) and \(\frac{1}{4}(1-3p)\)).

\hypertarget{kraus-operators-revisited}{%
\subsection{Kraus operators, revisited}\label{kraus-operators-revisited}}

One thing that is very important is that \emph{state-channel duality gives us more than just a one-to-one correspondence} between states \(\widetilde{\mathcal{E}}\) and channels \(\mathcal{E}\) --- it \emph{also} gives a one-to-one correspondence between vectors in the statistical ensemble \(\widetilde{\mathcal{E}}\) and the Kraus operators in the decomposition of \(\mathcal{E}\).
From this viewpoint, we see that the freedom to choose the Kraus operators representing a channel in many different ways is really the same thing as the freedom to choose the ensemble of pure states representing a density operator in many different ways.

We already know that two mixtures \(\{p_k, |\psi_k\rangle\}\) and \(\{q_l, |\phi_l\rangle\}\) described by the same density operator
\[
  \widetilde{\mathcal{E}}
  = \sum_k|\widetilde\psi_k\rangle\langle\widetilde\psi_k|
  = \sum_l|\widetilde\phi_l\rangle\langle\widetilde\phi_l|,
\]
(where \(|\widetilde \psi_k\rangle=\sqrt{p_k}|\psi_k\rangle\) and \(|\widetilde \phi_l\rangle=\sqrt{q_l}|\phi_l\rangle\)) are related: there exists some unitary \(R\) such that
\[
  |\widetilde \psi_k\rangle
  = \sum_{l} R_{kl} |\widetilde \phi_l\rangle.
\]
Using the aforementioned fact that any vector \(|\psi\rangle\) in \(\mathcal{H}\otimes\mathcal{H}'\) can be written as \(|\psi\rangle=\mathbf{1}\otimes V|\Omega\rangle\), this implies the same unitary freedom in choosing the Kraus operators.\footnote{The number of vectors contributing to each mixture (and hence the number of corresponding Kraus operators) may be different, so we simply extend the smaller set to the required size by adding zero operators.}

How many Kraus operators do we really need?
State-channel duality tells us that the \emph{minimal} number of Kraus operators needed to express \(\mathcal{E}\) in the operator-sum form is given by the rank of its Choi matrix \(\widetilde{\mathcal{E}}\), and so we need no more than \(dd'\) such operators.
In fact, this minimal set of Kraus operators corresponds to the spectral decomposition of \(\widetilde{\mathcal{E}}\).
Indeed, if \(\widetilde{\mathcal{E}}=\sum_k|\widetilde{v}_k\rangle\langle\widetilde{v}_k|\) and \(|\widetilde{v}_k\rangle=(\mathbf{1}\otimes E_k)|\Omega\rangle\), then the orthogonality of \(|\widetilde{v}_k\rangle\) and \(|\widetilde{v}_l\rangle\) implies the orthogonality (in the Hilbert--Schmidt sense\footnote{Recall that the Hilbert--Schmidt product \((A|B)\) of two operators \(A\) and \(B\) is defined by \((A|B)=\frac12\operatorname{tr}A^\dagger B\).}) of the corresponding Kraus operators, \(E_k\) and \(E_l\).
In order to see this, we write \(\langle\widetilde{v}_k|\widetilde{v}_l\rangle\) as
\[
  \begin{aligned}
    \braket{\widetilde{v}_k |\widetilde{v}_l}
    &= \langle\Omega|(\mathbf{1}\otimes E_k^\dagger)(\mathbf{1}\otimes E_l)|\Omega\rangle
  \\&= \operatorname{tr}(\mathbf{1}\otimes E_k^\dagger E_l)|\Omega\rangle\langle\Omega|
  \\&= \frac{1}{d}\operatorname{tr}\sum_{ij}|i\rangle\langle j|\otimes E_k^\dagger E_l |i\rangle\langle j|
  \end{aligned}
\]
(using the fact that we can substitute \(\frac{1}{d}\sum_{ij}|i\rangle\langle j|\otimes|i\rangle\langle j|\) for \(|\Omega\rangle\langle\Omega|\)).
Now, the trace of the tensor product of two matrices is the product of their traces, hence
\[
  \begin{aligned}
    \langle\widetilde{v}_k|\widetilde{v}_l\rangle
    &= \frac{1}{d}\sum_{ij} \langle i|j\rangle\operatorname{tr}E_k^\dagger E_l |i\rangle\langle j|
  \\&= \frac{1}{d} \operatorname{tr}E_k^\dagger E_l
  \end{aligned}
\]
(using the fact that \(\langle i|j\rangle=\delta_{ij}\) and \(\sum_i|i\rangle\langle i|=\mathbf{1}\)).
In summary then, \emph{\(\langle\widetilde{v}_k|\widetilde{v}_l\rangle=0\) implies that \(\operatorname{tr}E_k^\dagger E_l=0\)}.

\begin{idea}

A linear map \(\mathcal{E}\colon\mathcal{B}(\mathcal{H})\to\mathcal{B}(\mathcal{H}')\) is completely positive if and only if it admits an operator-sum decomposition of the form
\[
  \mathcal{E}(\rho) = \sum_k E_k\rho E^\dagger_k.
\]

If this is the case, then this decomposition has the following properties:

\begin{itemize}
\tightlist
\item
  \(\mathcal{E}\) is trace preserving if and only if \(\sum_k E^\dagger_kE_k=\mathbf{1}\).
\item
  Two sets of Kraus operators \(\{E_k\}\) and \(\{F_l\}\) represent the same map \(\mathcal{E}\) if and only if there exists a unitary \(R\) such that \(E_k =\sum_l R_{kl}F_l\) (where the smaller set of the Kraus operators is padded with zeros, if necessary).
\end{itemize}


\end{idea}

Note that, for \emph{any} \(\mathcal{E}\colon\mathcal{B}(\mathcal{H})\to\mathcal{B}(\mathcal{H}')\), there always exists a representation with \emph{at most} \(dd'\) mutually orthogonal Kraus operators: \(\operatorname{tr}E^\dagger_iE_j\propto\delta_{ij}\).

\hypertarget{correctable-channels}{%
\subsection{Correctable channels}\label{correctable-channels}}

Another question that we might ask ourselves is if we can \emph{reverse the action of a quantum channel, recovering the input state}.
Let us first make precise what we mean by this.

\begin{idea}
We say that a quantum channel \(\mathcal{E}\colon\mathcal{B}(\mathcal{H})\to\mathcal{B}(\mathcal{H}')\) is \textbf{correctable} if there exists a \textbf{recovery channel} \(\mathcal{R}\colon\mathcal{B}(\mathcal{H}')\to\mathcal{B}(\mathcal{H})\) such that the composition \(\mathcal{R}\circ\mathcal{E}\) is the identity channel.

\end{idea}

The action of any unitary operation \(U\) can, of course, be reversed by simply applying the inverse operation, \(U^\dagger\);
the same holds for any isometry \(V\), because \(V^\dagger V=\mathbf{1}\).
For example, the process of first adding an auxiliary system in a fixed state and then applying a unitary \(U\) to the composite system can be reversed by first applying \(U^\dagger\) to the composed system and then discarding the auxiliary system.
So how about a statistical mixture of unitaries?
Or, in general, a statistical mixture of isometries?

If all we know is that an isometry \(V_i\) is chosen randomly according to some distribution \(\{p_i\}_{i\in I}\), then the best we can do in an attempt to reverse the random process is to apply \(V_k^\dagger\), where \(k\in I\) is such that \(p_k\) is the largest of all the \(p_i\).
Clearly, this approach succeeds in reversing the action of the channel with probability \(p_k\).
However, if there were a way to determine, post factum, which particular isometry was chosen, then, of course, we could perfectly reverse the action of the channel.

Consider a channel \(\mathcal{E}\colon\mathcal{B}(\mathcal{H})\to\mathcal{B}(\mathcal{H}')\) given by
\[
  \mathcal{E}\colon\rho
  \longmapsto \rho'
  =\sum_i p_i V_i\rho V^\dagger_i
\]
in which the isometries \(V_i\) are mutually orthogonal (i.e.~\(V_i^\dagger V_j =\delta_{ij}\mathbf{1}\)).
Let \(\mathcal{H}'_i\) be the image of \(\mathcal{H}\) under \(V_i\);
these images are subspaces in \(\mathcal{H}'\), and they are mutually orthogonal. Indeed, for any vector \(|v\rangle\) in \(\mathcal{H}\), the vectors \(V_i|v\rangle\in \mathcal{H}'_i\) and \(V_j|v\rangle\in \mathcal{H}'_j\) are orthogonal:
\[
  \langle v|V_i^\dagger V_j|v\rangle
  = \delta_{ij} \langle v|\mathbf{1}|v\rangle
  = \delta_{ij}.
\]
We can now perform a measurement defined by the projections onto these mutually orthogonal subspaces \(\mathcal{H}'_i\), and find out which particular isometry was chosen (and then perfectly reverse its action by applying the inverse isometry).

Note that, for a measurement on \(\mathcal{H}'\) to be well defined, we need to decompose \(\mathcal{H}'\) into mutually orthogonal subspaces.
That is, the direct sum \(\bigoplus_i\mathcal{H}'_i\) might not ``fill up'' the space \(\mathcal{H}'\), so we might need to pad out with whatever is ``left over'' in order to obtain the decomposition of the whole \(\mathcal{H}'\) into mutually orthogonal subspaces.
That extra subspace with which we pad out the direct sum is \emph{not} in the image of the channel: we will never see the result of the measurement corresponding to the projection onto that subspace.
However, we \emph{need} to add it in order to obtain a complete decomposition of \(\mathcal{H}'\).
Here the Kraus operators \(E_i=\sqrt{p_i}V_i\) satisfy
\[
  E^\dagger_i E_j
  = \sqrt{p_i p_j}\delta_{ij}\mathbf{1}
\]
but remember that \emph{the operator-sum decomposition is not unique}, and so the same channel can be described by another, unitarily related, set of Kraus operators, \(K_i = \sum_k U_{ik}E_k\), which then satisfy
\[
  \begin{aligned}
    K_i^\dagger K_j
    &= \sum_{kl} U^\star_{ik} E^\dagger_k E_l U_{jl}
  \\&= \sum_{kl} U^\star_{ik} (\sqrt{p_k p_l}\delta_{kl}\mathbf{1}) U_{jl}
  \\&= \sum_{k} U^\star_{ik} p_k U_{jk}\mathbf{1}
  \\&= \sigma_{ij}\mathbf{1}
  \end{aligned}
\]
where \(\sigma_{ij}\) are elements of a density matrix with eigenvalues \(p_i\).
If this condition is satisfied, then the action of the channel can be reversed, and the original state \(\rho\) can be recovered.

Conversely, if the channel \(\mathcal{E}\) is correctable, then the above condition above holds.
Indeed, in terms of Kraus representations for \(\mathcal{E}\) and \(\mathcal{R}\), we require that
\[
  \mathcal{R}\circ\mathcal{E}(\rho)
  = \sum_{lj} R_l E_j \rho R^\dagger_l E^\dagger_j
  = \rho
\]
for any state \(\rho\).
This means that identity channel \(\mathcal{R}\circ\mathcal{E}=\mathbf{1}\) must have all the Kraus operators proportional to the identity:
\[
  R_lE_j=\lambda_{lj}\mathbf{1}
\]
for some complex numbers \(\lambda_{lj}\) such that\footnote{This is the normalisation condition for the Kraus operators \(R_lE_j\)} \(\sum_{lj} |\lambda_{lj}|^2=1\).
Then we can write
\[
  \begin{aligned}
    \sum_l E_i^\dagger R_l^\dagger R_l E_j
    &= E_i^\dagger E_j
  \\&=\sum_l \lambda^*_{il}\lambda_{jl}\mathbf{1}
  \\&=\sigma_{ij}\mathbf{1}
  \end{aligned}
\]
where \(\sigma_{ij} = \sum_l \lambda^*_{il}\lambda_{jl}\).
Clearly, \(\sigma_{ij}\) is a positive matrix such that \(\operatorname{tr}(\sigma_{ij})=1\) and \(\sum_i\sigma_{ii}=\sum_{il}|\lambda_{il}|^2=1\).
So the condition \(E_i^\dagger E_j = \sigma_{ij}\mathbf{1}\) is both necessary \emph{and} sufficient in order for the channel \(\mathcal{E}\) to be correctable.
In summary:

\begin{idea}

Let \(\mathcal{E}\colon\mathcal{B}(\mathcal{H})\to\mathcal{B}(\mathcal{H}')\) be a quantum channel with Kraus decomposition \(\mathcal{E}(\rho)=\sum_i E_i\rho E^\dagger_i\).
Then the following statements are equivalent:

\begin{enumerate}
\def\labelenumi{\roman{enumi}.}
\tightlist
\item
  \(\mathcal{E}\) is correctable;
\item
  \(E_i^\dagger E_j = \sigma_{ij}\mathbf{1}\) for some density matrix \(\sigma_{ij}\);
\item
  there exists a set of orthogonal isometries \(\{V_i\}\) and a probability distribution \(\{p_i\}\) such that
  \[
      \mathcal{E} (\rho) = \sum_i p_i V_i\rho V^\dagger_i
      \]
  for every state \(\rho\).
\end{enumerate}


\end{idea}

\hypertarget{appendices-1}{%
\subsection{\texorpdfstring{\emph{Appendices}}{Appendices}}\label{appendices-1}}

\hypertarget{isometries}{%
\subsubsection{Isometries}\label{isometries}}

In many applications, including quantum communication and quantum error correction, it is useful to encode a quantum state of one system into a quantum state of a larger system.
Such operations are described by \emph{isometries}.\footnote{The word isometric (like pretty much most of the fancy words you come across in this course) comes from Greek, meaning ``of the same measures'': \emph{isos} means ``equal'', and \emph{metron} means ``a measure'', and so an ``isometry'' is a transformation that preserves distances.}
You may think about isometries as a generalisation of unitaries: like unitaries, they preserve inner products; unlike unitaries, they are maps between spaces of \emph{different} dimensions.

\begin{idea}
Let \(\mathcal{H}\) and \(\mathcal{H}'\) be Hilbert spaces such that \(\dim\mathcal{H}\leqslant\dim\mathcal{H}'\).
An \textbf{isometry} is a linear map \(V\colon\mathcal{H}\to\mathcal{H}'\) such that \(V^\dagger V=\mathbf{1}_{\mathcal{H}}\)

Isometries preserve inner products, and therefore also the norm and the metric induced by the norm.

\end{idea}

An isometry \(V\colon\mathcal{H}\to\mathcal{H}'\) maps the \emph{whole} Hilbert space \(\mathcal{H}\) onto a \emph{subspace} of \(\mathcal{H}'\).
As a consequence, the matrix representation of an isometry is a rectangular matrix formed by selecting only a few of the columns from a unitary matrix.
For example, given a unitary \(U\) we can construct an isometry \(V\) as follows:

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-58-1} \end{center}

The fact that an isometry \(V\) preserves the inner products comes from the fact that we require \(V^\dagger V=\mathbf{1}_{\mathcal{H}}\);
we do \emph{not} require \(VV^\dagger=\mathbf{1}_{\mathcal{H'}}\).
Indeed, if we required both of these, then that would be equivalent to asking for \(V\) to be \emph{unitary}.
The operator \(VV^\dagger\) is a projector operator acting on \(\mathcal{H}'\), which projects onto the image of \(\mathcal{H}\) under the isometry \(V\), as we can see by expressing the \(V\) in Dirac notation:
\[
  V = \sum_i |b_i\rangle\langle a_i|,
\]
where the \(|a_i\rangle\) form an orthonormal basis in \(\mathcal{H}\), and the \(|b_i\rangle\) are just orthonormal vectors in \(\mathcal{H}'\);
in the special case where \(V\) is unitary, the orthonormal vectors \(|b_i\rangle\) form an orthonormal basis in \(\mathcal{H}'\).
Writing \(V\) in this form, it is clear that \(V^\dagger V=\sum_i |a_i\rangle\langle a_i|=\mathbf{1}\), and that \(VV^\dagger = \sum_i |b_i\rangle\langle b_i|\) projects on the subspace spanned by \(|b_i\rangle\).

The reason that we care about this more general notion of isometry (instead of specifically unitaries) is that \emph{isometries represent physically admissible operations}: they can be implemented by bringing two systems together (via tensoring) and then applying unitary transformations to the composite system.
That is, take some system \(\mathcal{A}\) in state \(|\psi\rangle\), and bring in another system \(\mathcal{B}\) in some fixed state \(|b\rangle\);
applying some unitary \(U\) to the combined system \(\mathcal{A}\mathcal{B}\) then gives an isometry from \(\mathcal{H}=\mathcal{H}_\mathcal{A}\) to \(\mathcal{H}'=\mathcal{H}_\mathcal{A}\otimes\mathcal{H}_\mathcal{B}\), i.e.~the result is a linear map \(V\) defined by
\[
  V\colon
  |\psi\rangle
  \longmapsto
  |\psi\rangle|b\rangle
  \longmapsto
  U(|\psi\rangle|b\rangle
\]
for any vector \(|\psi\rangle\in\mathcal{H}_\mathcal{A}\).

Any isometry is a quantum channel, since any quantum state described by the state vector \(|\psi\rangle\) (or by a density operator \(\rho\)) is transformed as
\[
  |\psi\rangle\longmapsto V|\psi\rangle
\]
(or as \(\rho\mapsto V\rho V^\dagger\)), and the normalisation condition is exactly the defining property of isometries:
\[
  V^\dagger V =\mathbf{1}.
\]

An example which we will later return to is that of the \textbf{three-qubit code}.
Take a qubit in some pure state \(|\psi\rangle=\alpha|0\rangle+\beta|1\rangle\), introduce two auxiliary qubits in a fixed state \(|0\rangle|0\rangle\), and apply a unitary operation to the three qubits, namely two controlled-\(\texttt{NOT}\) gates:

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-59-1} \end{center}

The result is the isometric embedding of the \(2\)-dimensional Hilbert space of the first qubit (spanned by \(|0\rangle\) and \(|1\rangle\)) into the \(2\)-dimensional subspace (spanned by \(|000\rangle\) and \(|111\rangle\)) of the \(8\)-dimensional Hilbert space of the three qubits.
The isometric operator
\[
  V = |000\rangle\langle 0| + |111\rangle\langle 1|
\]
acts via
\[
  \alpha|0\rangle+\beta|1\rangle
  \longmapsto \alpha|000\rangle+\beta|111\rangle.
\]
This three qubit-encoding can be reversed by the mirror image circuit:

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-60-1} \end{center}

\hypertarget{markov-approximation}{%
\subsubsection{The Markov approximation}\label{markov-approximation}}

Composition of quantum channels\footnote{Unitary evolutions form a group; quantum channels form a semigroup. Quantum operations are invertible only if they are either unitary operations or simple isometric embeddings (such as the process of bringing in the environment in some fixed state and then \emph{immediately} discarding it, without any intermediate interaction).} in the Kraus representation is rather straightforward, but do not be deceived by its mathematical simplicity!
We must remember that \emph{quantum channels do not capture all possible quantum evolutions}: the assumption that the system and the environment are \emph{not initially correlated} is crucial, and it does impose some restrictions on the applicability of our formalism.
Compare, for example, the following two scenarios.

Firstly:

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-61-1} \end{center}

Here the system, initially in state \(\rho\), undergoes two stages of evolution, and the environment is \emph{not} discarded after the first unitary evolution \(U_A\); the environment persists and participates in the second unitary evolution \(U_B\).
In this case the evolutions \(\rho\mapsto\rho'\) and \(\rho\mapsto\rho''\) are both well defined quantum channels, but the evolution \(\rho'\mapsto\rho''\) is \emph{not}: it falls outside the remit of our formalism because the input state of the system and the state of the environment are \emph{not independent}.

Secondly:

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-62-1} \end{center}

Here we have two stages of evolution, as before, but we \emph{discard} the environment after the first unitary, and start the second unitary evolution in a fresh tensor-product state, with a \emph{new} environment;
the two stages involve \emph{independent environments}.
In this case\footnote{A \textbf{quantum Markov process}! \href{https://en.wikipedia.org/wiki/Andrey_Markov}{Andrey Markov} (1929--2012) was a Russian mathematician best known for his work on stochastic processes.} all three evolutions (\(\rho\mapsto\rho'\), \(\rho'\mapsto\rho''\), and \(\rho\mapsto\rho''\)) are well defined quantum channels, and they compose: if \(\mathcal{E}_\mathcal{A}\) describes the evolution from \(\rho\) to \(\rho'\), and \(\mathcal{E}_\mathcal{B}\) from \(\rho'\) to \(\rho''\), then the composition \(\mathcal{E}_\mathcal{B}\circ\mathcal{E}_\mathcal{A}\) describes the evolution from \(\rho\) to \(\rho''\).

In practice we often deal with complex environments that have internal dynamics that ``hides'' any entanglement with the system as quickly as it arises.
For example, suppose that our system is an atom, surrounded by the electromagnetic field (which serves as the environment).
Let the field start in the vacuum state.
If the atom emits a photon into the environment, then the photon quickly propagates away, and the immediate vicinity of the atom appears to be empty, i.e.~resets to the vacuum state.
In this approximate model, we assume that the environment quickly forgets about the state resulting from any previous evolution.
This is known as the \textbf{Markov approximation};
in a quantum Markov process the environment has essentially no memory.

\hypertarget{what-use-are-positive-maps}{%
\subsubsection{What use are positive maps?}\label{what-use-are-positive-maps}}

Positive maps that are not completely positive are not completely useless.
True, they cannot describe any quantum dynamics, but still they have useful applications --- for example, they can help us to determine if a given state is entangled or not.

Recall: a quantum state of a bipartite system \(\mathcal{AB}\) described by the density matrix \(\varrho^{\mathcal{AB}}\) is said to be \textbf{separable} if \(\varrho^{\mathcal{AB}}\) is of the form
\[
  \varrho^{\mathcal{AB}}
  = \sum_k p_k \rho^{\mathcal{A}}_k \otimes\rho^{\mathcal{B}}_k
\]
where \(p_k \geqslant 0\) and \(\sum_{k=1} p_k=1\); otherwise \(\varrho^{\mathcal{AB}}\) is said to be \textbf{entangled}.
If we apply the partial transpose \(\mathbf{1}\otimes T\) to this state, then it remains separable, since, as we have seen, the transpose \(\rho^B\) is a legal density matrix.

\begin{idea}
Positive maps, such as the transpose, can be quite deceptive: you have to include other systems in order to detect their unphysical character.

\end{idea}

In separable states, one subsystem does not really know about the existence of the other, and so applying a positive map to one part produces a proper density operator, and thus does \emph{not} reveal the unphysical character of the map.
So, for \emph{any separable state} \(\rho\), we have \((\mathbf{1}\otimes T)\rho\geqslant 0\).

As an example, consider a quantum state of two qubits which is a mixture of the maximally entangled state \(|\psi\rangle = \frac{1}{\sqrt 2}(|00\rangle + |11\rangle)\) and the maximally mixed state described by the density matrix
\[
  \rho_p
  = p|\psi\rangle\langle\psi| + \frac{(1-p)}{4}\mathbf{1}\otimes\mathbf{1},
\]
where \(p\in [0,1]\).
If we apply the partial transpose \(\mathbf{1}\otimes T\) to this state, and check for which values of \(p\) the resulting matrix is a density matrix, we see that, for all \(p\in[\frac{1}{3},1]\), the density operator \(\rho\) describes an entangled state.

Note that the implication ``if separable then the partial transpose is positive'' does not imply the converse: there exist entangled states for which the partial transpose is positive, and they are known as the \textbf{entangled PPT states}\footnote{``PPT'' stands for \emph{positive partial transpose}.}
However, for \emph{two} qubits, the PPT states are exactly the separable states.

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-63-1} \end{center}

\hypertarget{choi-jamiolkowski}{%
\subsubsection{The Choi--Jamiołkowski isomorphism}\label{choi-jamiolkowski}}

The correspondence between linear maps \(\mathscr{B}(\mathcal{H})\to\mathscr{B}(\mathcal{H'})\) and operators in \(\mathscr{B}(\mathcal{H}\otimes\mathcal{H'})\), known as the \textbf{Choi--Jamiołkowski isomorphism} or \textbf{channel--state duality}, is another example of a well known correspondence between vectors in \(\mathcal{H}_{\mathcal{A}}\otimes\mathcal{H}_{\mathcal{B}}\) and operators \(\mathscr{B}(\mathcal{H}_{\mathcal{A}}^\star,\mathcal{H}_{\mathcal{B}})\) or \(\mathscr{B}(\mathcal{H}_{\mathcal{B}}^\star,\mathcal{H}_{\mathcal{A}})\).

It is slightly confusing at first, but the \textbf{Choi isomorphism}, the \textbf{Jamiołkowski isomorphism}, and the \textbf{Choi--Jamiołkowski} isomorphism are really three distinct things:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \href{https://en.wikipedia.org/wiki/Choi\%27s_theorem_on_completely_positive_maps}{the first} is very nice, but non-canonical (i.e.~is dependent on the choice of basis);
\item
  the second (for which I have no nice citation, but is basically given by considering \(\sum|j\rangle\langle i|\otimes\mathcal{E}(|i\rangle\langle j|)\) instead of \(\sum|i\rangle\langle j|\otimes\mathcal{E}(|i\rangle\langle j|)\)) is canonical, but doesn't always map CP maps to positive semidefinite matrices;
\item
  \href{https://en.wikipedia.org/wiki/Choi\%E2\%80\%93Jamio\%C5\%82kowski_isomorphism}{the third} brings together the two similar, but distinct, results by the respective authors. However, people often say ``Choi--Jamiołkowski'' to mean any one of the three. Such is life.
\end{enumerate}

Take a tensor product vector in \(|a\rangle\otimes|b\rangle\in \mathcal{H}_{\mathcal{A}}\otimes\mathcal{H}_{\mathcal{B}}\).
Then it defines natural maps in \(\mathscr{B}(\mathcal{H}_{\mathcal{A}}^\star,\mathcal{H}_{\mathcal{B}})\) and \(\mathscr{B}(\mathcal{H}_{\mathcal{B}}^\star,\mathcal{H}_{\mathcal{A}})\), via
\[
  \begin{aligned}
    \langle x|
    &\longmapsto \langle x|a\rangle|b\rangle
  \\\langle y|
    &\longmapsto |a\rangle\langle y|b\rangle
  \end{aligned}
\]
for any linear forms \(\langle x|\in\mathcal{H}^\star_A\) and \(\langle y|\in\mathcal{H}^\star_B\).
We then extend this construction (by linearity) to any vector in \(\mathcal{H}_{\mathcal{A}}\otimes\mathcal{H}_{\mathcal{B}}\).
These isomorphisms are \textbf{canonical}: they do not depend on the choice of any bases in the vectors spaces involved.

However, some care must be taken when we want to define correspondence between vectors in \(\mathcal{H}_{\mathcal{A}}\otimes\mathcal{H}_{\mathcal{B}}\) and operators in \(\mathscr{B}(\mathcal{H}_{\mathcal{A}},\mathcal{H}_{\mathcal{B}})\) or \(\mathscr{B}(\mathcal{H}_{\mathcal{B}},\mathcal{H}_{\mathcal{A}})\).
For example, physicists like to ``construct'' \(\mathscr{B}(\mathcal{H}_{\mathcal{B}},\mathcal{H}_{\mathcal{A}})\) in a deceptively simple way:
\[
  |a\rangle|b\rangle \longleftrightarrow |a\rangle\langle b|.
\]
(where we have simply omitted the tensor product symbol).
Flipping \(|b\rangle\) and switching from \(\mathcal{H}_{\mathcal{B}}\) to \(\mathcal{H}^\star_B\) is an \emph{anti-linear} operation (since it involves complex conjugation).
This is fine \emph{when we stick to a specific basis \(|i\rangle|j\rangle\) and use the ket-flipping approach only for the basis vectors}.
This means that, for \(|b\rangle=\sum_j\beta_j|j\rangle\), the correspondence looks like
\[
  |i\rangle|b\rangle \longleftrightarrow \sum_j \beta_j |i\rangle\langle j|
\]
and \emph{not} like
\[
  |i\rangle|b\rangle \longleftrightarrow |i\rangle\langle b|
  = \sum_j \beta^\star_j |i\rangle\langle j|.
\]
This isomorphism is \textbf{non-canonical}: it depends on the choice of the basis.
But it is still a pretty useful isomorphism!
The Choi--Jamiołkowski isomorphism is of this kind (i.e.~non-canonical) --- it works in the basis in which you express a maximally entangled state \(|\Omega\rangle=\sum_i|i\rangle|i\rangle\).

\hypertarget{block-matrices-and-partial-trace}{%
\subsubsection{Block matrices and partial trace}\label{block-matrices-and-partial-trace}}

For any matrix \(M\) in \(\mathcal{H}_{\mathcal{A}}\otimes\mathcal{H}_{\mathcal{B}}\) \emph{that is written in the tensor product basis}, the partial trace over the first subsystem (here \(\mathcal{A}\)) is the sum of the diagonal block matrices, and the partial trace over the second subsystem (here \(\mathcal{B}\)) is a matrix in which the block sub-matrices are replaced by their traces.
You can visualise this as in Figure \ref{fig:visualising-partial-trace}.



\begin{figure}[H]

{\centering \includegraphics{iqis-book_files/figure-latex/visualising-partial-trace-1} 

}

\caption{Visualising the two partial traces of a matrix \emph{written in the tensor product basis}.}\label{fig:visualising-partial-trace}
\end{figure}

For example, for any \(M\) in the tensor product space associated with two qubits, written in the standard basis \(\{|00\rangle,|01\rangle,|10\rangle,|11\rangle\}\) in block form as
\[
  M =
  \left[
    \begin{array}{c|c}
      P & Q
    \\\hline
      R & S
    \end{array}
  \right]
\]
where \(P\), \(Q\), \(R\), and \(S\) are all \((2\times 2)\) sized sub-matrices, we have that
\[
  \begin{aligned}
    \operatorname{tr}_{\mathcal{A}} M
    &= P+S
  \\\operatorname{tr}_{\mathcal{B}} M
    &=
  \left[
    \begin{array}{c|c}
      \operatorname{tr}P & \operatorname{tr}Q
    \\\hline
      \operatorname{tr}R & \operatorname{tr}S
    \end{array}
  \right]
  \end{aligned}
\]

The same holds for general \(M\) in any \(\mathcal{H}_{\mathcal{A}}\otimes\mathcal{H}_{\mathcal{B}}\) with such a block form (i.e.~\(m\times m\) blocks of \((n\times n)\) sized sub-matrices, where \(m=\dim\mathcal{H}_{\mathcal{A}}\) and \(n=\dim\mathcal{H}_{\mathcal{B}}\)).

\hypertarget{remarks-and-exercises-7}{%
\subsection{\texorpdfstring{\emph{Remarks and exercises}}{Remarks and exercises}}\label{remarks-and-exercises-7}}

\hypertarget{partial-inner-product}{%
\subsubsection{Partial inner product}\label{partial-inner-product}}

The tensor product structure brings with it the possibility to do ``partial things'' beyond just the partial trace.
Given \(\mathcal{H}_{\mathcal{A}}\otimes\mathcal{H}_{\mathcal{B}}\), any vector \(|x\rangle\in\mathcal{H}_{\mathcal{A}}\) defines an anti-linear map \(\mathcal{H}_{\mathcal{A}}\otimes\mathcal{H}_{\mathcal{B}}\to\mathcal{H}_{\mathcal{B}}\) called the \textbf{partial inner product with \(|x\rangle\).}
It is first defined on the product vectors \(|a\rangle\otimes|b\rangle\) by the formula
\[
  |a\rangle\otimes|b\rangle
  \longmapsto \langle x|a\rangle|b\rangle
\]
and then extended to other vectors in \(\mathcal{H}_{\mathcal{A}}\otimes\mathcal{H}_{\mathcal{B}}\) by linearity.
Similarly, any \(|y\rangle\in\mathcal{H}_{\mathcal{B}}\) defines a map \(\mathcal{H}_{\mathcal{A}}\otimes\mathcal{H}_{\mathcal{B}}\to\mathcal{H}_{\mathcal{A}}\) via
\[
  |a\rangle\otimes|b\rangle
  \longmapsto |a\rangle\langle y|b\rangle
\]

For example, the partial inner product of
\[
  |\psi\rangle=c_{00}|00\rangle+c_{01}|01\rangle+c_{10}|10\rangle+c_{11}|11\rangle\in\mathcal{H}_{\mathcal{A}}\otimes\mathcal{H}_{\mathcal{B}}
\]
with of \(|0\rangle\in\mathcal{H}_{\mathcal{A}}\) is
\[
  \langle 0|\psi\rangle = c_{00}|0\rangle + c_{01}|1\rangle
\]
and the partial inner product of the same \(|\psi\rangle\) with \(|1\rangle\in\mathcal{H}_{\mathcal{B}}\) is
\[
  \langle 1|\psi\rangle = c_{01}|0\rangle + c_{11}|1\rangle.
\]

\hypertarget{control-controlled-NOT}{%
\subsubsection{The ``control'' part of controlled-NOT}\label{control-controlled-NOT}}

Consider a single-qubit channel induced by the action of the \(\texttt{c-NOT}\) gate.
Recall that the unitary operator associated with the \(\texttt{c-NOT}\) gate can be written as
\[
  U = |0\rangle\langle 0|\otimes\mathbf{1}+ |1\rangle\langle 1|\otimes X
\]
where is \(X\) is the Pauli \(\sigma_x\) gate (i.e.~the \(\texttt{NOT}\) gate).
Let us step through the following simple circuit:

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-64-1} \end{center}

This time we are interested in the evolution of the control qubit: the control qubit will be our system, and the target qubit, initially in a fixed state \(|0\rangle\), will play the role of an ancilla.

We can calculate the Kraus operators
\[
  A_i = (\mathbf{1}\otimes\langle i|) U (\mathbf{1}\otimes|0\rangle)
\]
which we simply write as \(A_i=\langle i|U|0\rangle\), for \(i=0,1\).
We see that
\[
  \begin{aligned}
    A_i = \langle i|U|0\rangle
    &= \langle i| (|0\rangle\langle 0|\otimes\mathbf{1}+ |1\rangle\langle 1|\otimes X) |0\rangle
  \\&= |0\rangle\langle 0|\langle i|\mathbf{1}|0\rangle + |1\rangle\langle 1|\langle i|X|0\rangle
  \\&= |i\rangle\langle i|
\end{aligned}
\]
We can also check the normalisation condition:
\[
  A_0^\dagger A_0 + A_1^\dagger A_1
  = |0\rangle\langle 0| + |1\rangle\langle 1|
  =\mathbf{1}.
\]

The unitary action of the gate when the state of the target qubit is fixed at \(|0\rangle\) can be written as
\[
  \begin{aligned}
    |\psi\rangle|0\rangle
    \longmapsto
    & A_0|\psi\rangle|0\rangle + A_1|\psi\rangle|1\rangle
  \\=& |0\rangle\langle 0||\psi\rangle|0\rangle + |1\rangle\langle 1||\psi\rangle|1\rangle
  \\=& \langle 0|\psi||\rangle 0\rangle|0\rangle + \langle 1|\psi||\rangle 1\rangle|1\rangle
  \end{aligned}
\]
which is a familiar \(\texttt{c-NOT}\) entangling process: if \(|\psi\rangle=\alpha_0|0\rangle+\alpha_1|1\rangle\) then \(|\psi\rangle|0\rangle\) becomes \(\alpha_0|0\rangle|0\rangle+\alpha_1|1\rangle|1\rangle\).

The evolution of the control qubit alone can be expressed in the Kraus form as
\[
  \begin{aligned}
    \rho \longmapsto \rho'
    &= A_0\rho A_0^\dagger + A_1\rho A_1^\dagger
  \\&= |0\rangle\langle 0|\rho|0\rangle\langle 0| + |1\rangle\langle 1|\rho|1\rangle\langle 1|
  \\&= \rho_{00}|0\rangle\langle 0| + \rho_{11}|1\rangle\langle 1|.
  \end{aligned}
\]
Then, in the matrix form, if the initial state of the control qubit is \(|\psi\rangle=\alpha_0|0\rangle+\alpha_1|1\rangle\), we get
\[
  \begin{bmatrix}
    |\alpha|_0^2 & \alpha_0\alpha_0^\star
  \\\alpha_0^\star\alpha_1 & |\alpha_1|^2
  \end{bmatrix}
  = \rho
  \longmapsto
  \rho' =
  \begin{bmatrix}
    |\alpha_0|^2 & 0
  \\0 & |\alpha_1|^2
  \end{bmatrix}.
\]

As we can see, the diagonal elements of \(\rho\) survive, and the off-diagonal elements (the \textbf{coherences}) disappear.
The two Kraus operators, \(A_0=|0\rangle\langle 0|\) and \(A_1=|1\rangle\langle 1|\), define the measurement in the standard basis, and so you may think about this operation as being equivalent to \emph{measuring the control qubit in the standard basis and then just forgetting the result}.

\hypertarget{surprisingly-identical-channels}{%
\subsubsection{Surprisingly identical channels}\label{surprisingly-identical-channels}}

Let us now compare two single qubit quantum channels: \(\mathcal{A}(\rho)=\sum_k A_k\rho A^\dagger_k\), defined by the Kraus operators
\[
  \begin{aligned}
    A_1 = |0\rangle\langle 0|
    &= \begin{bmatrix}1&0\\0&0\end{bmatrix}
  \\A_2 = |1\rangle\langle 1|
  &= \begin{bmatrix}0&0\\0&1\end{bmatrix}
  \end{aligned}
\]
and \(\mathcal{B}(\rho)=\sum_k B_k\rho B^\dagger_k\), defined by the Kraus operators
\[
  \begin{aligned}
    B_1 = \frac{\mathbf{1}}{\sqrt{2}}
    &= \frac{1}{\sqrt{2}}\begin{bmatrix}1&0\\0&1\end{bmatrix}
  \\B_2 = \frac{Z}{\sqrt{2}}
    &= \frac{1}{\sqrt{2}}\begin{bmatrix}1&0\\0&-1\end{bmatrix}.
  \end{aligned}
\]

We are familiar with the first channel from \protect\hyperlink{control-controlled-NOT}{the previous example}: it performs the measurement in the standard basis, but doesn't reveal the outcome of the measurement.
The second channel chooses randomly, with equal probability, between two options: it will either let the qubit pass undisturbed, or apply the phase-flip \(Z\).

These two apparently very different physical processes correspond to the same quantum channel: \(\mathcal{A}(\rho)=\mathcal{B}(\rho)\) for any \(\rho\).
Indeed, you can check that \(B_1=(A_1+A_2)/\sqrt{2}\) and \(B_2=(A_1-A_2)/\sqrt{2}\), whence
\[
  \begin{aligned}
    \mathcal{B}(\rho)
    &= B_1\rho B_1^\dagger + B_2\rho B_2^\dagger
  \\&= \frac{1}{2} (A_1+A_2)\rho (A_1+A_2)^\dagger + \frac{1}{2} (A_1-A_2)\rho (A_1-A_2)^\dagger
  \\&=  A_1\rho A_1^\dagger + A_2\rho A_2^\dagger
  \\&= \mathcal{A}(\rho).
  \end{aligned}
\]

You can also check that the two channels can be implemented by the following two circuits:



\begin{figure}[H]

{\centering \includegraphics{iqis-book_files/figure-latex/two-channels-1} 

}

\caption{The \(\texttt{c-NOT}\) gate appears here as the measurement gate. The target qubit measures the control qubit in the standard basis (operation \(\mathcal{A}\) on the left) or in the Hadamard basis (operation \(\mathcal{B}\) on the right). The extra Hadamard gate on the target qubit has no effect on the control qubit.}\label{fig:two-channels}
\end{figure}

\hypertarget{independent-ancilla}{%
\subsubsection{Independent ancilla}\label{independent-ancilla}}

Another way to understand the freedom in the operator-sum representation is to realise that, once the system and the ancilla cease to interact, any operation on the ancilla alone has no effect on the state of the system.



\begin{figure}[H]

{\centering \includegraphics{iqis-book_files/figure-latex/operators-sum-freedom-1} 

}

\caption{The quantum channel \(\rho\mapsto\rho'\) is not affected by the choice of a unitary \(R\), and so these two processes are the same.}\label{fig:operators-sum-freedom}
\end{figure}

That is, the two unitaries \(U\) and \((\mathbf{1}\otimes R)U\) (where \(R\) acts only on the ancilla) describe the same channel, even though the Kraus operators \(E_k=\langle e_k|U|e\rangle\) for the latter are
\[
  \begin{aligned}
    F_k
    &= \langle e_k|(\mathbf{1}\otimes R)U|e\rangle
  \\&= \sum_j \langle e_k|R|e_j\rangle\langle e_j|U|e\rangle
  \\&= \sum_j R_{kj}E_j
  \end{aligned}
\]
Indeed, the unitary evolution \((\mathbf{1}\otimes R) U\) gives
\[
  \rho\otimes|e\rangle\langle e|
  \longmapsto
  \sum_{kl} E_k \rho E_l^\dagger \otimes R|e_k\rangle\langle e_l| R^\dagger
\]
and the subsequent trace over the environment gives
\[
  \begin{aligned}
    \operatorname{tr}_E \sum_{kl} E_k \rho E_l^\dagger \otimes R|e_k\rangle\langle e_l| R^\dagger
    &= \sum_{kl} E_k \rho E_l^\dagger \langle e_l| R^\dagger R|e_k\rangle
  \\&= \sum_{k} E_k \rho E_k^\dagger.
  \end{aligned}
\]

\hypertarget{cooling-down}{%
\subsubsection{Cooling down}\label{cooling-down}}

We can show that the process of cooling a qubit to its ground state, described the map \(\mathcal{E}(\rho)=|0\rangle\langle 0|\), is a quantum channel.
Indeed, the set of Kraus operators is \(|0\rangle\langle 0|\) and \(|0\rangle\langle 1|\), and all Bloch vectors are mapped to the Bloch vector representing state \(|0\rangle\langle 0|\).

\hypertarget{unchanged-reduced-density-operator}{%
\subsubsection{Unchanged reduced density operator}\label{unchanged-reduced-density-operator}}

Show that, for any operator \(\rho\) on \(\mathcal{H}_\mathcal{A}\otimes\mathcal{H}_\mathcal{B}\), and, for any operator \(R\) on \(\mathcal{H}_\mathcal{B}\), we have
\[
  \operatorname{tr}_\mathcal{B} \left[(\mathbf{1}\otimes R) \rho (\mathbf{1}\otimes R^\dagger)\right]
  = \operatorname{tr}_\mathcal{B} \rho.
\]
That is, the reduced density operator \(\rho_\mathcal{A}=\operatorname{tr}_\mathcal{B} \rho\) is not affected by \(R\).

\emph{(Hint: show this for operators \(\rho\) which are tensor products \(\rho=A\otimes B\) and then extend the result to any operator \(\rho\).)}

\hypertarget{order-matters}{%
\subsubsection{Order matters?}\label{order-matters}}

We know that, given a fixed state of the environment, the unitaries \(U\) and \((\mathbf{1}\otimes R)U\) (where \(R\) acts only on the environment) define the same quantum channel.
Is the same true for \(U\) and \(U(\mathbf{1}\otimes R)\)?
That is, do these two unitaries define the same quantum channel as one another?

\hypertarget{pauli-twirl}{%
\subsubsection{Pauli twirl}\label{pauli-twirl}}

Show that randomly applying the Pauli operators \(\mathbf{1}\), \(X\), \(Y\), and \(Z\), with uniform probability, to any density operator \(\rho\) of a single qubit results in the maximally mixed state
\[
  \frac{1}{4} \mathbf{1}\rho\mathbf{1}+\frac{1}{4} X\rho X + \frac{1}{4} Y\rho Y + \frac{1}{4} X\rho Z
  = \frac{1}{2}\mathbf{1}.
\]

\hypertarget{depolarising-channel}{%
\subsubsection{Depolarising channel}\label{depolarising-channel}}

The most ``popular'' Pauli channel is the \textbf{depolarising channel}
\[
  \rho\longmapsto (1-p)\rho + \frac{p}{3}\left(X\rho X+Y\rho Y+Z\rho Z\right).
\]
In the depolarising channel, a qubit in state \(\rho\) remains intact with probability \(1-p\), or is otherwise transformed with one of the Pauli operators \(X\), \(Y\), and \(Z\), each chosen randomly with probability \(p/3\).
Show, using the \protect\hyperlink{puali-twirl}{Pauli twirl} or otherwise, that we can rewrite the depolarising channel as
\[
  \rho \longmapsto \rho'
  = \left(1-\frac{4}{3} p\right) \rho + \frac{4}{3}p\frac{1}{2}\mathbf{1}.
\]

(For \(p\leqslant\frac{3}{4}\) we can thus say that the channel either does nothing or, with probability \(\frac{4}{3}p\), throws away the initial quantum state and replaces it by the maximally mixed state.)

\hypertarget{depolarising-channel-and-the-bloch-sphere}{%
\subsubsection{Depolarising channel and the Bloch sphere}\label{depolarising-channel-and-the-bloch-sphere}}

It is also instructive to see how the depolarising channel acts on the Bloch sphere.
An arbitrary density matrix for a single qubit can be written as
\[
  \frac{1}{2}(\mathbf{1}+\vec{s}\cdot\vec{\sigma}),
\]
where \(\vec{s}\) is the Bloch vector, and \(\vec{\sigma}=(\sigma_x,\sigma_y,\sigma_z)\) is the vector of Pauli matrices.
The depolarising channel maps this state to
\[
  \frac{1}{2}\left[
    \mathbf{1}+ \left(1-\frac{4}{3}p\right)\vec{s}\cdot\vec{\sigma}
  \right].
\]
The Bloch vector shrinks by a factor of \(1-\frac{4}{3}p\).
This means that, for \(p\leqslant\frac{3}{4}\), the Bloch sphere contracts uniformly under the action of the channel;
for \(p=\frac{3}{4}\), the sphere is contracted to a single point at its centre;
and for \(\frac{3}{4}\leqslant p\leqslant 1\), the Bloch vector is flipped, and starts pointing in the opposite direction.

\hypertarget{complete-positivity-of-a-certain-map}{%
\subsubsection{Complete positivity of a certain map}\label{complete-positivity-of-a-certain-map}}

Let \(\mathcal{E}\) be the linear map on single a qubit defined by
\[
  \begin{aligned}
    \mathcal{E}(\mathbf{1})
    &= \mathbf{1}
  \\\mathcal{E}(\sigma_x)
    &= a_x\sigma_x
  \\\mathcal{E}(\sigma_y)
    &= a_y\sigma_y
  \\\mathcal{E}(\sigma_z)
    &= a_z\sigma_z
  \end{aligned}
\]
where \(a_x\), \(a_y\), and \(a_z\) are some fixed real numbers.
Using the Choi matrix of \(\mathcal{E}\), determine the range of \(x\), \(y\), \(z\) for which the map \(\mathcal{E}\) is \emph{positive}, and the range for which it is \emph{completely positive}.

\hypertarget{toffoli-gate}{%
\subsubsection{Toffoli gate}\label{toffoli-gate}}

Consider the Toffoli gate

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-65-1} \end{center}

Express \(\rho'\) as a function of \(\rho\) in the Kraus representation.

\hypertarget{duals}{%
\subsubsection{Duals}\label{duals}}

We say that \(\mathcal{E}^\star\colon\mathcal{B}(\mathcal{H})\to\mathcal{B}(\mathcal{H}')\) is the \textbf{dual} of a linear map \(\mathcal{E}\colon\mathcal{B}(\mathcal{H})\to\mathcal{B}(\mathcal{H}')\) if
\[
  \operatorname{tr}\mathcal{E}^\star (X)Y = \operatorname{tr}X\mathcal{E}(Y)
\]
for any operators \(X\) and \(Y\) in \(\mathcal{B}(\mathcal{H})\).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Show that, if \(\mathcal{E}\) is trace preserving, then \(\mathcal{E}^\star\) is unital.
\item
  Show that, if \(\mathcal{E}=\sum_i E_i\cdot E_i^\dagger\), then \(\sum_i E^\dagger_i\cdot E_i\) is an operator-sum decomposition of \(\mathcal{E}^\star\).
\end{enumerate}

\hypertarget{trace-transpose-choi}{%
\subsubsection{Trace, transpose, Choi}\label{trace-transpose-choi}}

Let \(\mathcal{E}\colon\mathcal{B}(\mathcal{H})\to\mathcal{B}(\mathcal{H}')\), and let \(d=\dim\mathcal{H}\) and \(d'=\dim\mathcal{H}'\).
Show that, for any \((d\times d)\) matrix \(X\) and any \((d'\times d')\) matrix \(Y\),
\[
  \operatorname{tr}\mathcal{E}(X)Y
  = \operatorname{tr}\widetilde{\mathcal{E}} (X^T\otimes Y).
\]

(For example, if we are interested in the component \(\mathcal{E}(X)_{ij}=\langle i|\mathcal{E}(X)|j\rangle\), then we can take \(Y=|j\rangle\langle i|\).)

\hypertarget{purifications-and-isometries}{%
\subsubsection{Purifications and isometries}\label{purifications-and-isometries}}

All purifications of a density operator are related by an isometry acting on the purifying system.
That is, if \(\rho\) is a density operator on \(\mathcal{H}\), and \(|\psi_A\rangle\in \mathcal{H}\otimes\mathcal{H}_\mathcal{A}\) and \(|\psi_B\rangle\in\mathcal{H}\otimes\mathcal{H}_B\) (\(\dim\mathcal{H}_\mathcal{A}\leqslant\dim\mathcal{H}_\mathcal{B}\)) are two purifications of \(\rho\), then
\[
  |\psi_B\rangle=(\mathbf{1}\otimes V)|\psi_A\rangle.
\]

To show this, we start with the spectral decomposition of \(\rho\)
\[
  \rho = \sum_i p_i|i\rangle\langle i|
\]
and note that
\[
  \begin{aligned}
    |\psi_A\rangle
    &= \sum_i \sqrt{p_i} |i\rangle\otimes|a_i\rangle
  \\|\psi_B\rangle
    &= \sum_i \sqrt{p_i} |i\rangle\otimes|b_i\rangle
  \end{aligned}
\]
define an isometry \(V=\sum_i |b_i\rangle\langle a_i|\) satisfying the desired equation.

This observation leads to a way of relating \emph{all} convex decompositions of a given density operator: let \(\{p_k,|\psi_k\rangle\}\) and \(\{q_l,|\phi_l\rangle\}\) be convex decompositions of a density operator \(\rho\);
then there exists an isometry \(V\) such that these two decompositions
\[
  \rho
  = \sum_{k=1}^n|\widetilde{\psi}_k\rangle\langle\widetilde{\psi}_k|
  = \sum_{l=1}^m|\widetilde{\phi}_l\rangle\langle\widetilde{\phi}_l|,
\]
(where \(n\geqslant m\), and \(|\widetilde{\psi}_k\rangle=\sqrt{p_k}|\psi_k\rangle\) and \(|\widetilde{ \phi}_l\rangle=\sqrt{q_l}|\phi_l\rangle\)) are related:
\[
  |\widetilde{\psi}_k\rangle = \sum_{l} V_{kl} |\widetilde{\phi}_l\rangle.
\]

\hypertarget{tricks-with-a-maximally-entangled-state}{%
\subsubsection{Tricks with a maximally entangled state}\label{tricks-with-a-maximally-entangled-state}}

A maximally entangled state of a bipartite system can be written, using the Schmidt decomposition, as
\[
  \begin{aligned}
    |\Omega\rangle
    &= \frac{1}{\sqrt d}\sum_i |i\rangle|i\rangle
  \\|\Omega\rangle\langle\Omega|
    &= \frac{1}{d} \sum_{ij}|i\rangle\langle j|\otimes|i\rangle\langle j|
  \end{aligned}
\]
Each subsystem is of dimension \(d\), and all the Schmidt coefficients are equal.
Here are few useful tricks involving a maximally entangled state.

\begin{itemize}
\item
  If we take the transpose in the Schmidt basis of \(|\Omega\rangle\), then
  \[
      \langle\Omega|A\otimes B|\Omega\rangle = \frac{1}{d}\operatorname{tr}(A^T B).
    \]
\item
  Any pure state of the bipartite system \(|\psi\rangle=\sum_{ij} c_{ij}|i\rangle|j\rangle\) can be written as
  \[
      (C\otimes\mathbf{1})|\Omega\rangle = (\mathbf{1}\otimes C^T)|\Omega\rangle.
    \]
  This implies that
  \[
      (U\otimes\overline{U})|\Omega\rangle=|\Omega\rangle
    \]
  (where \(\overline{U}\) denotes the matrix given by taking the complex conjugate, entry-wise, of \(U\), i.e.~\emph{without} also taking the transpose).
\item
  The swap operation, \(S\colon|i\rangle|j\rangle\mapsto|j\rangle|i\rangle\), can be expressed as\footnote{We write \(X^{T_{\mathcal{A}}}\) to mean the partial transpose over \(\mathcal{A}\), i.e.~\(T\otimes\mathcal{I}\).}
  \[
      \begin{aligned}
        S
        &= d |\Omega\rangle\langle\Omega|^{T_{\mathcal{A}}}
      \\&= d \sum_{ij} \big(|i\rangle\langle j|\big)^T\otimes|i\rangle\langle j|
      \\&= d \sum_{ij} |j\rangle\langle i|\otimes|i\rangle\langle j|.
      \end{aligned}
    \]
  This implies that
  \[
      \operatorname{tr}[(A\otimes B)S] = \operatorname{tr}AB
    \]
  and that
  \[
      (A\otimes\mathbf{1})S = S(\mathbf{1}\otimes A).
    \]
\end{itemize}

\hypertarget{trace-preserving-and-partial-trace}{%
\subsubsection{Trace preserving and partial trace}\label{trace-preserving-and-partial-trace}}

Show that \(\mathcal{E}\) is trace preserving if and only if \(\operatorname{tr}_\mathcal{B}\widetilde{\mathcal{E}} = d\mathbf{1}\).
(Here the partial trace is over the second system in our definition \(\widetilde{\mathcal{E}} =\mathcal{I}\otimes\mathcal{E}|\Omega\rangle\langle\Omega|\)).

\emph{(Hint: show that \(\operatorname{tr}\mathcal{E}(|i\rangle\langle j|=\delta_{ij}\).)}

\hypertarget{rotating-kraus-operators}{%
\subsubsection{Rotating Kraus operators}\label{rotating-kraus-operators}}

Mathematically speaking, Kraus operators \(E_k\) are vectors in a \(dd'\)-dimensional Hilbert space, with the Hilbert--Schmidt inner product \(\operatorname{tr}E^\dagger_k E_l\).
So, our intuition tells us, in order to describe any quantum channel with \(\dim\mathcal{H}=\dim\mathcal{H}'=d\), we should need no more than \(d^2\) Kraus operators.
We can pick an orthonormal basis of operators \(\{B_i\}\) and express each Kraus vector in this basis as \(E_k=\sum c_{ki} B_i\) (where \(i=1,\ldots,d^2\) and \(k=1,\ldots,n\), with \(n\) possibly much larger than \(d^2\)).
This gives us
\[
  \begin{aligned}
    \rho
    \longmapsto
    & \sum_{ij} B_i\rho B^\dagger_j \left(\sum _k c_{ki}c^\star_{kj}\right)
  \\=& \sum_{ij} B_i\rho B^\dagger_j  C_{ij}
  \end{aligned}
\]
The matrix \(C_{ij}\) is positive semidefinite, and hence unitarily diagonalisable: \(C_{ij}=\sum_k U_{ik} d_k U^\dagger_{kj}\) for some unitary \(U\) and some \(d_k\geqslant 0\).
We can then unitarily ``rotate'' our operator basis and use the \(C_k=\sum_j U_{jk}B_j \sqrt{d_k}\) as our new Kraus operators.

\hypertarget{no-pancakes}{%
\subsubsection{No pancakes}\label{no-pancakes}}

Consider a single qubit operation which causes the \(z\)-component of the Bloch vector to shrink while preserving the values of the \(x\)- and \(y\)-components.
Under such an operation, the Bloch sphere is mapped to an oblate spheroid which touches the Bloch sphere along its equator.

Explain why we cannot physically implement such a map.

\hypertarget{part-applications}{%
\part{Applications}\label{part-applications}}

\hypertarget{quantum-cryptography}{%
\section{Quantum cryptography}\label{quantum-cryptography}}

\begin{quote}
About \textbf{!!!TO-DO!!!}.
\end{quote}

\hypertarget{bells-theorem}{%
\section{Bell's theorem}\label{bells-theorem}}

\begin{quote}
About \textbf{quantum correlations}, which are stronger than any correlations allowed by classical physics, and about the \href{https://en.wikipedia.org/wiki/CHSH_inequality}{\textbf{CHSH inequality}} which demonstrates this fact, and which is a variant of \textbf{Bell's theorem}.
\end{quote}

Every now and then, it is nice to put down your lecture notes and go and see how things actually work in the real world.
What is wonderful (and surprising) about quantum theory is that it turns up in many places that we might not expect it to, such as in the polarisation of light, where we stumble across an intriguing paradox.

If we take two polarising filters, and place them on top of each other with their polarisations oriented at \(90^\circ\) to one another, then basically no light will pass through, since the only light passing through the first filter is orthogonally polarised with respect to the second filter, and is thus blocked.
But then, if we take a third filter, and place it in between the other two, at an angle in the middle of both (i.e.~at \(45^\circ\)), then somehow \emph{more} light is let through than if the middle filter weren't there at all.\footnote{For the more visually inclined, there is a \href{https://www.youtube.com/watch?v=zcqZHYo7ONs}{video on YouTube by minutephysics} about this experiment, or you can play with a virtual version at \href{https://lab.quantumflytrap.com/lab/bell-inequality?mode=detections}{Virtual Lab by Quantum Flytrap}.}

This is intrinsically linked to Bell's theorem, which proves the technical sounding statement that ``any local real hidden variable theory must satisfy certain statistical properties'', which is \emph{not} satisfied in reality, as many quantum mechanical experiments (such as the above) show!

\hypertarget{quantum-correlations}{%
\subsection{Quantum correlations}\label{quantum-correlations}}

Consider two entangled qubits in the singlet state
\[
  |\psi\rangle
  = \frac{1}{\sqrt 2} \left( |01\rangle-|10\rangle \right)
\]
and note that the projector \(|\psi\rangle\langle\psi|\) can be written as\footnote{There are other, more elementary, ways of deriving this result but here I want you to hone your skills. Now that you've learned about projectors, traces, and Pauli operators, why not put them to good use.}
\[
  |\psi\rangle\langle\psi|
  = \frac{1}{4} \left(
    \mathbf{1}\otimes\mathbf{1}- \sigma_x\otimes\sigma_x - \sigma_y\otimes\sigma_y - \sigma_z\otimes \sigma_z
  \right).
\]
Any single qubit observable with values \(\pm 1\) can be represented by the operator
\[
  \vec{a}\cdot\vec\sigma
  = a_x\sigma_x + a_y\sigma_y + a_z\sigma_z,
\]
where \(\vec{a}\) is a unit vector in the three-dimensional Euclidean space.
Suppose Alice and Bob choose measurements defined by vectors \(\vec{a}\) and \(\vec{b}\), respectively.
For example, if the two qubits are spin-half particles, they may measure the spin components along the directions \(\vec{a}\) and \(\vec{b}\).
We write the corresponding observable as the tensor product
\[
  A\otimes B
  = (\vec{a}\cdot\vec\sigma)\otimes(\vec{b}\cdot\vec\sigma).
\]
The eigenvalues of \(A\otimes B\) are the products of eigenvalues of \(A\) and \(B\).
Thus \(A\otimes B\) has two eigenvalues: \(+1\), corresponding to the instances when Alice and Bob registered identical outcomes, i.e.~\((+1,+1)\) or \((-1,-1)\); and \(-1\), corresponding to the instances when Alice and Bob registered different outcomes, i.e.~\((+1,-1)\) or \((-1,+1)\).
This means that the expected value of \(A\otimes B\), in any state, has a simple interpretation:
\[
    \langle A\otimes B\rangle = \Pr (\text{outcomes are the same}) - \Pr (\text{outcomes are different}).
\]
This expression can take any numerical value from \(-1\) (perfect anti-correlations) through \(0\) (no correlations) to \(+1\) (perfect correlations).
We now evaluate the expectation value in the singlet state:
\[
\begin{aligned}
  \langle\psi|A\otimes B|\psi\rangle
  & = \operatorname{tr}\left[
      (\vec{a}\cdot\vec\sigma)\otimes(\vec{b}\cdot\vec\sigma) |\psi\rangle\langle\psi|
    \right]
\\& = -\frac{1}{4} \operatorname{tr}\left[
      (\vec{a}\cdot\vec\sigma)\sigma_x \otimes(\vec{a}\cdot\vec\sigma)\sigma_x
      + (\vec{a}\cdot\vec\sigma)\sigma_y \otimes(\vec{a}\cdot\vec\sigma)\sigma_y
      + (\vec{a}\cdot\vec\sigma)\sigma_z \otimes(\vec{a}\cdot\vec\sigma)\sigma_z
    \right]
\\& = -\frac{1}{4} \operatorname{tr}\left[
      (a_x b_x + a_y b_y + a_z b_z) \mathbf{1}\otimes\mathbf{1}
    \right]
\\& = -\vec{a}\cdot\vec{b}
\end{aligned}
\]
where we have used the fact that \(\operatorname{tr}(\vec{a}\cdot\vec\sigma)\sigma_k = a_k\) (\(k=x,y,z\)).
So if Alice and Bob choose the same observable, \(\vec{a} = \vec{b}\), then their outcomes will be always opposite: whenever Alice registers \(+1\) (resp. \(-1\)) Bob is bound to register \(-1\) (resp. \(+1\)).

\hypertarget{hidden-variables}{%
\subsection{Hidden variables}\label{hidden-variables}}

The story of ``hidden variables'' dates back to 1935 and grew out of Einstein's worries about the completeness of quantum theory.
Consider, for example, a qubit.
No quantum state of a qubit can be an eigenstate of two non-commuting operators, say \(\sigma_x\) and \(\sigma_z\).
If the qubit has a definite value of \(\sigma_x\) its value of \(\sigma_z\) must be indeterminate, and vice versa.
If we take quantum theory to be a complete description of the world, then we must accept that it is impossible for both \(\sigma_x\) and \(\sigma_z\) to have definite values for the same qubit at the same time.
Einstein felt very uncomfortable about all this.
He argued that quantum theory is incomplete, and that observables \(\sigma_x\) and \(\sigma_z\) may both have simultaneous definite values, although we only have knowledge of one of them at a time.
This is the hypothesis of \textbf{hidden variables}.
In this view, the indeterminacy found in quantum theory is merely due to our ignorance of these ``hidden variables'' that are present in nature but not accounted for in the theory.
Einstein came up with a number of pretty good arguments for the existence of ``hidden variables''.
Probably the most compelling one was described in his 1935 paper (known as the EPR paper), co-authored with his younger colleagues, Boris Podolsky and Nathan Rosen.
It stood for almost three decades as the most significant challenge to the completeness of quantum theory.
Then, in 1964, John Bell showed that the hidden variable hypothesis can be tested and refuted.

\hypertarget{chsh-inequality}{%
\subsection{CHSH inequality}\label{chsh-inequality}}

\begin{quote}
An upper bound on \textbf{classical} correlations.
\end{quote}

We will describe the most popular version of Bell's argument, introduced in 1969 by John Clauser, Michael Horne, Abner Shimony, and Richard Holt (CHSH).
Let us assume that the results of any measurement on any individual system are predetermined.
Any probabilities we may use to describe the system merely reflect our ignorance of these hidden variables.

Now, imagine the following scenario.
Alice and Bob, two characters with a predilection for wacky experiments, are equipped with appropriate measuring devices and sent to two distant locations.
Somewhere in between them there is a source that emits pairs of qubits that fly apart, one towards Alice and one towards Bob.
Let us label the two qubits in each pair as \(\mathcal{A}\) and \(\mathcal{B}\) respectively, and let us assume that both Alice and Bob have well defined values of their observables.
We ask Alice and Bob to measure one of the two pre-agreed observables.
For each incoming qubit, Alice and Bob choose randomly, and independently from each other, which particular observable will be measured.
Alice chooses between \(A_1\) and \(A_2\), and Bob between \(B_1\) and \(B_2\).
Each observable has value \(+1\) or \(-1\), and so we are allowed to think about them as random variables \(A_k\) and \(B_k\), for \(k=1,2\), which take values \(\pm 1\).
Let us define a new random variable, the \textbf{CHSH quantity} \(S\), as
\[
  S = A_1(B_1 - B_2) + A_2(B_1 + B_2).
\]
It is easy to see that one of the terms \(B_1\pm B_2\) must be equal to zero and the other to \(\pm 2\), hence \(S=\pm2\).
The average value of \(S\) must lie somewhere in-between, i.e.
\[
  -2 \leqslant\langle S\rangle \leqslant 2.
\]
That's it!
Such a simple and yet profound mathematical statement about correlations, which we refer simply to as the \textbf{CHSH inequality}.
No quantum theory is involved because the CHSH inequality is not specific to quantum theory: it does not really matter what kind of physical process is behind the appearance of binary values of \(A_1\), \(A_2\), \(B_1\), and \(B_2\); it is a statement about correlations, and for all classical correlations we must have
\[
  |
    \langle A_1 B_1\rangle - \langle A_1 B_2\rangle + \langle A_2 B_1\rangle + \langle A_2 B_2\rangle
  | \leqslant 2.
\]

There are essentially two two assumptions here:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Hidden variables}: observables have definite values; and
\item
  \textbf{Locality}: Alice's choice of measurements (\(A_1\) or \(A_2\)) does not affect the outcomes of Bob's measurement, and vice versa.
\end{enumerate}

We will not discuss the locality assumption here in detail but let me comment on it briefly.
In the hidden variable world a, statement such as ``if Bob were to measure \(B_1\) then he would register \(+1\)'' must be either true or false \emph{prior to Bob's measurement}.
Without the locality hypothesis, such a statement is ambiguous, since the value of \(B_1\) could depend on whether \(A_1\) or \(A_2\) will be chosen by Alice.
We do not want this for it implies the instantaneous communication.
It means that, say, Alice by making a choice between \(A_1\) and \(A_2\), affects Bob's results.
Bob can immediately ``see'' what Alice ``does''.

\hypertarget{quantum-correlations-revisited}{%
\subsection{Quantum correlations, revisited}\label{quantum-correlations-revisited}}

In quantum theory the observables \(A_1\), \(A_2\), \(B_1\), \(B_2\) become \(2\times 2\) Hermitian matrices with two eigenvalues \(\pm 1\), and \(\langle S\rangle\) becomes the expected value of the \((4\times 4)\) \textbf{CHSH matrix}
\[
  S
  = A_1\otimes(B_1-B_2) + A_2\otimes(B_1+B_2).
\]

We can now evaluate \(\langle S\rangle\) using quantum theory.
For example, if the two qubits are in the singlet state, then we know that
\[
  \langle A\otimes B\rangle = -\vec{a}\cdot\vec{b}.
\]
We choose vectors \(\vec{a}_1\), \(\vec{a}_2\), \(\vec{b}_1\), and \(\vec{b}_2\) as shown in Figure \ref{fig:choice-of-as-and-bs}, and then, with these choices,
\[
\begin{gathered}
  \langle A_1\otimes B_1\rangle
  = \langle A_2\otimes B_1\rangle
  = \langle A_2\otimes B_2\rangle
  = \frac{1}{\sqrt 2}
\\\langle A_1\otimes B_2\rangle
   = -\frac{1}{\sqrt 2}.
\end{gathered}
\]



\begin{figure}[H]

{\centering \includegraphics{iqis-book_files/figure-latex/choice-of-as-and-bs-1} 

}

\caption{The relative angle between the two perpendicular pairs is \(45^\circ\).}\label{fig:choice-of-as-and-bs}
\end{figure}

Thus
\[
  \langle A_1 B_1\rangle - \langle A_1 B_2\rangle + \langle A_2 B_1\rangle + \langle A_2 B_2\rangle
  = -2\sqrt{2},
\]
which obviously violates CHSH inequality.

To be clear, this violation has been observed in a number of painstakingly careful experiments.
The early efforts were truly heroic, and the experiments had many layers of complexity.
Today, however, such experiments are routine.

\begin{idea}
The behaviour of entangled quantum systems cannot be explained by any local hidden variables.

\end{idea}

\hypertarget{tsirelsons-inequality}{%
\subsection{Tsirelson's inequality}\label{tsirelsons-inequality}}

\begin{quote}
An upper bound on \textbf{quantum} correlations.
\end{quote}

One may ask if \(|\langle S\rangle|= 2\sqrt{2}\) is the maximal violation of the CHSH inequality, and the answer is ``yes, it is'': quantum correlations cannot achieve any value of \(|\langle S\rangle|\) larger than \(2\sqrt{2}\).
This is because, for any state \(|\psi\rangle\), the expected value \(\langle S\rangle = \langle\psi|S|\psi\rangle\) cannot exceed the largest eigenvalue of \(S\), and we can put an upper bound on the largest eigenvalues of \(S\).
To start with, the largest eigenvalue (in absolute value) of a Hermitian matrix \(M\), denoted by \(\|M\|\), is a matrix norm, and it has the following properties:
\[
\begin{aligned}
  \|M\otimes N\|
  & = \|M\| \|N\|
\\\|MN\|
  & \leqslant\|M\| \|N\|
\\\|M+N\|
  & \leqslant\|M\| + \|N\|
\end{aligned}
\]
Given that \(\|A_i\|=1\) and \(\|B_j\|=1\) (\(i,j=1,2\)), it is easy to show that \(\|S\| < 4\).
One can, however, derive a tighter bound.
We can show (do it) that
\[
  S^2
  = 4(\mathbf{1}\otimes\mathbf{1}) + [A_1,A_2]\otimes[B_1,B_2].
\]
The norm of each of the commutators (\(\|[A_1, A_2]\|\) and \(\|[B_1, B_2]\|\)) cannot exceed \(2\), and \(\|S^2\|=\|S\|^2\), which all together gives
\[
  \|S\|
  < 2\sqrt{2}
  \implies
  |\langle S\rangle| < 2\sqrt{2}.
\]
This result is known as the \textbf{Tsirelson inequality}.

\hypertarget{remarks-and-exercises-9}{%
\subsection{\texorpdfstring{\emph{Remarks and exercises}}{Remarks and exercises}}\label{remarks-and-exercises-9}}

\textbf{!!!TO-DO!!!}

\hypertarget{quantum-algorithms}{%
\section{Quantum algorithms}\label{quantum-algorithms}}

\begin{quote}
About quantum interference in disguise: \textbf{Hadamard, function evaluation, Hadamard}.
Also about the early quantum algorithms and how they deal with querying oracles, searching for a needle in a haystack, and estimating periodicity of certain functions.
\end{quote}

Classical computers essentially evaluate functions: given \(n\)-bits of input they produce \(m\)-bits of output that are uniquely determined by the input; that is, they find the value of
\[
  f\colon \{0,1\}^n \to \{0,1\}^m
\]
for a particular specified \(n\)-bit argument.
A function with an \(m\)-bit value is equivalent to \(m\) Boolean functions, each with a one-bit value, so we may just as well say that the basic task performed by a computer is the evaluation of Boolean functions
\[
  f\colon \{0,1\}^n \to  \{0,1\}.
\]
How can we adapt this to the world of quantum computing?

\hypertarget{quantum-boolean-function-evaluation}{%
\subsection{Quantum Boolean function evaluation}\label{quantum-boolean-function-evaluation}}

\emph{In quantum computation, all elementary operations are reversible} (unitary), so we compute Boolean functions in a reversible fashion as
\[
  |x\rangle|y\rangle \mapsto |x\rangle|y\oplus f(x)\rangle.
\]

The corresponding circuit diagram (for \(n=3\)) is shown in Figure \ref{fig:n-equals-3-circuit-diagram}.



\begin{figure}[H]

{\centering \includegraphics{iqis-book_files/figure-latex/n-equals-3-circuit-diagram-1} 

}

\caption{Computing some \(f\colon\{0,1\}^3\to\{0,1\}\) in a quantum manner.}\label{fig:n-equals-3-circuit-diagram}
\end{figure}

Here we use two registers: the first one (counting from the top to the bottom of the circuit diagram) stores the arguments \(x\), and the second one the values \(f(x)\).
More precisely, the value \(f(x)\) is added bit-wise to the pre-existing binary value \(y\) of the second register.
We usually set \(y=0\) to get
\[
  |x\rangle|0\rangle \mapsto |x\rangle|f(x)\rangle.
\]

Quantum Boolean function evaluation is a special case of the generalised \(x\)-controlled-\(U\) on two registers:
\[
  \sum_x |x\rangle\langle x|\otimes U_x
\]
where \(U_x\) is either the identity \(\mathbf{1}\) (when \(f(x)=0\)) or the bit-flip\footnote{Do not confuse the capital \(X\), which is the Pauli flip operator \(\sigma_x\), with the small \(x\), which is a binary string stored in the first register and the argument of our Boolean function \(f\).} \(X\) (when \(f(x)=1\)).
We may also write this as
\[
  \sum_x |x\rangle\langle x|\otimes X^{f(x)}.
\]

\hypertarget{example}{%
\subsubsection{Example}\label{example}}

Consider the Boolean function \(f\colon\{0,1\}^2\to\{0,1\}\) given by
\[
  f(x)
  =
  \begin{cases}
    1 &\text{if $x=01$,}
  \\0 &\text{otherwise.}
  \end{cases}
\]
The evaluation \(|x\rangle|y\rangle \mapsto |x\rangle|y\oplus f(x)\rangle\) can be tabulated explicitly as
\[
  \begin{array}{cc}
    |00\rangle|0\rangle \mapsto |00\rangle|0\rangle
    & |00\rangle|1\rangle \mapsto |00\rangle|1\rangle
  \\|01\rangle|0\rangle \mapsto |01\rangle|1\rangle
    & |01\rangle|1\rangle \mapsto |01\rangle|0\rangle
  \\|10\rangle|0\rangle \mapsto |10\rangle|0\rangle
    & |10\rangle|1\rangle \mapsto |10\rangle|1\rangle
  \\|11\rangle|0\rangle \mapsto |11\rangle|0\rangle
    & |11\rangle|1\rangle \mapsto |11\rangle|1\rangle
  \end{array}
\]
and the expression \(\sum_x |x\rangle\langle x|\otimes X^{f(x)}\) becomes
\[
  \begin{aligned}
    &|00\rangle\langle 00| \otimes \mathbf{1}
  \\+ &|01\rangle\langle 01| \otimes X
  \\+ &|10\rangle\langle 10| \otimes \mathbf{1}
  \\+ &|11\rangle\langle 11| \otimes \mathbf{1}.
  \end{aligned}
\]
Finally, the matrix form looks like
\[
  \left[
  \,
    \begin{array}{c|c|c|c}
      \begin{matrix}1&0\\0&1\end{matrix}
      & \begin{matrix}0&0\\0&0\end{matrix}
      & \begin{matrix}0&0\\0&0\end{matrix}
      & \begin{matrix}0&0\\0&0\end{matrix}
    \\\hline
    \begin{matrix}0&0\\0&0\end{matrix}
      & \begin{matrix}0&1\\1&0\end{matrix}
      & \begin{matrix}0&0\\0&0\end{matrix}
      & \begin{matrix}0&0\\0&0\end{matrix}
    \\\hline
    \begin{matrix}0&0\\0&0\end{matrix}
      & \begin{matrix}0&0\\0&0\end{matrix}
      & \begin{matrix}1&0\\0&1\end{matrix}
      & \begin{matrix}0&0\\0&0\end{matrix}
    \\\hline
    \begin{matrix}0&0\\0&0\end{matrix}
      & \begin{matrix}0&0\\0&0\end{matrix}
      & \begin{matrix}0&0\\0&0\end{matrix}
      & \begin{matrix}1&0\\0&1\end{matrix}
    \end{array}
  \,
  \right]
\]
As you can see, this is a diagonal block matrix: a \((4\times 4)\) matrix with \((2\times 2)\) matrices as entries.
The rows and the columns of the \((4\times 4)\) matrix are labelled by the binary strings \(00, 01, 10, 11\), and the \((2\times 2)\) matrices on the diagonal represent operations applied to the qubit in the second register.
Here all of them are the identity \(\mathbf{1}\) except the \((01, 01)\) entry, which represents the bit-flip \(X\).
This is because \(f(01)=1\), and \(f(x)=0\) for all other binary strings \(x\).

\hypertarget{hadamard-and-quantum-fourier-transforms}{%
\subsection{Hadamard and quantum Fourier transforms}\label{hadamard-and-quantum-fourier-transforms}}

\textbf{!!!TO-DO!!!}

\hypertarget{more-phase-kick-back}{%
\subsection{More phase kick-back}\label{more-phase-kick-back}}

What makes the quantum evaluation of Boolean functions really interesting is its action on a superposition of different inputs \(x\).
For example,
\[
  \sum_{x}|x\rangle|0\rangle
  \longmapsto
  \sum_{x}|x\rangle|f(x)\rangle
\]
produces \(f(x)\) for \emph{all} \(x\) in a \emph{single} run (note that we have dropped the normalisation factor).
It is more instructive to see the effect of the function evaluation when the qubit in the second register is prepared in the state \(|-\rangle = \frac{1}{\sqrt 2}(|0\rangle - |1\rangle\), since then
\[
  \sum_x|x\rangle|-\rangle
  \longmapsto
  \sum_x (-1)^{f(x)}|x\rangle|-\rangle
\]
(as shown in Figure \ref{fig:n-equals-3-minus-circuit-diagram}).
Whenever \(f(x)=1\), the bit flip \(X\) is applied to the qubit in the second register.



\begin{figure}[H]

{\centering \includegraphics{iqis-book_files/figure-latex/n-equals-3-minus-circuit-diagram-1} 

}

\caption{Computing some \(f\colon\{0,1\}^3\to\{0,1\}\) with the second-register qubit in state \(|-\rangle\).}\label{fig:n-equals-3-minus-circuit-diagram}
\end{figure}

The reason for defining the state \(|-\rangle\) as we do is that it is the eigenstate of \(X\) with eigenvalue \(-1\).
So, due the phase kick-back, whenever \(f(x)=1\), the phase factor \(-1\) appears in front of the corresponding term \(|x\rangle\).
As you can see, the second register stays in state \(|-\rangle\) all the way through the computation --- it is the first register where things happen.
Let us now see how quantum Boolean function evaluation introduces phase shifts in quantum interference experiments, and how such experiments can be viewed as computations.

\hypertarget{oracles-and-query-complexity}{%
\subsection{Oracles and query complexity}\label{oracles-and-query-complexity}}

The computational power of quantum interference was discovered by counting how many times certain Boolean functions have to be evaluated in order to find the answer to a given problem.
Imagine a ``black box'' (also called an \textbf{oracle}) that computes some fixed Boolean function, but whose inner workings are unknown to us, and a scenario in which one wants to learn about a given property of the Boolean function but has to ``pay'' (in energy, or in money!) for each use (often referred to as a \textbf{query}) of the box.
In such a setting, the objective is to minimise number of queries to the oracle while finding out as much information as possible about the function computed by the oracle.
For this purpose, we ignore everything that happens inside the black box: the Boolean function evaluation counts as just \emph{one} computational step.

\hypertarget{deutschs-algorithm}{%
\subsubsection{Deutsch's algorithm}\label{deutschs-algorithm}}

We start, once more, with the simplest quantum interference circuit:

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-66-1} \end{center}

Suppose you can prepare the input, you can read the output, you \emph{cannot} see the phase shifter, \emph{but} you are promised that the phase shifter is set to either \(\varphi=0\) or \(\varphi=\pi\).
Can you tell which value \(\varphi\) has been set to?

Of course you can!

One way of doing it is to set your input to \(|0\rangle\) and check the output: for \(\varphi=0\) the output is always \(|0\rangle\), and for \(\varphi=\pi\) it is always \(|1\rangle\).
A single run of the interference experiment is sufficient to determine the difference.
The first quantum algorithm, proposed by David Deutsch in 1985, is very much related to this effect, but where the phase setting is determined by the Boolean function evaluation via the phase kick-back.

\begin{scenario}
We are presented with an oracle that computes some unknown function \(f\colon\{0,1\}\to\{0,1\}\).
Note that there are only four possibilities for what \(f\) can be: it could be one of two constant functions (i.e.~those where \(f(0)=f(1)\)), or one of two ``balanced'' functions (i.e.~those where \(f(0)\neq f(1)\)).

\begin{longtable}[]{@{}rcc@{}}
\toprule
& \(f(0)\) & \(f(1)\)\tabularnewline
\midrule
\endhead
constant & \(\begin{matrix}0\\1\end{matrix}\) & \(\begin{matrix}0\\1\end{matrix}\)\tabularnewline
balanced & \(\begin{matrix}0\\1\end{matrix}\) & \(\begin{matrix}1\\0\end{matrix}\)\tabularnewline
\bottomrule
\end{longtable}

Our task is to determine, using the fewest queries possible, whether the function computed by the oracle is constant or balanced.

\end{scenario}

Note that we are \emph{not} asked for the particular values \(f(0)\) and \(f(1)\), but \emph{only whether the two values are the same or different}.
Classical intuition tells us that we have to evaluate both \(f(0)\) and \(f(1)\) and compare them, which involves evaluating \(f\) \emph{twice}.
But, in the quantum setting, we can solve this problem with a \emph{single} function evaluation, using the following circuit.

\begin{circuit}

(Deutsch's).

\emph{First register: \(1\) qubit. Second register: \(1\) qubit.}

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-67-1} \end{center}


\end{circuit}

During the function evaluation, the second register ``kicks back'' the phase factor \((-1)^{f(x)}\) in front of \(|x\rangle\), but the state of the second register remains unchanged; the first register is modified as follows:
\[
  \begin{aligned}
    |0\rangle
    &\overset{H}{\longmapsto}
    |0\rangle+|1\rangle
  \\&\overset{f}{\longmapsto}
    (-1)^{f(0)}|0\rangle + (-1)^{f(1)}|1\rangle
  \\&\quad\equiv
    |0\rangle + (-1)^{f(0)\oplus f(1)}|1\rangle
  \\&\overset{H}{\longmapsto}
    |f(0)\oplus f(1)\rangle.
  \end{aligned}
\]

This evolution can be represented by the circuit diagram

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-68-1} \end{center}

where the relative phase is \(\varphi = (-1)^{f(0)\oplus f(1)}\).
The first qubit ends in state \(|0\rangle\) if the function \(f\) is constant, and in state \(|1\rangle\) if the function is balanced, and the standard measurement distinguishes these two cases with certainty.\footnote{The original Deutsch algorithm provides the correct answer with probability 50\%. Here we have presented a modified/improved version.}

Deutsch's result laid the foundation for the new field of quantum computation, and was followed by several other quantum algorithms for various problems.
They all seem to rest on the same generic sequence: a Hadamard transform, followed by a function evaluation, followed by another Hadamard (or Fourier) transform.\footnote{The Hadamard transform is a special case of the Fourier transform over the group \(\mathbb{Z}_2^n\).}
As we shall see in a moment, in some cases (such as in Grover's search algorithm) this sequence is repeated several times.
Let me now take you through the three early quantum algorithms, each one offering a higher-order speed-up when compared to their classical analogues than the last.

\hypertarget{three-more-quantum-algorithms}{%
\subsection{Three more quantum algorithms}\label{three-more-quantum-algorithms}}

Along with Deutsch's algorithm, there are three more fundamental quantum algorithms that we will study here.
Each one was designed to solve a different specific problem, but they all share some similarity: this omnipresent sequence of Hadamard, function evaluation, Hadamard.

\hypertarget{the-bernstein-vazirani-algorithm}{%
\subsubsection{The Bernstein-Vazirani algorithm}\label{the-bernstein-vazirani-algorithm}}

\begin{scenario}
We are presented with an oracle that computes some unknown function \(f\colon\{0,1\}^n\to\{0,1\}\), but we are promised that \(f\) is of the form
\[
  f(x) = a\cdot x
  \equiv (a_1\cdot x_1) \oplus \ldots \oplus (a_n\cdot x_n)
\]
for some fixed \(a\in\{0,1\}^n\).

Our task is to determine, using the fewest queries possible, the value of the \(n\)-bit string \(a\).

\end{scenario}

It's quite easy to see how to do this classically: if we input the value \(x=00\ldots010\ldots0\), with the \(1\) in the \(m\)-th bit, then \(f(x)\) is simply the \(m\)-th bit of \(a\); after \(n\) such calls, we can evaluate every bit value.
It is also clear that there cannot exist a better classical algorithm: each call to the oracle teaches us exactly one bit of information, and since we must learn \(n\) bits, we must query it \(n\) times.

In contrast, by running the circuit below, it is possible to determine the value of \(a\) with a \emph{single} (!) call to the oracle.

\begin{circuit}

(Bernstein-Vazirani).

\emph{First register: \(n\) qubits. Second register: \(1\) qubit.}

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-69-1} \end{center}


\end{circuit}

N.B. The ``\(\ldots\)'' in the circuit means ``there are more wires here but they are identical (apart from the numbering) to the ones above''.
You might also see other notation to denote this, such as

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-70-1} \end{center}

or even simply

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-71-1} \end{center}

Now, stepping through the execution of the circuit (and ignoring the second register, which remains in state \(|-\rangle\) throughout), we obtain
\[
  \begin{aligned}
    |0\rangle
    &\overset{H}{\longmapsto}
    \left(\frac{1}{\sqrt2}\right)^n \sum_{x\in\{0,1\}^n} |x\rangle
  \\&\overset{f}{\longmapsto}
    \left(\frac{1}{\sqrt2}\right)^n \sum_{x\in\{0,1\}^n} (-1)^{a\cdot x}|x\rangle
  \\&\overset{H}{\longmapsto}
    \left(\frac{1}{\sqrt2}\right)^n \sum_{x\in\{0,1\}^n}
    \left[
      (-1)^{a\cdot x} \left(\frac{1}{\sqrt2}\right)^n
      \sum_{y\in\{0,1\}^n} (-1)^{y\cdot x} |y\rangle
    \right]
  \\&\quad= \left(\frac12\right)^n \sum_{y\in\{0,1\}^n}
    \left[
      \sum_{x\in\{0,1\}^n} (-1)^{(a\oplus y)\cdot x}
    \right]
    |y\rangle
  \\&\quad=|a\rangle
  \end{aligned}
\]
where we write the second Hadamard transform as
\[
  |x\rangle
  \mapsto
  \left(\frac{1}{\sqrt2}\right)^n \sum_{y\in\{0,1\}^n} (-1)^{y\cdot x}|y\rangle
\]
and where we have used the fact (which you should prove!) that, for any \(y\in\{0,1\}^n\),
\[
  \sum_{x\in\{0,1\}^n} (-1)^{x\cdot y}
  =
  \begin{cases}
    0 &\text{if $y\neq0$}
  \\2^n &\text{if $y=0$}
  \end{cases}
\]

This lets us write\footnote{Even if you don't immediately see how this sum works for \(z\neq a\) (writing \(|z\rangle\) to mean the output), you can first calculate the probability that the output is \(z=a\). In this case it is easy to see that the sum is \(2^n\), and that in the final state \(\sum_z\alpha_z|z\rangle\) the term \(z=a\) has amplitude \(1\). Thus, by normalisation, all the other terms must be equal to \(0\).}
\[
  \sum_{x\in\{0,1\}^n} (-1)^{(a\oplus y)\cdot x}
  =
  \begin{cases}
    0 &\text{if $y\neq a$}
  \\2^n &\text{if $y=a$.}
  \end{cases}
\]
If you take the sum over \(x\), then all the terms always cancel out \emph{unless} \(a\oplus y = 00\ldots0\), i.e.~\emph{unless \(y=a\)}.
Thus the standard bit-by-bit measurement of the first register gives the value of \(a\) and solves the problem with a single call to the oracle.

Note that the algorithm follows the same pattern as Deutsch's algorithm: Hadamard, function evaluation, Hadamard, i.e.~a generic quantum interference pattern.

\hypertarget{grovers-search-algorithm}{%
\subsubsection{Grover's search algorithm}\label{grovers-search-algorithm}}

The next algorithm we will study aims to solve the problem of searching for a specific item in an \emph{unsorted} database.
Think about an old-fashioned phone book: the entries are typically sorted alphabetically, by the name of the person that you want to find.
However, what if you were in the opposite situation: you had a phone number and wanted to find the corresponding person's name?
The phone book is not sorted in that way, and to find the number (and hence name) with, say, 50\% probability, you would need to search through, on average, 50\% of the entries.
In a large phone book, this would take a long time.

While this might seem like a rather contrived problem (a computer database should always maintain an index on any searchable field), many problems in computer science can be cast in this form, i.e.~that of an \textbf{unstructured search}.

\begin{scenario}
We are presented with an oracle that computes some unknown function \(f\colon\{0,1\}^n\to\{0,1\}\).

Our task is to find, using the fewest queries possible, an input \(x\in\{0,1\}^n\) such that \(f(x)=1\).

\end{scenario}

Suppose that we know that, amongst the \(N=2^n\) binary strings, there are \(M\ll N\) which are ``tagged'', i.e.~on which \(f\) evaluates to \(1\).
There is no structure in the database, and so any classical search requires around \(N/M\) steps, i.e.~the function \(f\) must be evaluated roughly \(N/M\) times.

In contrast, there is a quantum search algorithm, implemented by the circuit below, that was proposed in 1996 by Lov Grover, and which requires only roughly \(\sqrt{N/M}\) steps.

\begin{circuit}

(Grover's search).

\emph{First register: \(n\) qubits. Second register: \(1\) qubit.}

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-72-1} \end{center}

where \(f_0\) tags the binary string of \(n\) zeros: \(f_0(x)=1\) if \(x=00\ldots0\), and \(f_0(x)=0\) otherwise.


\end{circuit}

We can recognise the typical Hadamard, function evaluation, Hadamard sequence, and we can see that the second register (the bottom qubit, in state \(|-\rangle\)) plays an auxiliary role: the real action takes place in the first register.
However, unlike the previous algorithms, a single call to the oracle does not do very much, and we have to build up the quantum interference in the first register through repeated calls to the oracle (without any intermediate measurements!).

Here, the basic step is the \textbf{Grover iteration operator \(G\)}, which is the boxed part of the circuit that we repeat over and over.
After \(O(2^{n/2})\) applications of \(G\), we measure the first register bit-by-bit and obtain the value of \(|z\rangle\), which is such that, \emph{with ``high'' probability}, \(f(z)=1\).
In order to actually \emph{see} how this algorithm works, and to justify our claim that it gives what we are searching for ``with high probability'', we can take a more geometric approach.

First, we define two orthonormal vectors in the Hilbert space of the first register:\footnote{In fact, we shall completely ignore the second register from now on.}
\[
  \begin{aligned}
    |a\rangle
    &= \frac{1}{\sqrt{N-M}} \sum_{x\in f^{-1}(0)} \!\!\!\!|x\rangle
  \\|b\rangle
    &= \frac{1}{\sqrt{M}} \sum_{x\in f^{-1}(1)} \!\!\!\!|x\rangle
  \end{aligned}
\]
where \(f^{-1}(i) = \{x\in\{0,1\}^n \mid f(x)=i\}\).
These two vectors span a two-dimensional subspace in which the search will take place.

This subspace contains the equally-weighted superposition \(|s\rangle\) of all binary strings of length \(n\):\footnote{We often omit from our notation the fact that the sum is over all \(x\in\{0,1\}^n\), leaving it (hopefully) implicitly understood from the context.}
\[
  \begin{aligned}
    |s\rangle
    &= \frac{1}{\sqrt{N}} \sum_x|x\rangle
  \\&= \sqrt{\frac{N-M}{N}}|a\rangle + \sqrt{\frac{M}{N}}|b\rangle
  \\&= (\cos\alpha)|a\rangle + (\sin\alpha)|b\rangle
  \end{aligned}
\]
where we have parametrised \(\sqrt{\frac{N-M}{N}}\) as \(\cos\alpha\), and \(\sqrt{\frac{M}{N}}\) as \(\sin\alpha\), with \(\alpha\approx\sqrt{\frac{M}{N}}\), since \(N\gg M\).

The state \(|s\rangle\) is our starting input for our sequence of Grover iterations, and we will show that, applying \(G\), when restricting to the plane spanned by \(|a\rangle\) and \(|b\rangle\), amounts to applying a rotation by angle \(2\alpha\).
Grover's search algorithm can then be understood as a sequence of rotations which take the input state \(|s\rangle\) towards the target state \(|b\rangle\).

To see this, note that the oracle induces the unitary transformation
\[
  f\colon |x\rangle \mapsto (-1)^{f(x)}|x\rangle
\]
which we shall write as \(I_a = 2|a\rangle\langle a|-\mathbf{1}\), and interpret as a reflection through the \(|a\rangle\)-axis.
In particular, evaluation of \(f_0\) can be written as \(2|0\rangle\langle 0|-\mathbf{1}\), and thus thought of as a reflection through the \(|0\rangle\)-axis.
If we sandwich \(f_0\) in between two Hadamards then we obtain \(I_s = 2|s\rangle\langle s|-\mathbf{1}\), which is reflection through the \(|s\rangle\)-axis.
The Grover iteration operator \(G\) is the composition
\[
  G = I_s I_a.
\]
Note also that \(I_a = 2|a\rangle\langle a|-\mathbf{1}= \mathbf{1}-2|b\rangle\langle b|\).

Now recall the purely geometric fact that (working in \(2\)-dimensional Euclidean space), if we have two intersecting lines \(L_1\) and \(L_2\), meeting with angle \(\theta\), then reflecting an object through \(L_1\) and then reflecting the resulting image through \(L_2\) is the same as simply rotating the original object around the point of intersection \(L_1\cap L_2\) by \(2\theta\).

The angle between \(|a\rangle\) and \(|s\rangle\) is \(\alpha\), and so, each time \(G\) is applied, the vector is rotated (around the origin) by \(2\alpha\) towards the \(|b\rangle\)-axis.
We just have to choose the right number \(r\) of steps such that we end up as close to the \(|b\rangle\)-axis as possible.
The state \(|s\rangle\) starts at angle \(\alpha\) to \(|a\rangle\), and we should perform our final (and only) measurement when this angle is \(\pi/2\), i.e.~when \((2r+1)\alpha = \pi/2\), which gives
\[
  r \approx \frac{\pi}{4}\sqrt{\frac{N}{M}}.
\]

\begin{figure}[H]

{\centering \includegraphics{iqis-book_files/figure-latex/grover-search-geometrically-1} 

}

\caption{Understanding the Grover search algorithm geometrically.}\label{fig:grover-search-geometrically}
\end{figure}

So the quantum algorithm searches an unsorted list of \(N\) items in roughly \(\sqrt{N}\) steps: it offers a \emph{quadratic} speed-up when compared to classical search, which can be of immense practical importance.
For example, cracking some of the popular ciphers, such as AES (Advanced Encryption Standard), essentially requires a search among \emph{many} binary strings (called \textbf{keys}).
If these can be checked at a rate of, say, one million keys per second, then a classical computer would need over a thousand years to find the correct key, while a quantum computer using Grover's algorithm would find it in less than four minutes.

\hypertarget{simons-problem}{%
\subsubsection{Simon's problem}\label{simons-problem}}

Here we will see the simplest quantum algorithm that shows an exponential speed-up compared to the best classical algorithm.

\begin{scenario}
We are presented with an oracle that computes some unknown function \(f\colon\{0,1\}^n\to\{0,1\}^n\), but we are promised that \(f\) satisfies, for all \(x\in\{0,1\}^n\),
\[
  f(x) = f(x\oplus s)
\]
for some fixed \(s\in\{0,1\}^n\), which we call the \textbf{period} of \(f\).\footnote{This is equivalent to saying that \(f\) is \textbf{two-to-one}: for any \(y\in\{0,1\}^n\) such that there exists some \(x\in\{0,1\}^n\) with \(f(x)=y\), there exists exactly one other \(x'\neq x\) such that \(f(x')=y\) as well.}
So that the problem is non-trivial (i.e.~so that \(f\) really is two-to-one), we assume that \(s\) is \emph{not} the string of \(n\) zeros.

Our task is to determine, using the fewest queries possible, the value of the \(n\)-bit string \(s\).

\end{scenario}

Classically, this problem is exponentially hard.
We will not go through a detailed proof of this fact, but the intuition is reasonably simple: since there is no structure in the function \(f\) that would help us find its period \(s\), the best we can do is evaluate \(f\) on random inputs and hope that we find some distinct \(x\) and \(x'\) such that \(f(x)=f(x')\), and then we know that \(s=x\oplus y\).
After having made \(m\) queries to the oracle, we have a list of \(m\) values of the tuple \((x,f(x))\); there are \(m(m-1)/2\) possible pairs which could match within this list, and the probability that a randomly chosen pair match is \(1/2^{n-1}\).
This means that the probability of there being at least one matching pair within the list of \(m\) tuples is less than \(m^2/2^n\).
Clearly, the chance of finding a matching pair is negligible if the oracle is queried on fewer than \(\sqrt{2^n}\) inputs.

The quantum case, on the other hand, gives a result with high probability within a \emph{linear} number of steps.
The circuit that solves this problem, shown below, has a familiar Hadamard--function--Hadamard structure, but the second register has been expanded to \(n\) qubits.

\begin{circuit}

(Simon's problem).

\emph{First register: \(n\) qubits. Second register: \(n\) qubits.}

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-73-1} \end{center}


\end{circuit}

Let's follow the evolution of the two registers in this circuit.
We start off by preparing the equally-weighted superposition of all \(n\)-bit strings, and then query the oracle:
\[
  \begin{aligned}
    |0^n\rangle|0^n\rangle
    &\longmapsto
    \frac{1}{\sqrt{2^n}} \sum_x |x\rangle|0^n\rangle
  \\&\longmapsto
    \frac{1}{\sqrt{2^n}} \sum_x |x\rangle|f(x)\rangle.
  \end{aligned}
\]
The second Hadamard transform on the first register then yields the final output state:
\[
  \frac{1}{2^n} \sum_{x,y} (-1)^{x\cdot y} |y\rangle|f(x)\rangle.
\tag{6.4.3.1}
\]

Now, if we measure the second register \emph{before} applying the second Hadamard transform to the first, we obtain one of the \(2^{n-1}\) possible values of \(f(x)\), each equally likely.\footnote{As we shall see in a moment, the actual measurement on the second register is not actually necessary.}

Suppose that the outcome of the measurement is \(f(a)\).
Given that both \(a\) and \(a\oplus s\) are mapped to \(f(a)\) by \(f\), the first register then collapses to the state
\[
  \frac{1}{\sqrt{2}}\big( |a\rangle + |a\oplus s\rangle \big).
\]

The subsequent Hadamard transform on the first register then gives us the final state\footnote{We write \(s^\perp\) to mean the set of all \(y\in\{0,1\}^n\) such that \(y\cdot s=0\).}
\[
  \begin{aligned}
    \frac{1}{\sqrt{2^{n+1}}} \sum_y \Big((-1)^{a\cdot y}+(-1)^{(a\oplus s)\cdot y}\Big) |y\rangle|f(a)\rangle
    &=
    \frac{1}{\sqrt{2^{n+1}}} \sum_y (-1)^{a\cdot y}
      \Big( 1 + (-1)^{s\cdot y} \Big) |y\rangle|f(a)\rangle
  \\&=
    \frac{1}{\sqrt{2^{n-1}}} \sum_{y\in s^\perp}
      (-1)^{a\cdot y} |y\rangle|f(a)\rangle
  \end{aligned}
\]
where we have used the fact that \((a\oplus s)\cdot y = (a\cdot y)\oplus(s\cdot y)\), and that \(1+(-1)^{s\cdot y}\) can have only two values: either \(2\) (when \(s\cdot y = 0\)), or \(0\) (when \(s\cdot y = 1\)).
Now we measure the first register: the outcome is selected at random from all possible values of \(y\) such that \(a\cdot y = 0\), each occurring with probability \(1/(2^{n-1})\).

In fact, we do not have to measure the second register at all: it was a mathematical shortcut, simply taken for pedagogical purposes.
Instead of collapsing the state to just one term in a superposition, we can express Equation (6.4.3.1) as\footnote{Recall that the image of \(f\) is the set of all \(z\in\{0,1\}^n\) such that there exists some \(x\in\{0,1\}^n\) satisfying \(f(x)=z\).}
\[
  \frac{1}{2^n} \sum_{y,f(a)}
    \Big( (-1)^{a\cdot y} + (-1)^{(a\oplus s)\cdot y} \Big) |y\rangle|f(a)\rangle
  =
  \frac{1}{2^n} \sum_{y,f(a)} (-1)^{a\cdot y}
    \Big( 1 + (-1)^{s\cdot y} \Big) |y\rangle|f(a)\rangle
\]
where the summation over \(f(a)\) means summing over all binary strings in the image of \(f\).

The output of the algorithm is then
\[
  \frac{1}{2^{n-1}} \sum_{y\in s^\perp} |y\rangle
    \sum_{f(a)} (-1)^{a\cdot y} |f(a)\rangle
\]
and, again, the measurement outcome is selected at random from all possible values of \(y\) such that \(s\cdot y=0\).

We are not quite done yet: we cannot infer \(s\) from a \emph{single} output \(y\).
However, once we have found \(n-1\) linearly independent\footnote{Here, \textbf{linearly independent} means that no string in the set \(\{y_1,\ldots,y_n\}\) can be expressed as the bitwise sum of some other strings in this set.} strings \(y_1,y_2,\ldots,y_{n-1}\), we can solve the \(n-1\) equations
\[
  \left\{
  \begin{aligned}
    s\cdot y_1 &= 0
  \\s\cdot y_2 &= 0
  \\&\,\,\,\vdots
  \\s\cdot y_{n-1} &= 0
  \end{aligned}
  \right\}
\]
to determine a unique value of \(s\).
(Note that we only need \(n-1\) values, and not \(n\), because \(s=0\) will always be a solution, but we have explicitly assumed that this is not the case, and so it suffices to narrow down the space of possible solutions to consist of \emph{two} elements, since then we know that we can just take the non-zero one.)

So we run this algorithm repeatedly, each time obtaining another value of \(y\) that satisfies \(s\cdot y = 0\).
Every time we find some new value of \(y\) that is linearly independent of all previous ones, we can discard half the potential candidates for \(s\).
The probability that \(y_1,\ldots,y_{n-1}\) are linearly independent is
\[
  \left( 1 - \frac{1}{2^{n-1}} \right)
  \left( 1 - \frac{1}{2^{n-2}} \right)
  \ldots
  \left( 1 - \frac{1}{2} \right).
\tag{6.4.3.2}
\]

Indeed, suppose that we have \(k\) linearly independent binary strings \(y_1,\ldots,y_k\).
Then these strings span a subspace of size \(2^k\), consisting of all binary strings of the form \(\bigoplus_{i=1}^k b_i y_i\), where \(b_1,\ldots,b_k\in\{0,1\}\).
Now suppose we obtain some \(y_{k+1}\).
It will be linearly independent from the \(y_1,\ldots,y_k\) if and only if it lies \emph{outside} the subspace spanned by the \(y_1,\ldots,y_k\), which occurs with probability \(1-(2^k)/(2^n)\).
We can bound Equation (6.4.3.2) from below:\footnote{Use the inequality \[\begin{aligned}(1-x)(1-y)&= 1 - x - y - xy\\&\geqslant 1 - (x+y)\end{aligned}\] which holds for any \(0<x,y<1\).}
the probability of obtaining a linearly independent set \(\{y_1,\ldots,y_{n-1}\}\) by running the algorithm \(n-1\) times (i.e.~not having to discard any values and run again) is
\[
  \prod_{k=1}^{n-1}
  \left(
    1-\frac{1}{2^k}
  \right)
  \geqslant
  \left[
    1 -
    \left(
      \frac{1}{2^{n-1}} + \frac{1}{2^{n-2}} + \ldots + \frac14
    \right)
  \right]
  \cdot \frac12
  >
  \frac14.
\]

We conclude that we can determine \(s\) with some constant probability of error after repeating the algorithm \(O(n)\) times.
The exponential separation that this algorithm demonstrates between quantum and classical highlights the vast potential of a quantum computer to speed up function evaluation.



\begin{figure}[H]

{\centering \includegraphics{iqis-book_files/figure-latex/simons-diagramatically-1} 

}

\caption{Picture all possible binary strings as dots, but with the string \(s\) denoted by a star. Every linearly independent \(y_{k+1}\) lets us ``zoom in'' twice as close towards \(s\).}\label{fig:simons-diagramatically}
\end{figure}

\hypertarget{remarks-and-exercises-10}{%
\subsection{\texorpdfstring{\emph{Remarks and exercises}}{Remarks and exercises}}\label{remarks-and-exercises-10}}

\hypertarget{shors-algorithm}{%
\subsubsection{Shor's algorithm}\label{shors-algorithm}}

\textbf{!!!TO-DO!!!}

\hypertarget{rsa}{%
\subsubsection{RSA}\label{rsa}}

\textbf{!!!TO-DO!!!}

\hypertarget{more-complexity-classes}{%
\subsubsection{More complexity classes}\label{more-complexity-classes}}

\textbf{!!!TO-DO!!!}

\hypertarget{section}{%
\subsubsection{}\label{section}}

\textbf{!!!TO-DO!!! implementing reflections}

\hypertarget{section-1}{%
\subsubsection{}\label{section-1}}

\textbf{!!!TO-DO!!! optimality of Grover}

\hypertarget{decoherence-and-basic-quantum-error-correction}{%
\section{Decoherence and basic quantum error correction}\label{decoherence-and-basic-quantum-error-correction}}

\begin{quote}
About the one big problem that hinders us from physically implementing everything that we've learnt so far, namely \textbf{decoherence}, as well as how we can start to deal with it via some elementary \textbf{error correction}.
\end{quote}

In principle we know how to build a quantum computer: we can start with simple quantum logic gates and try to integrate them together into quantum networks.
However, if we keep on putting quantum gates together into networks we will quickly run into some serious practical problems.
The more interacting qubits involved, the harder it is to prevent them from getting entangled with the environment.
This unwelcome entanglement, also known as \textbf{decoherence}, destroys the interference, and thus the power, of quantum computing.

\hypertarget{decoherence-simplified}{%
\subsection{Decoherence simplified}\label{decoherence-simplified}}

Consider the following qubit-environment interaction:
\[
  \begin{aligned}
    |0\rangle|e\rangle &\longmapsto |0\rangle|e_{00}\rangle
  \\|1\rangle|e\rangle &\longmapsto |1\rangle|e_{11}\rangle
  \end{aligned}
\]
where \(|e\rangle\), \(|e_{00}\rangle\), and \(|e_{11}\rangle\) are the states of the environment, which not need to be orthogonal.\footnote{The reason we use two indices in \(|e_{00}\rangle\) and \(|e_{11}\rangle\) will become clear in a moment, when we consider more general interaction with the environment.}
Let \(|\psi\rangle = \alpha|0\rangle + \beta|1\rangle\) be the initial state of the qubit.
The environment is essentially trying to \emph{measure} the qubit and, as the result, the two get entangled:
\[
  \Big( \alpha|0\rangle + \beta|1\rangle \Big) |e\rangle
  \longmapsto
  \alpha |0\rangle|e_{00}\rangle + \beta |1\rangle |e_{11}\rangle.
\]
This state can also be written as
\[
  \begin{aligned}
    \Big( \alpha|0\rangle + \beta|1\rangle \Big) |e\rangle
    \longmapsto
    & \Big( \alpha|0\rangle + \beta|1\rangle \Big) \frac{|e_{00}\rangle+|e_{11}\rangle}{2}
  \\+& \Big( \alpha|0\rangle - \beta|1\rangle \Big) \frac{|e_{00}\rangle-|e_{11}\rangle}{2}.
  \end{aligned}
\]
or as
\[
  |\psi\rangle|e\rangle
  \longmapsto
  \mathbf{1}|\psi\rangle|e_{\mathbf{1}}\rangle + Z|\psi\rangle|e_Z\rangle,
\]
where \(|e_{\mathbf{1}}\rangle = \frac12(|e_{00}\rangle + |e_{11}\rangle)\) and \(|e_Z\rangle = \frac12(|e_{00}\rangle - |e_{11}\rangle)\).
We may interpret this expression by saying that two things can happen to the qubit: nothing \(\mathbf{1}\) (first term), or phase-flip \(Z\) (second term).
\emph{This, however, should not be taken literally unless the states of the environment, \(|e_{\mathbf{1}}\rangle\) and \(|e_Z\rangle\), are orthogonal.}\footnote{Why not?}

This process is what we refer to as \textbf{decoherence}.

\hypertarget{decoherence-and-interference}{%
\subsection{Decoherence and interference}\label{decoherence-and-interference}}

Suppose the qubit undergoes the usual interference experiment, but, in between the two Hadamard gates, it is affected by \textbf{decoherence} (denoted by \(\times\)), which acts as described above (i.e.~\(|0\rangle|e\rangle\mapsto|0\rangle|e_{00}\rangle\) and \(|1\rangle|e\rangle\mapsto|1\rangle|e_{11}\rangle\)).

\begin{figure}[H]

{\centering \includegraphics{iqis-book_files/figure-latex/decoherence-interference-1} 

}

\caption{The usual interference experiment, but with decoherence.}\label{fig:decoherence-interference}
\end{figure}

Let us step through the circuit in Figure \ref{fig:decoherence-interference}, keeping track of the state of the environment:
\[
  \begin{aligned}
    |0\rangle|e\rangle
    & \overset{H}{\longmapsto} \Big( |0\rangle + |1\rangle \Big) |e\rangle
  \\& \overset{\phi}{\longmapsto} \Big( |0\rangle + e^{i\phi}|1\rangle \Big) |e\rangle
  \\& \overset{\times}{\longmapsto} |0\rangle|e_{00}\rangle + e^{i\phi}|1\rangle|e_{11}\rangle
  \\& \overset{H}{\longmapsto} |0\rangle\Big( |e_{00}\rangle + e^{i\phi}|e_{11}\rangle \Big) + |1\rangle\Big( |e_{00}\rangle - e^{i\phi}|e_{11}\rangle \Big).
  \end{aligned}
\]
If we write \(\langle e_{00}|e_{11}\rangle = ve^{i\alpha}\), then the final probabilities of \(0\) and \(1\) oscillate with \(\phi\) as
\[
  \begin{aligned}
    P_{0}(\phi) &= \frac12\big(1 + v\cos(\phi + \alpha)\big),
  \\P_{1}(\phi) &= \frac12\big(1 - v\cos(\phi + \alpha)\big).
  \end{aligned}
\]

\begin{figure}[H]

{\centering \includegraphics{iqis-book_files/figure-latex/visibility-suppression-1} 

}

\caption{Visibility suppression.}\label{fig:visibility-suppression}
\end{figure}

As we can see in Figure \ref{fig:visibility-suppression}, the interference pattern is suppressed by a factor \(v\), which we call the \textbf{visibility}.
As \(v=|\langle e_{00}|e_{11}\rangle|\) decreases, we lose all the advantages of quantum interference.
For example, in Deutsch's algorithm we obtain the correct answer with probability at most \(\frac12(1+v)\).
For \(\langle e_{00}|e_{11}\rangle = 0\), the \textbf{perfect decoherence} case, the network outputs \(0\) or \(1\) with equal probabilities, i.e.~\emph{it is useless as a computing device}.

\begin{idea}
It is clear that we want to avoid decoherence, or at least diminish its impact on our computing device.
For this we need \textbf{quantum error correction}: we encode the state of a single (logical) qubit across several (physical) qubits.

\end{idea}

\textbf{!!!TO-DO!!! generalised decoherence as controlled-\(U\) gate, varying from \(\mathbf{1}\) to controlled-\(\texttt{NOT}\)}

\hypertarget{evolution-of-density-operators-under-decoherence}{%
\subsection{Evolution of density operators under decoherence}\label{evolution-of-density-operators-under-decoherence}}

In terms of density operators, the qubit alone evolves from the pure state \(|\psi\rangle\langle\psi|\) to a mixed state, which can be obtained by tracing over the environment.
We start with the evolution of the state vector \(|\psi\rangle=\alpha|0\rangle+\beta|1\rangle\), which is given by
\[
  \left( \alpha|0\rangle +\beta |1\rangle\right)|e\rangle \longmapsto
  \alpha |0\rangle|e_{00}\rangle +\beta |1\rangle |e_{11}\rangle,
\]
Then we write it as the evolution of the projector \(|\psi\rangle\langle\psi|\), and trace over the environment to obtain
\[
  \begin{aligned}
    |\psi\rangle\langle\psi| \longmapsto & |\alpha|^2|0\rangle\langle 0| \langle e_{00}|e_{00}\rangle+ \alpha\beta^\star |0\rangle\langle 1|\langle e_{11}|e_{00}\rangle
  \\+ &\alpha^\star\beta |1\rangle\langle 0|\langle e_{00}|e_{11}\rangle  + |\beta|^2|1\rangle\langle 1|\langle e_{11}|e_{11}\rangle.
  \end{aligned}
\]
Written in the matrix form, this is
\[
  \begin{bmatrix}
    |\alpha|^2 & \alpha\beta^\ast
  \\\alpha^\ast\beta & |\beta|^2
  \end{bmatrix}
  \longmapsto
  \begin{bmatrix}
    |\alpha|^2 & \alpha\beta^\ast \langle e_{11}|e_{00}\rangle
    \\\alpha^\ast\beta \langle e_{00}|e_{11}\rangle & |\beta|^2
  \end{bmatrix}.
\]
The off-diagonal elements, originally called \textbf{coherences}, vanish as \(\langle e_{00}|e_{11}\rangle\) approaches zero.
This is why this particular interaction is called decoherence.

Notice that
\[
|\psi\rangle|e\rangle \longmapsto \mathbf{1}|\psi\rangle|e_{\mathbf{1}}\rangle+Z|\psi\rangle|e_Z\rangle,
\]
implies
\[
|\psi\rangle\langle\psi|\longmapsto \mathbf{1}|\psi\rangle\langle\psi| \mathbf{1}\langle e_{\mathbf{1}}|e_{\mathbf{1}}\rangle +Z|\psi\rangle\langle\psi| Z\langle e_Z|e_Z\rangle,
\]
\emph{only} when \(\langle e_{\mathbf{1}}|e_Z\rangle=0\) (otherwise you would have additional cross terms \(\mathbf{1}|\psi\rangle\langle\psi| Z\) and \(Z|\psi\rangle\langle\psi| \mathbf{1}\)).
In this case we can indeed say that, with probability \(\langle e_{\mathbf{1}}|e_{\mathbf{1}}\rangle\), nothing happens, and, with probability \(\langle e_Z|e_Z\rangle\), the qubit undergoes the phase-flip \(Z\).

\hypertarget{quantum-errors}{%
\subsection{Quantum errors}\label{quantum-errors}}

The most general qubit-environment interaction
\[
  \begin{aligned}
    |0\rangle|e\rangle &\longmapsto |0\rangle|e_{00}\rangle + |1\rangle|e_{01}\rangle,
  \\|1\rangle|e\rangle &\longmapsto |1\rangle|e_{10}\rangle + |0\rangle|e_{11}\rangle,
  \end{aligned}
\]
where the states of the environment are neither normalised nor orthogonal, leads to decoherence
\[
  \begin{aligned}
    \Big( \alpha|0\rangle + \beta|1\rangle \Big) |e\rangle \longmapsto
    & \Big( \alpha|0\rangle + \beta|1\rangle \Big) \frac{|e_{00}\rangle+|e_{11}\rangle}{2}
  \\+& \Big( \alpha|0\rangle - \beta|1\rangle \Big) \frac{|e_{00}\rangle-|e_{11}\rangle}{2}
  \\+& \Big( \alpha|1\rangle + \beta|0\rangle \Big) \frac{|e_{01}\rangle+|e_{10}\rangle}{2}
  \\+& \Big( \alpha|1\rangle - \beta|0\rangle \Big) \frac{|e_{01}\rangle-|e_{10}\rangle}{2}.
  \end{aligned}
\]
We can also write this as
\[
|\psi\rangle|e\rangle \longmapsto  \mathbf{1}|\psi\rangle|e_{\mathbf{1}}\rangle + Z|\psi\rangle |e_Z\rangle +X|\psi\rangle |e_X\rangle + Y|\psi\rangle |e_Y\rangle.
\]
The intuition behind this expression is that four things can happen to the qubit:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  nothing (\(\mathbf{1}\)),
\item
  phase-flip (\(Z\)),
\item
  bit-flip (\(X\)), or
\item
  both bit-flip and phase-flip (\(Y\)).
\end{enumerate}

This is certainly the case when the states \(|e_{\mathbf{1}}\rangle, |e_X\rangle, |e_Y\rangle\) and \(|e_Z\rangle\) are mutually orthogonal, otherwise we cannot perfectly distinguish between the four alternatives.

\begin{idea}
What is important here is the discretisation of errors, and the fact that we can reduce quantum errors to \emph{two types}: bit-flip errors \(X\), and phase-flip errors \(Z\).

\end{idea}

In general, given \(n\) qubits in state \(|\psi\rangle\) and the environment in state \(|e\rangle\) the joint evolution can be expanded as
\[
|\psi\rangle|e\rangle \longmapsto \sum_i E_i|\psi\rangle|e_i\rangle,
\]
where the \(E_i\) are the \(n\)-fold tensor products of the Pauli operators and the \(|e_i\rangle\) are the corresponding states of the environment, which are not assumed to be normalised or mutually orthogonal.
A typical operator \(E_i\) acting on five qubits may look like this,
\[
  X\otimes Z \otimes \mathbf{1}\otimes \mathbf{1}\otimes Y
  \equiv XZ\mathbf{1}\mathbf{1}Y.
\]
We can say that \(E_i\) represents an error consisting of the bit (\(X\)) error on the first qubit, phase (\(Z\)) error on the second qubit and both bit and phase (\(Y\)) error on the fifth qubit.
Again, \emph{this is not quite accurate if the corresponding states of the environment are not mutually orthogonal}, but it gives the right kind of intuition nonetheless.
Here the index \(i\) in \(E_i\) ranges from \(1\) to \(4^5=1024\), because there are \(4^5\) different Pauli operators acting on \(5\) qubits.

\hypertarget{same-evolution-different-errors}{%
\subsection{Same evolution, different errors}\label{same-evolution-different-errors}}

We can always pick up an orthonormal basis \(|u_i\rangle\) in the environment and express the system--environment evolution as
\[
  \begin{aligned}
    |\psi\rangle|e\rangle
    \longmapsto &\sum_{ij} E_i|\psi\rangle|u_j\rangle\langle u_j|e_i\rangle
    \\&= \sum_{j}\Big( \sum_i \langle u_j|e_i\rangle E_i\Big)|\psi\rangle|u_j\rangle
    \\&= \sum_j M_j|\psi\rangle|u_j\rangle.
  \end{aligned}
\]
The new ``error'' operators \(M_j\) satisfy \(\sum_j M_j^\dagger M_j =\mathbf{1}\) and, in general, they are \emph{not} unitary.
Now, the evolution of the density operator \(|\psi\rangle\langle\psi|\) can be written as
\[
  |\psi\rangle\langle\psi|\longmapsto \sum_j M_j|\psi\rangle\langle\psi| M_j^\dagger.
\]
Which particular errors you choose depends of your choice of the basis in the environment.
If, instead of \(|u_j\rangle\), you pick up a different basis, say \(|v_k\rangle\), then
\[
  \begin{aligned}
    |\psi\rangle|e\rangle
    \longmapsto &\sum_j M_j|\psi\rangle|u_j\rangle
  \\&= \sum_j M_j |\psi\rangle\sum_k|v_k\rangle\langle v_k|u_j\rangle
  \\&= \sum_k \Big(\sum_j \langle v_k|u_j\rangle M_j \Big)|\psi\rangle|v_k\rangle
  \\&= \sum_k N_k|\psi\rangle|v_k\rangle,
  \end{aligned}
\]
and, consequently,
\[
  |\psi\rangle\langle\psi|\longmapsto \sum_k N_k|\psi\rangle\langle\psi| N_k^\dagger.
\]
The new ``errors'' satisfy \(\sum_k N_k^\dagger N_k = \mathbf{1}\), and the error operators \(N_k\) and \(M_j\) are related by the unitary matrix \(U_{kj}=\langle v_k|u_j\rangle\).

\hypertarget{some-errors-can-be-corrected-on-some-states}{%
\subsection{Some errors can be corrected on some states}\label{some-errors-can-be-corrected-on-some-states}}

Alice prepares a quantum object in some state \(|\psi\rangle\) and sends it to Bob.
The object is intercepted by a malicious Eve who changes its state by applying one of the prescribed unitary operations \(U_1,\ldots, U_n\), with probabilities \(p_1,\ldots, p_n\), respectively.
Alice and Bob know the set of possible unitaries (errors), and the associated probabilities, but they do not know which particular unitary operation was chosen by Eve.
Can Bob reconstruct the state \(|\psi\rangle\)?
The answer is affirmative, at least for \emph{some states} \(|\psi\rangle\).

Let \(\mathcal{H}\) be the Hilbert space pertaining to the object, and let \(\mathcal{C}\) be a subspace of \(\mathcal{H}\).
Suppose \(|\psi\rangle\in\mathcal{C}\), and that, for each vector in \(\mathcal{C}\), we have
\[
  \langle\psi|U^\dagger_i U_j|\psi\rangle = \delta_{ij}
\]
Any error \(U_k\) transforms the subspace \(\mathcal{C}\) into the subspace \(\mathcal{C}_k\), which is orthogonal to \(\mathcal{C}\) and also to any other subspace \(\mathcal{C}_j\) for \(j\neq k\).
All Bob has to do is
- perform a measurement, defined by projectors on the subspaces \(\mathcal{C}_j\) for \(j=1,\ldots n\),
- identify \(k\), and
- apply \(U_k^\dagger\).

As an example, consider an object composed of three qubits and the subspace \(\mathcal{C}\) spanned by the two basis vectors \(|000\rangle\) and \(|111\rangle\).
Suppose Eve applies one of the following four unitary operations: \(U_0=\mathbf{1}\otimes\mathbf{1}\otimes \mathbf{1}\), \(U_1 =X\otimes\mathbf{1}\otimes \mathbf{1}\), \(U_2 =\mathbf{1}\otimes X\otimes \mathbf{1}\), and \(U_3=\mathbf{1}\otimes\mathbf{1}\otimes X\).
That is, the identity, or bit-flip on the first, second, or third qubit.
Each operation is chosen randomly with the same probability of \(1/4\).
It is easy to see that the four operations generate four subspaces:
\[
  \begin{aligned}
    \mathcal{C} = \Big\langle|000\rangle,|111\rangle\Big\rangle &\qquad \mathcal{C}_1 = \Big\langle|100\rangle,|011\rangle\Big\rangle
  \\\mathcal{C}_2 = \Big\langle|010\rangle,|101\rangle\Big\rangle& \qquad \mathcal{C}_3 = \Big\langle|001\rangle,|110\rangle\Big\rangle.
  \end{aligned}
\]
The eight dimensional Hilbert space of the three qubits is then decomposed into the sum of orthogonal subspaces
\[
\mathcal{C} \oplus \mathcal{C}_1 \oplus\mathcal{C}_2 \oplus \mathcal{C}_3
\]
So suppose Alice prepares \(|\psi\rangle=\alpha|000\rangle+\beta|111\rangle\) and Eve applies the bit-flip to the third qubit.
This generates the state \(\mathbf{1}\otimes\mathbf{1}\otimes X|\psi\rangle=\alpha|001\rangle+\beta|110\rangle\in \mathcal{C}_3\).
The projective measurement on these subspaces tells Bob that the new state is in the subspace \(\mathcal{C}_3\), and hence the original state can be recovered by the operation \(\mathbf{1}\otimes\mathbf{1}\otimes X\).

\hypertarget{repetition-codes}{%
\subsection{Repetition codes}\label{repetition-codes}}

In order to give a sense of how quantum error correction actually works, let us begin with a \emph{classical} example of a repetition code.
Suppose a transmission channel flips each bit in transit with probability \(p\).
If this error rate is considered too high then it can be decreased by encoding each bit into, say, three bits:
\[
  \begin{aligned}
    0 &\mapsto 000
  \\1 &\mapsto 111.
  \end{aligned}
\]
That is, each time we want to send logical \(0\), we send three physical bits, all in state \(0\); each time we want to send logical \(1\), we send three physical bits, all in state \(1\).
The receiver decodes the bit value by a ``majority vote'' of the three bits.
If only one error occurs, then this error correction procedure is foolproof.
In general, the net probability of error is just the likelihood that two or three errors occur, which is \(3p^2(1-p) + p^3 < p\).
Thus the three bit code improves the reliability of the information transfer.
The \emph{quantum} case, however, is more complicated, because we have both bit-flip \emph{and} phase-flip errors.

\hypertarget{quantum-error-correction}{%
\subsection{Quantum error correction}\label{quantum-error-correction}}

In order to protect a qubit against bit-flips (incoherent \(X\) rotations), we rely on the same repetition code, but both encoding and error correction is now done by quantum operations.
We take a qubit in some unknown pure state \(\alpha|0\rangle + \beta|1\rangle\), introduce two auxiliary qubits, and encode it into three qubits as

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-74-1} \end{center}

Suppose that at most one qubit is then flipped (say, the second one).
The encoded state then becomes \(\alpha|010\rangle + \beta|101\rangle\).
Decoding requires some care: if we measure the three qubits directly it would destroy the superposition of states that we are working so hard to protect.
Instead we introduce another two additional qubits, both in state \(|0\rangle\), and apply the following network:

\begin{center}\includegraphics{iqis-book_files/figure-latex/unnamed-chunk-75-1} \end{center}

We measure the two auxiliary qubits, also known as \textbf{ancilla bits}, and the result of the measurement, known as the \textbf{error syndrome}, tells us how to reset the three qubits of the code.
The theory behind this network runs as follows.

If qubits one and two (counting from the top) are the same, then the first ancilla is in the \(|0\rangle\) state.
Similarly, if qubits two and three are the same, then the second ancilla is in the \(|0\rangle\) state.
However, if they are different, then the corresponding ancilla is in the \(|1\rangle\) state.
Hence, the four possible error syndromes --- \(|00\rangle\), \(|01\rangle\), \(|10\rangle\), and \(|11\rangle\) --- each indicate a different possibility: no errors, an error in the third, first, or second qubits (respectively).
In our example, we would measure \(|11\rangle\), revealing that both qubits 1 and 2, and qubits 2 and 3, are different.
Thus it is qubit 2 that has an error.
Knowing the error, we can go back and fix it, simply by applying \(X\) to qubit 2.
The net result is the state \(\alpha|000\rangle + \beta|111\rangle\), which is then turned into \((\alpha|0\rangle + \beta|1\rangle)|0\rangle|0\rangle\) by running the mirror image of the encoding network.

\hypertarget{turning-bit-flips-into-phase-flips}{%
\subsection{Turning bit-flips into phase-flips}\label{turning-bit-flips-into-phase-flips}}

The three-qubit code that we have just demonstrated is sufficient to protect a qubit against single bit-flips, but not phase-flips.
But this is good enough.
Recall that \(HZH=X\), and so it is enough to sandwich the decoherence area in between the Hadamard gates: they will turn phase flips into bit flips, and we already know hot to protect our qubits against \(Z\)-errors.
The encoded state \(\alpha|0\rangle + \beta|1\rangle\) now reads \(\alpha|+++\rangle+\beta|---\rangle\), where \(|\pm\rangle=|0\rangle\pm|1\rangle\).

\hypertarget{dealing-with-bit-flip-and-phase-flip-errors}{%
\subsection{Dealing with bit-flip and phase-flip errors}\label{dealing-with-bit-flip-and-phase-flip-errors}}

We can now put the bit-flip and phase-flip codes together: first we encode the qubit using the phase-flip code, and then we encode each of the three qubits of the code using the bit-flip code.
This gives an error correction scheme that allows us to protect against both types of error, thus yielding a code that encodes a single logical qubit across nine physical qubits, protecting against a single quantum error on any of the nine qubits.

If we want to preserve a quantum state for a long time without doing any computations, or if we want to send it through a noisy communications channel, we can just encode the state using a quantum code and decode it when we are done.
Computation on encoded states using noisy gates requires few more tricks.

\textbf{!!!TO-DO!!! (``to be completed'')}

\hypertarget{remarks-and-exercises-11}{%
\subsection{\texorpdfstring{\emph{Remarks and exercises}}{Remarks and exercises}}\label{remarks-and-exercises-11}}

\textbf{!!!TO-DO!!!}

\hypertarget{quantum-error-correction-and-fault-tolerance}{%
\section{Quantum error correction and fault tolerance}\label{quantum-error-correction-and-fault-tolerance}}

\hypertarget{further-reading}{%
\section{Further reading}\label{further-reading}}

\begin{quote}
About \ldots{} \textbf{!!!TO-DO!!!}
\end{quote}

possible topics:
- graphical calculus
- philosophical ``problem'' of measurement
- history of experimental results and implementations
- current uses of quantum information theory

\end{document}
